{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbff640f",
   "metadata": {
    "id": "view-in-github",
    "papermill": {
     "duration": 0.006135,
     "end_time": "2025-04-03T07:44:23.554096",
     "exception": false,
     "start_time": "2025-04-03T07:44:23.547961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/raihanewubd/selfSupervised/blob/main/i_jepa_aav_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a11482b2",
   "metadata": {
    "_cell_guid": "1b74e769-17ce-492e-bbf7-eb90938bae5d",
    "_uuid": "ab0f765f-50d0-4e71-934b-69036f927618",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:23.565592Z",
     "iopub.status.busy": "2025-04-03T07:44:23.565297Z",
     "iopub.status.idle": "2025-04-03T07:44:47.810747Z",
     "shell.execute_reply": "2025-04-03T07:44:47.810050Z"
    },
    "id": "7Qm5o5BpuTyt",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 24.252842,
     "end_time": "2025-04-03T07:44:47.812308",
     "exception": false,
     "start_time": "2025-04-03T07:44:23.559466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from transformers import ViTForImageClassification, ViTImageProcessor\n",
    "from torchvision.models import vit_b_16\n",
    "\n",
    "\n",
    "\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6e1255f",
   "metadata": {
    "_cell_guid": "d0758325-ed5a-4988-b20a-51539395a900",
    "_uuid": "b02bcb6e-1d67-4b0c-9d11-a22f3ab07a61",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:47.824022Z",
     "iopub.status.busy": "2025-04-03T07:44:47.823789Z",
     "iopub.status.idle": "2025-04-03T07:44:47.826629Z",
     "shell.execute_reply": "2025-04-03T07:44:47.826036Z"
    },
    "id": "Gxnc6znruQbZ",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "9a7e3c98-b215-41a6-da85-f0ccbf58bc80",
    "papermill": {
     "duration": 0.009675,
     "end_time": "2025-04-03T07:44:47.827681",
     "exception": false,
     "start_time": "2025-04-03T07:44:47.818006",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "376a74fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:47.838691Z",
     "iopub.status.busy": "2025-04-03T07:44:47.838487Z",
     "iopub.status.idle": "2025-04-03T07:44:47.841238Z",
     "shell.execute_reply": "2025-04-03T07:44:47.840654Z"
    },
    "id": "51MrUfzzXm_a",
    "papermill": {
     "duration": 0.009421,
     "end_time": "2025-04-03T07:44:47.842301",
     "exception": false,
     "start_time": "2025-04-03T07:44:47.832880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define base directory and file name for saving the classifier checkpoint.\n",
    "base_dir = \"/kaggle/working\"\n",
    "#base_dir = \"/content/drive/MyDrive/AAVDATASET/spectrogram\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cef8dc13",
   "metadata": {
    "_cell_guid": "cfbd3054-08ff-4e37-a1dd-a9816ded260d",
    "_uuid": "2bb0d814-c433-4069-b2de-b8afb06f8c33",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:47.853200Z",
     "iopub.status.busy": "2025-04-03T07:44:47.853002Z",
     "iopub.status.idle": "2025-04-03T07:44:52.318802Z",
     "shell.execute_reply": "2025-04-03T07:44:52.317894Z"
    },
    "id": "fKthbkn-t67J",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.473021,
     "end_time": "2025-04-03T07:44:52.320508",
     "exception": false,
     "start_time": "2025-04-03T07:44:47.847487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = '/kaggle/input/aav-spectrogram/spectrogram'\n",
    "#data_dir = os.path.join(base_dir,'dataset')\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7263b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:52.333040Z",
     "iopub.status.busy": "2025-04-03T07:44:52.332802Z",
     "iopub.status.idle": "2025-04-03T07:44:52.381928Z",
     "shell.execute_reply": "2025-04-03T07:44:52.380996Z"
    },
    "id": "2zIe8gpxxU60",
    "outputId": "2047897e-2614-44a2-e53b-a29879c16e7f",
    "papermill": {
     "duration": 0.056328,
     "end_time": "2025-04-03T07:44:52.383140",
     "exception": false,
     "start_time": "2025-04-03T07:44:52.326812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device for GPU acceleration if available.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fbe0235",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:52.394548Z",
     "iopub.status.busy": "2025-04-03T07:44:52.394312Z",
     "iopub.status.idle": "2025-04-03T07:44:52.399958Z",
     "shell.execute_reply": "2025-04-03T07:44:52.399303Z"
    },
    "id": "cuurpOHkxbxk",
    "papermill": {
     "duration": 0.01252,
     "end_time": "2025-04-03T07:44:52.401087",
     "exception": false,
     "start_time": "2025-04-03T07:44:52.388567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_blocks(image, context_scale=0.85, target_scale=0.2, num_targets=4, max_overlap=0.5):\n",
    "    # Extract a central context block.\n",
    "    _, H, W = image.shape\n",
    "    context_size = int(context_scale * H)\n",
    "    top = (H - context_size) // 2\n",
    "    left = (W - context_size) // 2\n",
    "    context_block = image[:, top:top+context_size, left:left+context_size]\n",
    "    context_block = torch.nn.functional.interpolate(\n",
    "        context_block.unsqueeze(0),\n",
    "        size=(224, 224),\n",
    "        mode='bilinear',\n",
    "        align_corners=False\n",
    "    ).squeeze(0)\n",
    "\n",
    "    # Extract num_targets target blocks randomly.\n",
    "    target_blocks = []\n",
    "    for _ in range(num_targets):\n",
    "        target_size = int(target_scale * H)\n",
    "        top_t = random.randint(0, H - target_size)\n",
    "        left_t = random.randint(0, W - target_size)\n",
    "        target_block = image[:, top_t:top_t+target_size, left_t:left_t+target_size]\n",
    "        target_block = torch.nn.functional.interpolate(\n",
    "            target_block.unsqueeze(0),\n",
    "            size=(224, 224),\n",
    "            mode='bilinear',\n",
    "            align_corners=False\n",
    "        ).squeeze(0)\n",
    "        target_blocks.append(target_block)\n",
    "    target_blocks = torch.stack(target_blocks)\n",
    "    return context_block, target_blocks, (top, left, context_size), None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efbb6516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:52.412744Z",
     "iopub.status.busy": "2025-04-03T07:44:52.412508Z",
     "iopub.status.idle": "2025-04-03T07:44:52.416172Z",
     "shell.execute_reply": "2025-04-03T07:44:52.415538Z"
    },
    "id": "oj2gcdgq4hvd",
    "papermill": {
     "duration": 0.010438,
     "end_time": "2025-04-03T07:44:52.417249",
     "exception": false,
     "start_time": "2025-04-03T07:44:52.406811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_sample(sample, context_scale, target_scale, num_targets):\n",
    "    # Unpack sample: sample is ((img, label), image_path)\n",
    "    (img, label), image_path = sample\n",
    "    # Move image to GPU if available.\n",
    "    img = img.to(device)\n",
    "    context_block, target_blocks, _, _ = extract_blocks(img, context_scale, target_scale, num_targets)\n",
    "    # Bring results back to CPU before caching.\n",
    "    return (context_block.cpu(), target_blocks.cpu(), label, image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "995fd0c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:52.428246Z",
     "iopub.status.busy": "2025-04-03T07:44:52.428050Z",
     "iopub.status.idle": "2025-04-03T07:44:52.433736Z",
     "shell.execute_reply": "2025-04-03T07:44:52.433099Z"
    },
    "id": "w3876qql71lv",
    "papermill": {
     "duration": 0.012524,
     "end_time": "2025-04-03T07:44:52.434932",
     "exception": false,
     "start_time": "2025-04-03T07:44:52.422408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PrecomputedIJEPADataset(Dataset):\n",
    "    def __init__(self, base_dataset, context_scale=0.85, target_scale=0.2, num_targets=4, cache_file=None):\n",
    "        self.cache_file = cache_file\n",
    "        if cache_file and os.path.exists(cache_file):\n",
    "            # Load precomputed data from disk.\n",
    "            with open(cache_file, 'rb') as f:\n",
    "                self.data = pickle.load(f)\n",
    "        else:\n",
    "            # Create a list of samples along with their original image paths (if available) using a progress bar.\n",
    "            if hasattr(base_dataset, 'samples'):\n",
    "                base_samples = [\n",
    "                    (base_dataset[i], base_dataset.samples[i][0])\n",
    "                    for i in tqdm(range(len(base_dataset)), desc=\"Loading samples\")\n",
    "                ]\n",
    "            else:\n",
    "                base_samples = [\n",
    "                    (sample, None) for sample in tqdm(base_dataset, desc=\"Loading samples\")\n",
    "                ]\n",
    "\n",
    "            # Process samples sequentially with a progress bar.\n",
    "            self.data = []\n",
    "            for sample in tqdm(base_samples, desc=\"Processing samples\"):\n",
    "                result = process_sample(sample, context_scale, target_scale, num_targets)\n",
    "                self.data.append(result)\n",
    "\n",
    "            if cache_file:\n",
    "                with open(cache_file, 'wb') as f:\n",
    "                    pickle.dump(self.data, f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fcf7123",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:44:52.445801Z",
     "iopub.status.busy": "2025-04-03T07:44:52.445580Z",
     "iopub.status.idle": "2025-04-03T07:46:09.464399Z",
     "shell.execute_reply": "2025-04-03T07:46:09.463459Z"
    },
    "id": "54OBcd7SgFde",
    "outputId": "bfa2b185-0136-43ab-a541-410d9f5ae95d",
    "papermill": {
     "duration": 77.049495,
     "end_time": "2025-04-03T07:46:09.489579",
     "exception": false,
     "start_time": "2025-04-03T07:44:52.440084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/precomputed_fulldataset_aav.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading samples: 100%|██████████| 3513/3513 [00:28<00:00, 125.14it/s]\n",
      "Processing samples: 100%|██████████| 3513/3513 [00:12<00:00, 287.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to load dataset: 77.0128 seconds and DataLoader: 0.0011 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Timing the loading of the dataset and DataLoader\n",
    "cache_path = os.path.join(base_dir,\"precomputed_fulldataset_aav.pkl\")\n",
    "print(cache_path)\n",
    "start_time = time.time()\n",
    "dataset_aav_ijepa = PrecomputedIJEPADataset(dataset, cache_file=cache_path)\n",
    "end_time_train_ijepa_dataset = time.time()\n",
    "dataloader_aav_ijepa = DataLoader(dataset_aav_ijepa, batch_size=32, shuffle=True)\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to load dataset: {end_time_train_ijepa_dataset - start_time:.4f} seconds and DataLoader: {end_time - end_time_train_ijepa_dataset:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c38d9fdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:09.535472Z",
     "iopub.status.busy": "2025-04-03T07:46:09.535162Z",
     "iopub.status.idle": "2025-04-03T07:46:09.539637Z",
     "shell.execute_reply": "2025-04-03T07:46:09.538688Z"
    },
    "id": "KEaXCJIKJLBt",
    "outputId": "9a487a6b-18c4-4478-bc20-da5f7efff64a",
    "papermill": {
     "duration": 0.028896,
     "end_time": "2025-04-03T07:46:09.541056",
     "exception": false,
     "start_time": "2025-04-03T07:46:09.512160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in the dataset: 3513\n"
     ]
    }
   ],
   "source": [
    "num_images = len(dataset_aav_ijepa)\n",
    "print(f\"Number of images in the dataset: {num_images}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72adc995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:09.585159Z",
     "iopub.status.busy": "2025-04-03T07:46:09.584952Z",
     "iopub.status.idle": "2025-04-03T07:46:09.588897Z",
     "shell.execute_reply": "2025-04-03T07:46:09.588193Z"
    },
    "id": "7pXBRPzuZPZH",
    "outputId": "bd63ba50-dbe3-4e88-f815-fe4587a2d7f4",
    "papermill": {
     "duration": 0.027415,
     "end_time": "2025-04-03T07:46:09.590213",
     "exception": false,
     "start_time": "2025-04-03T07:46:09.562798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches: 110\n"
     ]
    }
   ],
   "source": [
    "total_batches = len(dataloader_aav_ijepa)\n",
    "print(\"Total number of batches:\", total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "424c56a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:09.636358Z",
     "iopub.status.busy": "2025-04-03T07:46:09.636149Z",
     "iopub.status.idle": "2025-04-03T07:46:09.641436Z",
     "shell.execute_reply": "2025-04-03T07:46:09.640673Z"
    },
    "id": "EqNu-u2qLX44",
    "outputId": "24f917f4-1e58-4f72-d50c-7ff688eac560",
    "papermill": {
     "duration": 0.030013,
     "end_time": "2025-04-03T07:46:09.642788",
     "exception": false,
     "start_time": "2025-04-03T07:46:09.612775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import torch\\nfrom torch.utils.data import Subset\\nfrom sklearn.model_selection import train_test_split\\n\\n\\n# Define the split ratio (e.g., 80% train, 20% test)\\ntrain_ratio = 0.8\\ntest_ratio = 1 - train_ratio\\n\\n# Get the total number of samples in the dataset.\\nnum_samples = len(dataset_aav_ijepa)\\n\\n# Create a list of indices for all samples in the dataset.\\nindices = list(range(num_samples))\\n\\n# Split the indices into train and test sets using train_test_split.\\ntrain_indices, test_indices = train_test_split(indices, test_size=test_ratio, random_state=42)  # Set random_state for reproducibility.\\n\\n# Create Subset datasets for train and test using the split indices.\\ntrain_dataset_aav_ijepa = Subset(dataset_aav_ijepa, train_indices)\\ntest_dataset_aav_ijepa = Subset(dataset_aav_ijepa, test_indices)\\n\\n# Create DataLoaders for the train and test datasets.\\ntrain_loader_aav_ijepa = torch.utils.data.DataLoader(train_dataset_aav_ijepa, batch_size=32, shuffle=True)\\ntest_loader_aav_ijepa = torch.utils.data.DataLoader(test_dataset_aav_ijepa, batch_size=32, shuffle=False)  # No need to shuffle the test set.\\n\\nprint(f\"Training set size: {len(train_dataset_aav_ijepa)}\")\\nprint(f\"Testing set size: {len(test_dataset_aav_ijepa)}\")'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import torch\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define the split ratio (e.g., 80% train, 20% test)\n",
    "train_ratio = 0.8\n",
    "test_ratio = 1 - train_ratio\n",
    "\n",
    "# Get the total number of samples in the dataset.\n",
    "num_samples = len(dataset_aav_ijepa)\n",
    "\n",
    "# Create a list of indices for all samples in the dataset.\n",
    "indices = list(range(num_samples))\n",
    "\n",
    "# Split the indices into train and test sets using train_test_split.\n",
    "train_indices, test_indices = train_test_split(indices, test_size=test_ratio, random_state=42)  # Set random_state for reproducibility.\n",
    "\n",
    "# Create Subset datasets for train and test using the split indices.\n",
    "train_dataset_aav_ijepa = Subset(dataset_aav_ijepa, train_indices)\n",
    "test_dataset_aav_ijepa = Subset(dataset_aav_ijepa, test_indices)\n",
    "\n",
    "# Create DataLoaders for the train and test datasets.\n",
    "train_loader_aav_ijepa = torch.utils.data.DataLoader(train_dataset_aav_ijepa, batch_size=32, shuffle=True)\n",
    "test_loader_aav_ijepa = torch.utils.data.DataLoader(test_dataset_aav_ijepa, batch_size=32, shuffle=False)  # No need to shuffle the test set.\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset_aav_ijepa)}\")\n",
    "print(f\"Testing set size: {len(test_dataset_aav_ijepa)}\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "489bf105",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:09.688048Z",
     "iopub.status.busy": "2025-04-03T07:46:09.687816Z",
     "iopub.status.idle": "2025-04-03T07:46:09.724015Z",
     "shell.execute_reply": "2025-04-03T07:46:09.723310Z"
    },
    "id": "YcNSpd5mLi3g",
    "outputId": "3ff04da4-5c3f-40f6-e0c7-fe0794fa41cb",
    "papermill": {
     "duration": 0.060897,
     "end_time": "2025-04-03T07:46:09.725156",
     "exception": false,
     "start_time": "2025-04-03T07:46:09.664259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2459\n",
      "Validation set size: 527\n",
      "Testing set size: 527\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the split ratios (e.g., 70% train, 15% validation, 15% test)\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Get the total number of samples in the dataset.\n",
    "num_samples = len(dataset_aav_ijepa)\n",
    "\n",
    "# 1. Split into train and (validation + test)\n",
    "train_indices, val_test_indices = train_test_split(\n",
    "    list(range(num_samples)),\n",
    "    test_size=val_ratio + test_ratio,\n",
    "    random_state=42  # Set random_state for reproducibility\n",
    ")\n",
    "\n",
    "# 2. Split (validation + test) into validation and test\n",
    "val_indices, test_indices = train_test_split(\n",
    "    val_test_indices,\n",
    "    test_size=test_ratio / (val_ratio + test_ratio),\n",
    "    random_state=42  # Set random_state for reproducibility\n",
    ")\n",
    "\n",
    "# Create Subset datasets for train, validation, and test\n",
    "train_dataset_aav_ijepa = Subset(dataset_aav_ijepa, train_indices)\n",
    "val_dataset_aav_ijepa = Subset(dataset_aav_ijepa, val_indices)\n",
    "test_dataset_aav_ijepa = Subset(dataset_aav_ijepa, test_indices)\n",
    "\n",
    "# Create DataLoaders for train, validation, and test\n",
    "train_loader_aav_ijepa = torch.utils.data.DataLoader(train_dataset_aav_ijepa, batch_size=32, shuffle=True)\n",
    "val_loader_aav_ijepa = torch.utils.data.DataLoader(val_dataset_aav_ijepa, batch_size=32, shuffle=False)\n",
    "test_loader_aav_ijepa = torch.utils.data.DataLoader(test_dataset_aav_ijepa, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Training set size: {len(train_dataset_aav_ijepa)}\")\n",
    "print(f\"Validation set size: {len(val_dataset_aav_ijepa)}\")\n",
    "print(f\"Testing set size: {len(test_dataset_aav_ijepa)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eba1b43",
   "metadata": {
    "_cell_guid": "7aeb9d44-2fd8-4da1-87c0-4b992adb53db",
    "_uuid": "f3ad3daa-80ba-4ae8-8b4e-770815bad02e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:09.769545Z",
     "iopub.status.busy": "2025-04-03T07:46:09.769338Z",
     "iopub.status.idle": "2025-04-03T07:46:09.772315Z",
     "shell.execute_reply": "2025-04-03T07:46:09.771719Z"
    },
    "id": "YQIK4mND8qK1",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.02634,
     "end_time": "2025-04-03T07:46:09.773416",
     "exception": false,
     "start_time": "2025-04-03T07:46:09.747076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vit_encoder():\n",
    "    model = vit_b_16(pretrained=False)\n",
    "    model.heads = nn.Identity()  # remove classification head\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1699697a",
   "metadata": {
    "_cell_guid": "2d8198b7-dbf5-4228-975a-8c733cea1a07",
    "_uuid": "b79e21b1-3b97-4dfc-958f-bddb3c94c746",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:09.826203Z",
     "iopub.status.busy": "2025-04-03T07:46:09.826001Z",
     "iopub.status.idle": "2025-04-03T07:46:12.280680Z",
     "shell.execute_reply": "2025-04-03T07:46:12.279956Z"
    },
    "id": "rkq_fT7g8qK1",
    "jupyter": {
     "outputs_hidden": false
    },
    "outputId": "937b6613-1e96-4188-9910-59f4a58f9004",
    "papermill": {
     "duration": 2.485394,
     "end_time": "2025-04-03T07:46:12.282038",
     "exception": false,
     "start_time": "2025-04-03T07:46:09.796644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "context_encoder = get_vit_encoder().cuda()\n",
    "target_encoder  = get_vit_encoder().cuda()\n",
    "target_encoder.load_state_dict(context_encoder.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b40cc91d",
   "metadata": {
    "_cell_guid": "9206cc42-0845-4604-ab30-6852e28e2dcb",
    "_uuid": "e303f4ac-a09b-4f56-b997-6b364d63a675",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:12.330492Z",
     "iopub.status.busy": "2025-04-03T07:46:12.330245Z",
     "iopub.status.idle": "2025-04-03T07:46:12.334681Z",
     "shell.execute_reply": "2025-04-03T07:46:12.334056Z"
    },
    "id": "OApD7Fy68qK1",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.02795,
     "end_time": "2025-04-03T07:46:12.335878",
     "exception": false,
     "start_time": "2025-04-03T07:46:12.307928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    def __init__(self, input_dim=768, hidden_dim=768, output_dim=768, num_targets=4):\n",
    "        super().__init__()\n",
    "        self.num_targets = num_targets\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim * num_targets)\n",
    "        )\n",
    "    def forward(self, context_repr):\n",
    "        pred = self.mlp(context_repr)\n",
    "        # Reshape to [B, num_targets, output_dim]\n",
    "        return pred.view(-1, self.num_targets, pred.size(-1) // self.num_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db5a6468",
   "metadata": {
    "_cell_guid": "e10ef302-1659-4a97-9bbb-2de90ac902c9",
    "_uuid": "66d2337f-fb52-4652-9da7-242ce9d9d5e1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:12.381095Z",
     "iopub.status.busy": "2025-04-03T07:46:12.380882Z",
     "iopub.status.idle": "2025-04-03T07:46:12.411425Z",
     "shell.execute_reply": "2025-04-03T07:46:12.410866Z"
    },
    "id": "ZsZNIdEk8qK2",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.05503,
     "end_time": "2025-04-03T07:46:12.412622",
     "exception": false,
     "start_time": "2025-04-03T07:46:12.357592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 6. Set up optimizer, loss, and EMA update (same as your CIFAR code).\n",
    "predictor = Predictor().cuda()\n",
    "optimizer = optim.Adam(list(context_encoder.parameters()) + list(predictor.parameters()), lr=1e-1)\n",
    "criterion = nn.MSELoss()\n",
    "ema_decay = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9df2ed2f",
   "metadata": {
    "_cell_guid": "aece458a-d1da-4334-804f-b054cf8ed0fc",
    "_uuid": "0e90599a-d03d-4231-a58a-1272a3613cc3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:12.456721Z",
     "iopub.status.busy": "2025-04-03T07:46:12.456489Z",
     "iopub.status.idle": "2025-04-03T07:46:12.460215Z",
     "shell.execute_reply": "2025-04-03T07:46:12.459598Z"
    },
    "id": "kM60lfOw8qK2",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.027067,
     "end_time": "2025-04-03T07:46:12.461277",
     "exception": false,
     "start_time": "2025-04-03T07:46:12.434210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def update_ema(model, model_ema, beta):\n",
    "    for param, param_ema in zip(model.parameters(), model_ema.parameters()):\n",
    "        param_ema.data.mul_(beta).add_(param.data, alpha=1 - beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99b9a775",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:12.505746Z",
     "iopub.status.busy": "2025-04-03T07:46:12.505382Z",
     "iopub.status.idle": "2025-04-03T07:46:12.546976Z",
     "shell.execute_reply": "2025-04-03T07:46:12.546213Z"
    },
    "papermill": {
     "duration": 0.065204,
     "end_time": "2025-04-03T07:46:12.548221",
     "exception": false,
     "start_time": "2025-04-03T07:46:12.483017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0: shape = torch.Size([3, 224, 224])\n",
      "Item 0: shape = tensor([[[-0.5137, -0.5137, -0.5137,  ..., -0.5294, -0.5294, -0.5294],\n",
      "         [-0.5137, -0.5137, -0.5100,  ..., -0.5294, -0.5294, -0.5294],\n",
      "         [-0.5089, -0.5089, -0.5070,  ..., -0.5197, -0.5197, -0.5197],\n",
      "         ...,\n",
      "         [-0.3569, -0.3569, -0.3569,  ..., -0.3155, -0.3155, -0.3155],\n",
      "         [-0.3926, -0.3926, -0.3926,  ..., -0.3327, -0.3327, -0.3327],\n",
      "         [-0.5137, -0.5137, -0.5137,  ..., -0.4902, -0.4902, -0.4902]],\n",
      "\n",
      "        [[ 0.4510,  0.4510,  0.4510,  ...,  0.4118,  0.4118,  0.4118],\n",
      "         [ 0.4510,  0.4510,  0.4510,  ...,  0.3671,  0.3633,  0.3633],\n",
      "         [ 0.4558,  0.4558,  0.4558,  ...,  0.4141,  0.4123,  0.4123],\n",
      "         ...,\n",
      "         [ 0.5245,  0.5245,  0.5245,  ...,  0.5383,  0.5383,  0.5383],\n",
      "         [ 0.5116,  0.5116,  0.5116,  ...,  0.5315,  0.5315,  0.5315],\n",
      "         [ 0.4510,  0.4510,  0.4510,  ...,  0.4588,  0.4588,  0.4588]],\n",
      "\n",
      "        [[-0.1373, -0.1373, -0.1373,  ..., -0.1059, -0.1059, -0.1059],\n",
      "         [-0.1312, -0.1312, -0.1312,  ..., -0.0938, -0.0938, -0.0938],\n",
      "         [-0.1343, -0.1343, -0.1343,  ..., -0.1145, -0.1145, -0.1145],\n",
      "         ...,\n",
      "         [-0.2157, -0.2157, -0.2157,  ..., -0.2433, -0.2444, -0.2481],\n",
      "         [-0.1978, -0.1978, -0.1978,  ..., -0.2360, -0.2360, -0.2360],\n",
      "         [-0.1373, -0.1373, -0.1373,  ..., -0.1451, -0.1451, -0.1451]]])\n",
      "Item 1: shape = torch.Size([4, 3, 224, 224])\n",
      "Item 1: shape = tensor([[[[-0.5451, -0.5451, -0.5451,  ..., -0.5529, -0.5529, -0.5529],\n",
      "          [-0.5451, -0.5451, -0.5451,  ..., -0.5529, -0.5529, -0.5529],\n",
      "          [-0.5451, -0.5451, -0.5451,  ..., -0.5529, -0.5529, -0.5529],\n",
      "          ...,\n",
      "          [-0.5137, -0.5137, -0.5137,  ..., -0.5451, -0.5451, -0.5451],\n",
      "          [-0.5137, -0.5137, -0.5137,  ..., -0.5451, -0.5451, -0.5451],\n",
      "          [-0.5137, -0.5137, -0.5137,  ..., -0.5451, -0.5451, -0.5451]],\n",
      "\n",
      "         [[ 0.4353,  0.4353,  0.4353,  ...,  0.4353,  0.4353,  0.4353],\n",
      "          [ 0.4353,  0.4353,  0.4353,  ...,  0.4353,  0.4353,  0.4353],\n",
      "          [ 0.4353,  0.4353,  0.4353,  ...,  0.4353,  0.4353,  0.4353],\n",
      "          ...,\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4431,  0.4431,  0.4431],\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4431,  0.4431,  0.4431],\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4431,  0.4431,  0.4431]],\n",
      "\n",
      "         [[-0.1137, -0.1137, -0.1137,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          [-0.1137, -0.1137, -0.1137,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          [-0.1137, -0.1137, -0.1137,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          ...,\n",
      "          [-0.1373, -0.1373, -0.1373,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          [-0.1373, -0.1373, -0.1373,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          [-0.1373, -0.1373, -0.1373,  ..., -0.1059, -0.1059, -0.1059]]],\n",
      "\n",
      "\n",
      "        [[[-0.5373, -0.5373, -0.5373,  ..., -0.5686, -0.5686, -0.5686],\n",
      "          [-0.5373, -0.5373, -0.5373,  ..., -0.5686, -0.5686, -0.5686],\n",
      "          [-0.5373, -0.5373, -0.5373,  ..., -0.5686, -0.5686, -0.5686],\n",
      "          ...,\n",
      "          [-0.5451, -0.5451, -0.5451,  ..., -0.5529, -0.5529, -0.5529],\n",
      "          [-0.5451, -0.5451, -0.5451,  ..., -0.5529, -0.5529, -0.5529],\n",
      "          [-0.5451, -0.5451, -0.5451,  ..., -0.5529, -0.5529, -0.5529]],\n",
      "\n",
      "         [[ 0.4118,  0.4118,  0.4118,  ...,  0.4118,  0.4118,  0.4118],\n",
      "          [ 0.4118,  0.4118,  0.4118,  ...,  0.4118,  0.4118,  0.4118],\n",
      "          [ 0.4118,  0.4118,  0.4118,  ...,  0.4118,  0.4118,  0.4118],\n",
      "          ...,\n",
      "          [ 0.4275,  0.4275,  0.4275,  ...,  0.4118,  0.4118,  0.4118],\n",
      "          [ 0.4275,  0.4275,  0.4275,  ...,  0.4118,  0.4118,  0.4118],\n",
      "          [ 0.4275,  0.4275,  0.4275,  ...,  0.4118,  0.4118,  0.4118]],\n",
      "\n",
      "         [[-0.1059, -0.1059, -0.1059,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          [-0.1059, -0.1059, -0.1059,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          [-0.1059, -0.1059, -0.1059,  ..., -0.1059, -0.1059, -0.1059],\n",
      "          ...,\n",
      "          [-0.1137, -0.1137, -0.1137,  ..., -0.0980, -0.0980, -0.0980],\n",
      "          [-0.1137, -0.1137, -0.1137,  ..., -0.0980, -0.0980, -0.0980],\n",
      "          [-0.1137, -0.1137, -0.1137,  ..., -0.0980, -0.0980, -0.0980]]],\n",
      "\n",
      "\n",
      "        [[[-0.6078, -0.6078, -0.6078,  ..., -0.6078, -0.6078, -0.6078],\n",
      "          [-0.6078, -0.6078, -0.6078,  ..., -0.6078, -0.6078, -0.6078],\n",
      "          [-0.6078, -0.6078, -0.6078,  ..., -0.6078, -0.6078, -0.6078],\n",
      "          ...,\n",
      "          [-0.4667, -0.4667, -0.4667,  ..., -0.4431, -0.4431, -0.4431],\n",
      "          [-0.4667, -0.4667, -0.4667,  ..., -0.4431, -0.4431, -0.4431],\n",
      "          [-0.4667, -0.4667, -0.4667,  ..., -0.4431, -0.4431, -0.4431]],\n",
      "\n",
      "         [[ 0.3647,  0.3647,  0.3647,  ...,  0.3725,  0.3725,  0.3725],\n",
      "          [ 0.3647,  0.3647,  0.3647,  ...,  0.3725,  0.3725,  0.3725],\n",
      "          [ 0.3647,  0.3647,  0.3647,  ...,  0.3725,  0.3725,  0.3725],\n",
      "          ...,\n",
      "          [ 0.4667,  0.4667,  0.4667,  ...,  0.4745,  0.4745,  0.4745],\n",
      "          [ 0.4667,  0.4667,  0.4667,  ...,  0.4745,  0.4745,  0.4745],\n",
      "          [ 0.4667,  0.4667,  0.4667,  ...,  0.4745,  0.4745,  0.4745]],\n",
      "\n",
      "         [[-0.0667, -0.0667, -0.0667,  ..., -0.0745, -0.0745, -0.0745],\n",
      "          [-0.0667, -0.0667, -0.0667,  ..., -0.0745, -0.0745, -0.0745],\n",
      "          [-0.0667, -0.0667, -0.0667,  ..., -0.0745, -0.0745, -0.0745],\n",
      "          ...,\n",
      "          [-0.1529, -0.1529, -0.1529,  ..., -0.1765, -0.1765, -0.1765],\n",
      "          [-0.1529, -0.1529, -0.1529,  ..., -0.1765, -0.1765, -0.1765],\n",
      "          [-0.1529, -0.1529, -0.1529,  ..., -0.1765, -0.1765, -0.1765]]],\n",
      "\n",
      "\n",
      "        [[[-0.5137, -0.5137, -0.5137,  ..., -0.5216, -0.5216, -0.5216],\n",
      "          [-0.5137, -0.5137, -0.5137,  ..., -0.5216, -0.5216, -0.5216],\n",
      "          [-0.5137, -0.5137, -0.5137,  ..., -0.5216, -0.5216, -0.5216],\n",
      "          ...,\n",
      "          [-0.4824, -0.4824, -0.4824,  ..., -0.4588, -0.4588, -0.4588],\n",
      "          [-0.4824, -0.4824, -0.4824,  ..., -0.4588, -0.4588, -0.4588],\n",
      "          [-0.4824, -0.4824, -0.4824,  ..., -0.4588, -0.4588, -0.4588]],\n",
      "\n",
      "         [[ 0.4588,  0.4588,  0.4588,  ...,  0.4588,  0.4588,  0.4588],\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4588,  0.4588,  0.4588],\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4588,  0.4588,  0.4588],\n",
      "          ...,\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4667,  0.4667,  0.4667],\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4667,  0.4667,  0.4667],\n",
      "          [ 0.4588,  0.4588,  0.4588,  ...,  0.4667,  0.4667,  0.4667]],\n",
      "\n",
      "         [[-0.1294, -0.1294, -0.1294,  ..., -0.1216, -0.1216, -0.1216],\n",
      "          [-0.1294, -0.1294, -0.1294,  ..., -0.1216, -0.1216, -0.1216],\n",
      "          [-0.1294, -0.1294, -0.1294,  ..., -0.1216, -0.1216, -0.1216],\n",
      "          ...,\n",
      "          [-0.1451, -0.1451, -0.1451,  ..., -0.1608, -0.1608, -0.1608],\n",
      "          [-0.1451, -0.1451, -0.1451,  ..., -0.1608, -0.1608, -0.1608],\n",
      "          [-0.1451, -0.1451, -0.1451,  ..., -0.1608, -0.1608, -0.1608]]]])\n",
      "Item 2: shape = <class 'int'>\n",
      "Item 2: shape = 2\n",
      "Item 3: shape = <class 'str'>\n",
      "Item 3: shape = /kaggle/input/aav-spectrogram/spectrogram/single/segment_523.png\n"
     ]
    }
   ],
   "source": [
    "sample = next(iter(train_dataset_aav_ijepa))\n",
    "for i, item in enumerate(sample):\n",
    "    print(f\"Item {i}: shape = {item.shape if hasattr(item, 'shape') else type(item)}\")\n",
    "    print(f\"Item {i}: shape = {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44fc7f29",
   "metadata": {
    "_cell_guid": "0182b713-044f-4839-9cfc-0369f1eec96d",
    "_uuid": "c8659b2c-5286-4027-b97b-c1ac887bb5f6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-04-03T07:46:12.593274Z",
     "iopub.status.busy": "2025-04-03T07:46:12.593067Z",
     "iopub.status.idle": "2025-04-03T12:14:58.276465Z",
     "shell.execute_reply": "2025-04-03T12:14:58.275395Z"
    },
    "id": "IjnBW1lE8qK2",
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 16125.708696,
     "end_time": "2025-04-03T12:14:58.278962",
     "exception": false,
     "start_time": "2025-04-03T07:46:12.570266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150 - Train Loss: 9933.0125395605 - Epoch Time: 107.27s\n",
      "Checkpoint saved at epoch 1 with loss 9933.0125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150 - Train Loss: 0.0396372993 - Epoch Time: 107.37s\n",
      "Checkpoint saved at epoch 2 with loss 0.0396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150 - Train Loss: 0.0000303999 - Epoch Time: 106.85s\n",
      "Checkpoint saved at epoch 3 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150 - Train Loss: 0.0000105425 - Epoch Time: 106.96s\n",
      "Checkpoint saved at epoch 4 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150 - Train Loss: 0.0000105456 - Epoch Time: 106.76s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150 - Train Loss: 0.0000107935 - Epoch Time: 106.89s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150 - Train Loss: 0.0000107122 - Epoch Time: 106.96s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150 - Train Loss: 0.0000107772 - Epoch Time: 106.98s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150 - Train Loss: 0.0000105551 - Epoch Time: 107.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150 - Train Loss: 0.0000106493 - Epoch Time: 106.91s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150 - Train Loss: 0.0000106900 - Epoch Time: 106.93s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150 - Train Loss: 0.0000105622 - Epoch Time: 107.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150 - Train Loss: 0.0000106139 - Epoch Time: 107.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150 - Train Loss: 0.0000105650 - Epoch Time: 107.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150 - Train Loss: 0.0000106657 - Epoch Time: 107.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150 - Train Loss: 0.0000105473 - Epoch Time: 106.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150 - Train Loss: 0.0000105052 - Epoch Time: 107.02s\n",
      "Checkpoint saved at epoch 17 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150 - Train Loss: 0.0000106344 - Epoch Time: 107.25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150 - Train Loss: 0.0000107107 - Epoch Time: 107.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150 - Train Loss: 0.0000106454 - Epoch Time: 107.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150 - Train Loss: 0.0000106319 - Epoch Time: 107.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150 - Train Loss: 0.0000111355 - Epoch Time: 107.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150 - Train Loss: 0.0000105512 - Epoch Time: 107.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150 - Train Loss: 0.0000074876 - Epoch Time: 107.26s\n",
      "Checkpoint saved at epoch 24 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150 - Train Loss: 0.0000005274 - Epoch Time: 106.99s\n",
      "Checkpoint saved at epoch 25 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150 - Train Loss: 0.0000004784 - Epoch Time: 107.10s\n",
      "Checkpoint saved at epoch 26 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150 - Train Loss: 0.0000004783 - Epoch Time: 106.97s\n",
      "Checkpoint saved at epoch 27 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150 - Train Loss: 0.0000004836 - Epoch Time: 107.02s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150 - Train Loss: 0.0000004834 - Epoch Time: 107.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150 - Train Loss: 0.0000004713 - Epoch Time: 107.13s\n",
      "Checkpoint saved at epoch 30 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150 - Train Loss: 0.0000004805 - Epoch Time: 107.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150 - Train Loss: 0.0000004824 - Epoch Time: 107.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150 - Train Loss: 0.0000004764 - Epoch Time: 107.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150 - Train Loss: 0.0000004753 - Epoch Time: 107.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150 - Train Loss: 0.0000004814 - Epoch Time: 107.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150 - Train Loss: 0.0000005078 - Epoch Time: 107.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150 - Train Loss: 0.0000004749 - Epoch Time: 107.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150 - Train Loss: 0.0000004879 - Epoch Time: 107.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150 - Train Loss: 0.0000005223 - Epoch Time: 107.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150 - Train Loss: 0.0000005056 - Epoch Time: 107.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150 - Train Loss: 0.0000004725 - Epoch Time: 107.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150 - Train Loss: 0.0000004950 - Epoch Time: 107.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150 - Train Loss: 0.0000005075 - Epoch Time: 107.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150 - Train Loss: 0.0000004958 - Epoch Time: 107.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150 - Train Loss: 0.0000005210 - Epoch Time: 107.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150 - Train Loss: 0.0000005225 - Epoch Time: 107.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150 - Train Loss: 0.0000005026 - Epoch Time: 107.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150 - Train Loss: 0.0000004808 - Epoch Time: 107.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150 - Train Loss: 0.0000005004 - Epoch Time: 107.17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150 - Train Loss: 0.0000005338 - Epoch Time: 107.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150 - Train Loss: 0.0000004779 - Epoch Time: 107.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150 - Train Loss: 0.0000005533 - Epoch Time: 107.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150 - Train Loss: 0.0000004996 - Epoch Time: 107.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150 - Train Loss: 0.0000004975 - Epoch Time: 107.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/150 - Train Loss: 0.0000005309 - Epoch Time: 107.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150 - Train Loss: 0.0000006238 - Epoch Time: 107.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150 - Train Loss: 0.0000005418 - Epoch Time: 107.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150 - Train Loss: 0.0000006051 - Epoch Time: 107.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150 - Train Loss: 0.0000005226 - Epoch Time: 107.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150 - Train Loss: 0.0000005147 - Epoch Time: 107.42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150 - Train Loss: 0.0000005316 - Epoch Time: 107.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150 - Train Loss: 0.0000005201 - Epoch Time: 107.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150 - Train Loss: 0.0000006084 - Epoch Time: 107.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150 - Train Loss: 0.0000005030 - Epoch Time: 107.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150 - Train Loss: 0.0000005373 - Epoch Time: 107.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150 - Train Loss: 0.0000005435 - Epoch Time: 107.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150 - Train Loss: 0.0000005381 - Epoch Time: 107.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150 - Train Loss: 0.0000005580 - Epoch Time: 107.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150 - Train Loss: 0.0000005703 - Epoch Time: 107.40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150 - Train Loss: 0.0000007013 - Epoch Time: 107.38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150 - Train Loss: 0.0000007536 - Epoch Time: 107.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/150 - Train Loss: 0.0000006479 - Epoch Time: 107.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150 - Train Loss: 0.0000006654 - Epoch Time: 107.58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/150 - Train Loss: 0.0000007969 - Epoch Time: 107.47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150 - Train Loss: 0.0000006994 - Epoch Time: 107.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/150 - Train Loss: 0.0000010518 - Epoch Time: 107.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150 - Train Loss: 0.0000006269 - Epoch Time: 107.35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150 - Train Loss: 0.0000008526 - Epoch Time: 107.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150 - Train Loss: 0.0000012404 - Epoch Time: 107.49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150 - Train Loss: 0.0000010181 - Epoch Time: 107.50s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150 - Train Loss: 0.0000014421 - Epoch Time: 107.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/150 - Train Loss: 0.0000020086 - Epoch Time: 107.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150 - Train Loss: 0.0000013026 - Epoch Time: 107.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/150 - Train Loss: 0.0000027119 - Epoch Time: 107.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/150 - Train Loss: 0.0000108288 - Epoch Time: 107.61s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/150 - Train Loss: 0.0335191947 - Epoch Time: 107.51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150 - Train Loss: 0.0002173877 - Epoch Time: 107.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/150 - Train Loss: 0.0000008129 - Epoch Time: 107.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/150 - Train Loss: 0.0000011182 - Epoch Time: 107.48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/150 - Train Loss: 0.0000006072 - Epoch Time: 107.37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/150 - Train Loss: 0.0000017031 - Epoch Time: 107.53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/150 - Train Loss: 0.0000033567 - Epoch Time: 107.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/150 - Train Loss: 0.0012622321 - Epoch Time: 107.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/150 - Train Loss: 0.0157197408 - Epoch Time: 107.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150 - Train Loss: 0.0000031637 - Epoch Time: 107.59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/150 - Train Loss: 0.0000006788 - Epoch Time: 107.44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/150 - Train Loss: 0.0000011293 - Epoch Time: 107.46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150 - Train Loss: 0.0000017528 - Epoch Time: 107.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150 - Train Loss: 0.0000054151 - Epoch Time: 107.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/150 - Train Loss: 0.0240594276 - Epoch Time: 107.43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 101/150 - Train Loss: 0.0000903395 - Epoch Time: 107.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/150 - Train Loss: 0.0000004740 - Epoch Time: 107.36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/150 - Train Loss: 0.0000004091 - Epoch Time: 107.03s\n",
      "Checkpoint saved at epoch 103 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 104/150 - Train Loss: 0.0000004067 - Epoch Time: 107.14s\n",
      "Checkpoint saved at epoch 104 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105/150 - Train Loss: 0.0000004230 - Epoch Time: 107.20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150 - Train Loss: 0.0000004331 - Epoch Time: 107.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150 - Train Loss: 0.0000004418 - Epoch Time: 107.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/150 - Train Loss: 0.0000004794 - Epoch Time: 107.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/150 - Train Loss: 0.0000004372 - Epoch Time: 107.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/150 - Train Loss: 0.0000004795 - Epoch Time: 107.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/150 - Train Loss: 0.0000004915 - Epoch Time: 107.21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150 - Train Loss: 0.0000006456 - Epoch Time: 107.18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150 - Train Loss: 0.0000008599 - Epoch Time: 107.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/150 - Train Loss: 0.0001194077 - Epoch Time: 107.29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150 - Train Loss: 0.0076031929 - Epoch Time: 107.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/150 - Train Loss: 0.0000017180 - Epoch Time: 107.11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150 - Train Loss: 0.0000005330 - Epoch Time: 107.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/150 - Train Loss: 0.0000005618 - Epoch Time: 107.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150 - Train Loss: 0.0000005691 - Epoch Time: 107.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150 - Train Loss: 0.0000005377 - Epoch Time: 107.23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 121/150 - Train Loss: 0.0000005937 - Epoch Time: 107.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150 - Train Loss: 0.0000005797 - Epoch Time: 107.14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/150 - Train Loss: 0.0000006270 - Epoch Time: 107.09s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/150 - Train Loss: 0.0000005586 - Epoch Time: 107.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/150 - Train Loss: 0.0000005701 - Epoch Time: 107.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/150 - Train Loss: 0.0000008348 - Epoch Time: 107.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/150 - Train Loss: 0.0033423548 - Epoch Time: 107.10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/150 - Train Loss: 0.0000105633 - Epoch Time: 107.30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 129/150 - Train Loss: 0.0000007841 - Epoch Time: 107.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150 - Train Loss: 0.0000010025 - Epoch Time: 107.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/150 - Train Loss: 0.0000008815 - Epoch Time: 107.12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/150 - Train Loss: 0.0000015642 - Epoch Time: 107.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150 - Train Loss: 0.0000010456 - Epoch Time: 107.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150 - Train Loss: 0.0000008773 - Epoch Time: 107.41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150 - Train Loss: 0.0000012329 - Epoch Time: 107.15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150 - Train Loss: 0.0000016365 - Epoch Time: 107.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/150 - Train Loss: 0.0000014308 - Epoch Time: 107.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/150 - Train Loss: 0.0000013933 - Epoch Time: 107.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150 - Train Loss: 0.0013548351 - Epoch Time: 107.24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150 - Train Loss: 0.0000191366 - Epoch Time: 107.16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150 - Train Loss: 0.0000275483 - Epoch Time: 107.28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/150 - Train Loss: 0.0003201611 - Epoch Time: 107.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150 - Train Loss: 0.0005432271 - Epoch Time: 107.05s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/150 - Train Loss: 0.0010315167 - Epoch Time: 107.13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150 - Train Loss: 0.0008990226 - Epoch Time: 107.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150 - Train Loss: 0.0021160119 - Epoch Time: 107.01s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/150 - Train Loss: 0.0754867362 - Epoch Time: 107.03s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/150 - Train Loss: 0.0003909256 - Epoch Time: 107.07s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/150 - Train Loss: 0.0000001251 - Epoch Time: 107.10s\n",
      "Checkpoint saved at epoch 149 with loss 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/150 - Train Loss: 0.0000000020 - Epoch Time: 107.08s\n",
      "Checkpoint saved at epoch 150 with loss 0.0000\n",
      "Total Training Time: 16125.67s\n"
     ]
    }
   ],
   "source": [
    "# Create a directory for visualizations if it doesn't exist.\n",
    "#viz_dir = \"/kaggle/working/viz\"\n",
    "#os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "num_epochs = 150\n",
    "ema_decay = 0.1\n",
    "best_loss = float('inf')\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start_time = time.time()\n",
    "    context_encoder.train()\n",
    "    predictor.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Enumerate over batches with a progress bar.\n",
    "    for batch_idx, (context_block, target_blocks, class_label, filepath) in enumerate(tqdm(train_loader_aav_ijepa, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)):\n",
    "        context_block = context_block.cuda()            # [B, C, 224, 224]\n",
    "        target_blocks = target_blocks.cuda()              # [B, num_targets, C, 224, 224]\n",
    "\n",
    "        # Forward pass through context encoder and predictor.\n",
    "        context_repr = context_encoder(context_block)     # [B, 768]\n",
    "        preds = predictor(context_repr)                   # [B, num_targets, 768]\n",
    "\n",
    "        B, num_targets, C, Ht, Wt = target_blocks.shape\n",
    "        target_blocks_flat = target_blocks.view(B * num_targets, C, Ht, Wt)\n",
    "        with torch.no_grad():\n",
    "            target_repr_flat = target_encoder(target_blocks_flat)\n",
    "        target_repr = target_repr_flat.view(B, num_targets, -1)\n",
    "\n",
    "        loss = criterion(preds, target_repr)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        update_ema(context_encoder, target_encoder, ema_decay)\n",
    "        running_loss += loss.item() * context_block.size(0)\n",
    "\n",
    "        # --- Visualization for first image of the current batch ---\n",
    "        '''with torch.no_grad():\n",
    "            # Get the first sample's context block and compute its feature vector.\n",
    "            context_img = context_block[0].cpu()  # shape: [C, 224, 224]\n",
    "            context_feat = context_encoder(context_block[0].unsqueeze(0)).cpu().squeeze(0)  # shape: [768]\n",
    "            # Reshape feature vector to a 2D heatmap (24x32).\n",
    "            context_heat = context_feat.view(24, 32).numpy()\n",
    "\n",
    "            # For target, choose the first target block of the first sample.\n",
    "            target_img = target_blocks[0][0].cpu()  # shape: [C, 224, 224]\n",
    "            target_feat = target_encoder(target_blocks[0][0].unsqueeze(0).to(context_block.device)).cpu().squeeze(0)\n",
    "            target_heat = target_feat.view(24, 32).numpy()\n",
    "\n",
    "            # Plot the images and corresponding heatmaps.\n",
    "            fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "            # Display context block image.\n",
    "            if context_img.shape[0] == 1:\n",
    "                axs[0, 0].imshow(context_img.squeeze(), cmap='gray')\n",
    "            else:\n",
    "                axs[0, 0].imshow(context_img.permute(1, 2, 0))\n",
    "            axs[0, 0].set_title(\"Context Block\")\n",
    "            axs[0, 0].axis(\"off\")\n",
    "\n",
    "            # Display context feature heatmap.\n",
    "            im0 = axs[0, 1].imshow(context_heat, cmap=\"viridis\")\n",
    "            axs[0, 1].set_title(\"Context Feature Heatmap\")\n",
    "            axs[0, 1].axis(\"off\")\n",
    "            fig.colorbar(im0, ax=axs[0, 1])\n",
    "\n",
    "            # Display target block image.\n",
    "            if target_img.shape[0] == 1:\n",
    "                axs[1, 0].imshow(target_img.squeeze(), cmap='gray')\n",
    "            else:\n",
    "                axs[1, 0].imshow(target_img.permute(1, 2, 0))\n",
    "            axs[1, 0].set_title(\"Target Block\")\n",
    "            axs[1, 0].axis(\"off\")\n",
    "\n",
    "            # Display target feature heatmap.\n",
    "            im1 = axs[1, 1].imshow(target_heat, cmap=\"viridis\")\n",
    "            axs[1, 1].set_title(\"Target Feature Heatmap\")\n",
    "            axs[1, 1].axis(\"off\")\n",
    "            fig.colorbar(im1, ax=axs[1, 1])\n",
    "\n",
    "            # Save the visualization figure with epoch and batch number.\n",
    "            viz_path = os.path.join(viz_dir, f\"epoch{epoch+1}_batch{batch_idx+1}.png\")\n",
    "            plt.savefig(viz_path)\n",
    "            plt.close(fig)'''\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset_aav_ijepa)\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.10f} - Epoch Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # Save checkpoint if current epoch loss is lower than previous best.\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'context_encoder_state_dict': context_encoder.state_dict(),\n",
    "            'target_encoder_state_dict': target_encoder.state_dict(),\n",
    "            'predictor_state_dict': predictor.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': epoch_loss\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(base_dir,\"ijepa_checkpoint_best.pth\"))\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1} with loss {epoch_loss:.4f}\")\n",
    "\n",
    "\n",
    "total_train_time = time.time() - total_start_time\n",
    "print(f\"Total Training Time: {total_train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2fe3e",
   "metadata": {
    "id": "clZWxsbpZ9EO",
    "papermill": {
     "duration": 0.57814,
     "end_time": "2025-04-03T12:14:59.473475",
     "exception": false,
     "start_time": "2025-04-03T12:14:58.895335",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e628605",
   "metadata": {
    "id": "GQnzVW9aaDL4",
    "papermill": {
     "duration": 0.576548,
     "end_time": "2025-04-03T12:15:00.708681",
     "exception": false,
     "start_time": "2025-04-03T12:15:00.132133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Load the Saved Checkpoint for the Self-Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "501c8eb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:15:01.961904Z",
     "iopub.status.busy": "2025-04-03T12:15:01.961526Z",
     "iopub.status.idle": "2025-04-03T12:15:03.043556Z",
     "shell.execute_reply": "2025-04-03T12:15:03.042628Z"
    },
    "id": "TXG_-3UPaHTE",
    "papermill": {
     "duration": 1.737414,
     "end_time": "2025-04-03T12:15:03.045148",
     "exception": false,
     "start_time": "2025-04-03T12:15:01.307734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-c1445deed640>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(os.path.join(base_dir, \"ijepa_checkpoint_best.pth\"))\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(base_dir, \"ijepa_checkpoint_best.pth\"))\n",
    "context_encoder.load_state_dict(checkpoint['context_encoder_state_dict'])\n",
    "# Freeze the context encoder.\n",
    "context_encoder.eval()\n",
    "for param in context_encoder.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffc135f",
   "metadata": {
    "id": "W4p4tYAraGVn",
    "papermill": {
     "duration": 0.576786,
     "end_time": "2025-04-03T12:15:04.399627",
     "exception": false,
     "start_time": "2025-04-03T12:15:03.822841",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Define the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bc07c69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:15:05.656434Z",
     "iopub.status.busy": "2025-04-03T12:15:05.656138Z",
     "iopub.status.idle": "2025-04-03T12:15:05.660393Z",
     "shell.execute_reply": "2025-04-03T12:15:05.659680Z"
    },
    "id": "rGFXEjdsaOW1",
    "papermill": {
     "duration": 0.600981,
     "end_time": "2025-04-03T12:15:05.661583",
     "exception": false,
     "start_time": "2025-04-03T12:15:05.060602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_classes = 3  # Adjust this number based on your dataset.\n",
    "classifier = nn.Linear(768, num_classes).cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a9722",
   "metadata": {
    "id": "X0ZKbi8UaQig",
    "papermill": {
     "duration": 0.671516,
     "end_time": "2025-04-03T12:15:06.921959",
     "exception": false,
     "start_time": "2025-04-03T12:15:06.250443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Set Up Optimizer and Loss Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f2f9cef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:15:08.161549Z",
     "iopub.status.busy": "2025-04-03T12:15:08.161210Z",
     "iopub.status.idle": "2025-04-03T12:15:08.165364Z",
     "shell.execute_reply": "2025-04-03T12:15:08.164310Z"
    },
    "id": "R19laeJNaTp9",
    "papermill": {
     "duration": 0.662871,
     "end_time": "2025-04-03T12:15:08.166876",
     "exception": false,
     "start_time": "2025-04-03T12:15:07.504005",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf_optimizer = optim.Adam(classifier.parameters(), lr=1e-3)\n",
    "criterion_cls = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e28519",
   "metadata": {
    "id": "1L2khmV-aWGm",
    "papermill": {
     "duration": 0.576008,
     "end_time": "2025-04-03T12:15:09.349173",
     "exception": false,
     "start_time": "2025-04-03T12:15:08.773165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Training Loop for the Classifier (Using Training Data Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a983c2d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T12:15:10.590968Z",
     "iopub.status.busy": "2025-04-03T12:15:10.590607Z",
     "iopub.status.idle": "2025-04-03T14:19:25.504664Z",
     "shell.execute_reply": "2025-04-03T14:19:25.503812Z"
    },
    "id": "3nQoDWvwaZ4g",
    "papermill": {
     "duration": 7456.167539,
     "end_time": "2025-04-03T14:19:26.092199",
     "exception": false,
     "start_time": "2025-04-03T12:15:09.924660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Train Loss: 35.3247123539 | Train Acc: 41.3989426596% | Time: 17.46s\n",
      "Checkpoint saved at epoch 1 with Train Acc: 41.3989426596%\n",
      "Epoch 2/500 - Train Loss: 35.6016814446 | Train Acc: 40.1789345262% | Time: 14.94s\n",
      "Epoch 3/500 - Train Loss: 34.9700855559 | Train Acc: 42.4562830419% | Time: 14.98s\n",
      "Checkpoint saved at epoch 3 with Train Acc: 42.4562830419%\n",
      "Epoch 4/500 - Train Loss: 34.9525565791 | Train Acc: 42.0089467263% | Time: 14.95s\n",
      "Epoch 5/500 - Train Loss: 34.5196446134 | Train Acc: 44.4489629931% | Time: 14.99s\n",
      "Checkpoint saved at epoch 5 with Train Acc: 44.4489629931%\n",
      "Epoch 6/500 - Train Loss: 35.3358164964 | Train Acc: 42.8629524197% | Time: 14.95s\n",
      "Epoch 7/500 - Train Loss: 35.1088398478 | Train Acc: 41.8869459130% | Time: 14.95s\n",
      "Epoch 8/500 - Train Loss: 34.9299192382 | Train Acc: 40.9516063440% | Time: 14.90s\n",
      "Epoch 9/500 - Train Loss: 35.6973246259 | Train Acc: 40.2602684018% | Time: 14.97s\n",
      "Epoch 10/500 - Train Loss: 35.0103146751 | Train Acc: 41.7649450996% | Time: 14.91s\n",
      "Epoch 11/500 - Train Loss: 34.6409890621 | Train Acc: 43.1476209841% | Time: 14.92s\n",
      "Epoch 12/500 - Train Loss: 34.7931857558 | Train Acc: 41.6022773485% | Time: 14.92s\n",
      "Epoch 13/500 - Train Loss: 35.5584921992 | Train Acc: 41.5616104107% | Time: 14.92s\n",
      "Epoch 14/500 - Train Loss: 34.5647855161 | Train Acc: 43.3916226108% | Time: 14.91s\n",
      "Epoch 15/500 - Train Loss: 35.8190500380 | Train Acc: 39.2029280195% | Time: 14.95s\n",
      "Epoch 16/500 - Train Loss: 35.4891174629 | Train Acc: 40.8702724685% | Time: 14.92s\n",
      "Epoch 17/500 - Train Loss: 35.1418868892 | Train Acc: 41.4802765352% | Time: 14.93s\n",
      "Epoch 18/500 - Train Loss: 34.7246815957 | Train Acc: 43.4322895486% | Time: 14.92s\n",
      "Epoch 19/500 - Train Loss: 34.6675600139 | Train Acc: 43.1882879219% | Time: 14.90s\n",
      "Epoch 20/500 - Train Loss: 34.8033778946 | Train Acc: 41.9276128508% | Time: 14.93s\n",
      "Epoch 21/500 - Train Loss: 35.1047481438 | Train Acc: 40.3416022773% | Time: 14.98s\n",
      "Epoch 22/500 - Train Loss: 35.2325132698 | Train Acc: 42.7002846686% | Time: 14.91s\n",
      "Epoch 23/500 - Train Loss: 35.7977143634 | Train Acc: 41.0329402196% | Time: 14.89s\n",
      "Epoch 24/500 - Train Loss: 35.0567443526 | Train Acc: 41.0736071574% | Time: 14.90s\n",
      "Epoch 25/500 - Train Loss: 35.6046572831 | Train Acc: 39.5282635218% | Time: 14.89s\n",
      "Epoch 26/500 - Train Loss: 35.0685403006 | Train Acc: 40.4636030907% | Time: 14.90s\n",
      "Epoch 27/500 - Train Loss: 34.8496195945 | Train Acc: 43.4322895486% | Time: 14.98s\n",
      "Epoch 28/500 - Train Loss: 34.9952144437 | Train Acc: 42.1309475397% | Time: 14.94s\n",
      "Epoch 29/500 - Train Loss: 35.1340505597 | Train Acc: 41.5616104107% | Time: 14.93s\n",
      "Epoch 30/500 - Train Loss: 35.8277200894 | Train Acc: 40.5856039040% | Time: 14.94s\n",
      "Epoch 31/500 - Train Loss: 35.2577595262 | Train Acc: 42.2936152908% | Time: 14.92s\n",
      "Epoch 32/500 - Train Loss: 35.0890785223 | Train Acc: 42.7409516063% | Time: 14.90s\n",
      "Epoch 33/500 - Train Loss: 34.9611116075 | Train Acc: 41.9276128508% | Time: 14.91s\n",
      "Epoch 34/500 - Train Loss: 34.5079083938 | Train Acc: 43.7982919886% | Time: 14.93s\n",
      "Epoch 35/500 - Train Loss: 35.1556128589 | Train Acc: 41.7649450996% | Time: 14.92s\n",
      "Epoch 36/500 - Train Loss: 34.8892063135 | Train Acc: 43.3916226108% | Time: 14.89s\n",
      "Epoch 37/500 - Train Loss: 35.2182665367 | Train Acc: 41.9682797885% | Time: 14.93s\n",
      "Epoch 38/500 - Train Loss: 35.3714448632 | Train Acc: 39.4875965840% | Time: 14.88s\n",
      "Epoch 39/500 - Train Loss: 34.9163649299 | Train Acc: 41.1956079707% | Time: 14.90s\n",
      "Epoch 40/500 - Train Loss: 34.7288478706 | Train Acc: 43.8389589264% | Time: 14.89s\n",
      "Epoch 41/500 - Train Loss: 35.5034722554 | Train Acc: 40.2196014640% | Time: 14.93s\n",
      "Epoch 42/500 - Train Loss: 35.1213894037 | Train Acc: 41.7242781619% | Time: 14.89s\n",
      "Epoch 43/500 - Train Loss: 35.8192328524 | Train Acc: 40.6262708418% | Time: 14.89s\n",
      "Epoch 44/500 - Train Loss: 34.5879813618 | Train Acc: 44.0016266775% | Time: 14.88s\n",
      "Epoch 45/500 - Train Loss: 35.2075153295 | Train Acc: 42.2936152908% | Time: 14.90s\n",
      "Epoch 46/500 - Train Loss: 35.6260066203 | Train Acc: 41.1549410329% | Time: 14.89s\n",
      "Epoch 47/500 - Train Loss: 36.6261906608 | Train Acc: 39.6095973973% | Time: 14.88s\n",
      "Epoch 48/500 - Train Loss: 34.8055309305 | Train Acc: 42.7816185441% | Time: 14.88s\n",
      "Epoch 49/500 - Train Loss: 35.2493507042 | Train Acc: 40.1789345262% | Time: 14.90s\n",
      "Epoch 50/500 - Train Loss: 34.8875428129 | Train Acc: 44.1236274908% | Time: 14.89s\n",
      "Epoch 51/500 - Train Loss: 35.5995049724 | Train Acc: 39.1622610817% | Time: 14.89s\n",
      "Epoch 52/500 - Train Loss: 34.9196099198 | Train Acc: 42.4156161041% | Time: 14.88s\n",
      "Epoch 53/500 - Train Loss: 35.0777448060 | Train Acc: 42.8629524197% | Time: 14.89s\n",
      "Epoch 54/500 - Train Loss: 34.8561195104 | Train Acc: 42.7409516063% | Time: 14.92s\n",
      "Epoch 55/500 - Train Loss: 35.5522571771 | Train Acc: 41.9276128508% | Time: 14.89s\n",
      "Epoch 56/500 - Train Loss: 35.0654907366 | Train Acc: 41.5209434730% | Time: 14.90s\n",
      "Epoch 57/500 - Train Loss: 35.0691036791 | Train Acc: 40.9922732818% | Time: 14.88s\n",
      "Epoch 58/500 - Train Loss: 35.8789989871 | Train Acc: 38.2269215128% | Time: 14.90s\n",
      "Epoch 59/500 - Train Loss: 34.9030323083 | Train Acc: 42.3749491663% | Time: 14.88s\n",
      "Epoch 60/500 - Train Loss: 35.1840142135 | Train Acc: 43.1069540464% | Time: 14.92s\n",
      "Epoch 61/500 - Train Loss: 34.9858016379 | Train Acc: 43.4729564864% | Time: 14.88s\n",
      "Epoch 62/500 - Train Loss: 34.9394577556 | Train Acc: 41.7242781619% | Time: 14.90s\n",
      "Epoch 63/500 - Train Loss: 35.4351729758 | Train Acc: 40.3822692151% | Time: 14.90s\n",
      "Epoch 64/500 - Train Loss: 34.8640805328 | Train Acc: 41.8869459130% | Time: 14.91s\n",
      "Epoch 65/500 - Train Loss: 34.9788280307 | Train Acc: 42.6596177308% | Time: 14.88s\n",
      "Epoch 66/500 - Train Loss: 35.9490272194 | Train Acc: 39.3655957706% | Time: 14.89s\n",
      "Epoch 67/500 - Train Loss: 34.9364937435 | Train Acc: 41.6022773485% | Time: 14.91s\n",
      "Epoch 68/500 - Train Loss: 34.5999156237 | Train Acc: 42.4969499797% | Time: 14.89s\n",
      "Epoch 69/500 - Train Loss: 34.6628299147 | Train Acc: 42.5376169174% | Time: 14.93s\n",
      "Epoch 70/500 - Train Loss: 35.0777166014 | Train Acc: 42.1716144774% | Time: 14.89s\n",
      "Epoch 71/500 - Train Loss: 35.9111051080 | Train Acc: 38.5115900773% | Time: 14.90s\n",
      "Epoch 72/500 - Train Loss: 34.8712540757 | Train Acc: 43.1069540464% | Time: 14.88s\n",
      "Epoch 73/500 - Train Loss: 34.8608427326 | Train Acc: 42.8222854819% | Time: 14.92s\n",
      "Epoch 74/500 - Train Loss: 35.2897778424 | Train Acc: 40.8296055307% | Time: 14.87s\n",
      "Epoch 75/500 - Train Loss: 34.7470339722 | Train Acc: 43.8796258642% | Time: 14.92s\n",
      "Epoch 76/500 - Train Loss: 35.5985009902 | Train Acc: 40.7076047174% | Time: 14.88s\n",
      "Epoch 77/500 - Train Loss: 34.7172559802 | Train Acc: 44.8149654331% | Time: 14.90s\n",
      "Checkpoint saved at epoch 77 with Train Acc: 44.8149654331%\n",
      "Epoch 78/500 - Train Loss: 34.6575277641 | Train Acc: 44.4082960553% | Time: 14.88s\n",
      "Epoch 79/500 - Train Loss: 34.7539338493 | Train Acc: 42.8222854819% | Time: 14.94s\n",
      "Epoch 80/500 - Train Loss: 36.1424935917 | Train Acc: 36.3969093127% | Time: 14.91s\n",
      "Epoch 81/500 - Train Loss: 35.0303940107 | Train Acc: 43.2696217975% | Time: 14.89s\n",
      "Epoch 82/500 - Train Loss: 35.6846704684 | Train Acc: 40.0569337129% | Time: 14.89s\n",
      "Epoch 83/500 - Train Loss: 35.8766994383 | Train Acc: 40.7482716551% | Time: 14.88s\n",
      "Epoch 84/500 - Train Loss: 35.4958576413 | Train Acc: 41.7649450996% | Time: 14.94s\n",
      "Epoch 85/500 - Train Loss: 34.9619147120 | Train Acc: 42.0089467263% | Time: 14.91s\n",
      "Epoch 86/500 - Train Loss: 34.9328312866 | Train Acc: 43.3102887353% | Time: 14.91s\n",
      "Epoch 87/500 - Train Loss: 34.9228137252 | Train Acc: 42.0902806019% | Time: 14.91s\n",
      "Epoch 88/500 - Train Loss: 35.3241271957 | Train Acc: 41.1549410329% | Time: 14.95s\n",
      "Epoch 89/500 - Train Loss: 34.8909524911 | Train Acc: 43.1069540464% | Time: 14.88s\n",
      "Epoch 90/500 - Train Loss: 35.2361283658 | Train Acc: 42.8629524197% | Time: 14.88s\n",
      "Epoch 91/500 - Train Loss: 35.3142360666 | Train Acc: 40.5856039040% | Time: 14.88s\n",
      "Epoch 92/500 - Train Loss: 35.6613604357 | Train Acc: 39.6502643351% | Time: 14.90s\n",
      "Epoch 93/500 - Train Loss: 34.6840317064 | Train Acc: 43.3102887353% | Time: 14.90s\n",
      "Epoch 94/500 - Train Loss: 35.1054314746 | Train Acc: 42.4156161041% | Time: 14.90s\n",
      "Epoch 95/500 - Train Loss: 35.5201130424 | Train Acc: 40.3416022773% | Time: 14.89s\n",
      "Epoch 96/500 - Train Loss: 34.8806504367 | Train Acc: 43.2696217975% | Time: 14.89s\n",
      "Epoch 97/500 - Train Loss: 35.3568983063 | Train Acc: 39.9349328996% | Time: 14.89s\n",
      "Epoch 98/500 - Train Loss: 35.7298370259 | Train Acc: 38.7149247662% | Time: 14.88s\n",
      "Epoch 99/500 - Train Loss: 34.6813825725 | Train Acc: 45.0589670598% | Time: 14.94s\n",
      "Checkpoint saved at epoch 99 with Train Acc: 45.0589670598%\n",
      "Epoch 100/500 - Train Loss: 35.3512323476 | Train Acc: 40.6262708418% | Time: 14.89s\n",
      "Epoch 101/500 - Train Loss: 35.6122927232 | Train Acc: 40.6669377796% | Time: 14.92s\n",
      "Epoch 102/500 - Train Loss: 35.4532966149 | Train Acc: 39.8535990240% | Time: 14.91s\n",
      "Epoch 103/500 - Train Loss: 35.6305423170 | Train Acc: 41.2769418463% | Time: 14.93s\n",
      "Epoch 104/500 - Train Loss: 34.6770029997 | Train Acc: 43.3916226108% | Time: 14.88s\n",
      "Epoch 105/500 - Train Loss: 34.9895324552 | Train Acc: 43.5136234242% | Time: 14.96s\n",
      "Epoch 106/500 - Train Loss: 35.2433725425 | Train Acc: 42.0496136641% | Time: 14.88s\n",
      "Epoch 107/500 - Train Loss: 34.8324650518 | Train Acc: 43.2696217975% | Time: 14.91s\n",
      "Epoch 108/500 - Train Loss: 35.2061215608 | Train Acc: 40.2602684018% | Time: 14.92s\n",
      "Epoch 109/500 - Train Loss: 34.8839734390 | Train Acc: 41.8056120374% | Time: 14.95s\n",
      "Epoch 110/500 - Train Loss: 34.7447622860 | Train Acc: 43.1069540464% | Time: 14.89s\n",
      "Epoch 111/500 - Train Loss: 34.8126034442 | Train Acc: 42.5376169174% | Time: 14.94s\n",
      "Epoch 112/500 - Train Loss: 35.2715162472 | Train Acc: 41.0736071574% | Time: 14.92s\n",
      "Epoch 113/500 - Train Loss: 34.8126732343 | Train Acc: 42.7816185441% | Time: 14.89s\n",
      "Epoch 114/500 - Train Loss: 35.5276236673 | Train Acc: 42.1716144774% | Time: 14.90s\n",
      "Epoch 115/500 - Train Loss: 34.9595090848 | Train Acc: 41.6022773485% | Time: 14.89s\n",
      "Epoch 116/500 - Train Loss: 34.9206555199 | Train Acc: 43.3916226108% | Time: 14.89s\n",
      "Epoch 117/500 - Train Loss: 34.7949549254 | Train Acc: 42.6189507930% | Time: 14.90s\n",
      "Epoch 118/500 - Train Loss: 35.3202590617 | Train Acc: 40.6669377796% | Time: 14.89s\n",
      "Epoch 119/500 - Train Loss: 34.9503521284 | Train Acc: 41.5616104107% | Time: 14.92s\n",
      "Epoch 120/500 - Train Loss: 34.8829370412 | Train Acc: 44.2862952420% | Time: 14.93s\n",
      "Epoch 121/500 - Train Loss: 35.2018818840 | Train Acc: 39.8129320862% | Time: 14.90s\n",
      "Epoch 122/500 - Train Loss: 34.7961607722 | Train Acc: 44.2862952420% | Time: 14.93s\n",
      "Epoch 123/500 - Train Loss: 35.4324143359 | Train Acc: 40.7889385929% | Time: 14.91s\n",
      "Epoch 124/500 - Train Loss: 34.7140978606 | Train Acc: 43.5949572997% | Time: 14.90s\n",
      "Epoch 125/500 - Train Loss: 34.7623846330 | Train Acc: 42.6189507930% | Time: 14.89s\n",
      "Epoch 126/500 - Train Loss: 34.6274726406 | Train Acc: 44.1236274908% | Time: 14.92s\n",
      "Epoch 127/500 - Train Loss: 34.9744015762 | Train Acc: 42.3342822285% | Time: 14.89s\n",
      "Epoch 128/500 - Train Loss: 34.9965860983 | Train Acc: 43.0256201708% | Time: 14.90s\n",
      "Epoch 129/500 - Train Loss: 34.7061837014 | Train Acc: 44.4489629931% | Time: 14.92s\n",
      "Epoch 130/500 - Train Loss: 34.9868939728 | Train Acc: 41.2769418463% | Time: 14.90s\n",
      "Epoch 131/500 - Train Loss: 34.9714683480 | Train Acc: 44.2049613664% | Time: 14.92s\n",
      "Epoch 132/500 - Train Loss: 35.0386698710 | Train Acc: 41.7242781619% | Time: 14.89s\n",
      "Epoch 133/500 - Train Loss: 34.7412161456 | Train Acc: 44.4082960553% | Time: 14.90s\n",
      "Epoch 134/500 - Train Loss: 35.0189705189 | Train Acc: 42.7002846686% | Time: 14.88s\n",
      "Epoch 135/500 - Train Loss: 35.1918395494 | Train Acc: 40.5449369662% | Time: 14.88s\n",
      "Epoch 136/500 - Train Loss: 35.2757743396 | Train Acc: 40.7482716551% | Time: 14.89s\n",
      "Epoch 137/500 - Train Loss: 35.1821521908 | Train Acc: 42.2122814152% | Time: 14.91s\n",
      "Epoch 138/500 - Train Loss: 35.1188148694 | Train Acc: 43.3916226108% | Time: 14.88s\n",
      "Epoch 139/500 - Train Loss: 35.0834715877 | Train Acc: 41.7242781619% | Time: 14.92s\n",
      "Epoch 140/500 - Train Loss: 34.4611208749 | Train Acc: 45.5063033754% | Time: 14.90s\n",
      "Checkpoint saved at epoch 140 with Train Acc: 45.5063033754%\n",
      "Epoch 141/500 - Train Loss: 35.0956968503 | Train Acc: 42.5782838552% | Time: 14.94s\n",
      "Epoch 142/500 - Train Loss: 35.9179318617 | Train Acc: 38.6742578284% | Time: 14.89s\n",
      "Epoch 143/500 - Train Loss: 34.8371869527 | Train Acc: 42.4156161041% | Time: 14.90s\n",
      "Epoch 144/500 - Train Loss: 35.1755426425 | Train Acc: 42.7409516063% | Time: 14.90s\n",
      "Epoch 145/500 - Train Loss: 35.0625798532 | Train Acc: 41.8462789752% | Time: 14.89s\n",
      "Epoch 146/500 - Train Loss: 35.1101878069 | Train Acc: 42.1309475397% | Time: 15.02s\n",
      "Epoch 147/500 - Train Loss: 34.9623070537 | Train Acc: 41.4396095974% | Time: 14.89s\n",
      "Epoch 148/500 - Train Loss: 35.4722795951 | Train Acc: 39.4875965840% | Time: 14.90s\n",
      "Epoch 149/500 - Train Loss: 35.0991539274 | Train Acc: 43.1476209841% | Time: 14.90s\n",
      "Epoch 150/500 - Train Loss: 36.1436032537 | Train Acc: 40.0162667751% | Time: 14.91s\n",
      "Epoch 151/500 - Train Loss: 34.7541435911 | Train Acc: 42.1716144774% | Time: 14.90s\n",
      "Epoch 152/500 - Train Loss: 35.3648982900 | Train Acc: 39.8942659618% | Time: 14.92s\n",
      "Epoch 153/500 - Train Loss: 36.3165176813 | Train Acc: 40.3416022773% | Time: 14.91s\n",
      "Epoch 154/500 - Train Loss: 35.0233881257 | Train Acc: 40.8702724685% | Time: 14.94s\n",
      "Epoch 155/500 - Train Loss: 35.0218464678 | Train Acc: 41.1956079707% | Time: 14.90s\n",
      "Epoch 156/500 - Train Loss: 34.9160276125 | Train Acc: 44.3269621797% | Time: 14.93s\n",
      "Epoch 157/500 - Train Loss: 36.0207886216 | Train Acc: 40.5449369662% | Time: 14.89s\n",
      "Epoch 158/500 - Train Loss: 35.0782229730 | Train Acc: 41.8056120374% | Time: 14.90s\n",
      "Epoch 159/500 - Train Loss: 35.0757011469 | Train Acc: 43.1069540464% | Time: 14.92s\n",
      "Epoch 160/500 - Train Loss: 34.5603126566 | Train Acc: 43.2289548597% | Time: 14.88s\n",
      "Epoch 161/500 - Train Loss: 35.2909446444 | Train Acc: 40.7482716551% | Time: 14.88s\n",
      "Epoch 162/500 - Train Loss: 34.7272862180 | Train Acc: 43.3102887353% | Time: 14.88s\n",
      "Epoch 163/500 - Train Loss: 35.2100642153 | Train Acc: 41.1956079707% | Time: 14.90s\n",
      "Epoch 164/500 - Train Loss: 34.9955482034 | Train Acc: 43.2289548597% | Time: 14.87s\n",
      "Epoch 165/500 - Train Loss: 35.2404522524 | Train Acc: 42.0496136641% | Time: 14.91s\n",
      "Epoch 166/500 - Train Loss: 34.7966172200 | Train Acc: 43.3102887353% | Time: 14.89s\n",
      "Epoch 167/500 - Train Loss: 35.9875585228 | Train Acc: 40.5042700285% | Time: 14.90s\n",
      "Epoch 168/500 - Train Loss: 37.3698635999 | Train Acc: 38.6742578284% | Time: 14.89s\n",
      "Epoch 169/500 - Train Loss: 35.3245319840 | Train Acc: 40.8702724685% | Time: 14.89s\n",
      "Epoch 170/500 - Train Loss: 34.7752406009 | Train Acc: 42.7002846686% | Time: 14.89s\n",
      "Epoch 171/500 - Train Loss: 36.0646388399 | Train Acc: 39.9755998373% | Time: 14.89s\n",
      "Epoch 172/500 - Train Loss: 35.1739899710 | Train Acc: 40.5042700285% | Time: 14.88s\n",
      "Epoch 173/500 - Train Loss: 34.5704569879 | Train Acc: 43.9609597397% | Time: 14.89s\n",
      "Epoch 174/500 - Train Loss: 35.4592367101 | Train Acc: 42.1716144774% | Time: 14.90s\n",
      "Epoch 175/500 - Train Loss: 34.5932348967 | Train Acc: 42.7409516063% | Time: 14.93s\n",
      "Epoch 176/500 - Train Loss: 35.5466790091 | Train Acc: 40.0976006507% | Time: 14.94s\n",
      "Epoch 177/500 - Train Loss: 35.3970423921 | Train Acc: 39.5689304595% | Time: 14.91s\n",
      "Epoch 178/500 - Train Loss: 34.8773023308 | Train Acc: 43.2696217975% | Time: 14.95s\n",
      "Epoch 179/500 - Train Loss: 35.3229759591 | Train Acc: 42.1716144774% | Time: 14.90s\n",
      "Epoch 180/500 - Train Loss: 34.8123234867 | Train Acc: 41.6836112241% | Time: 14.90s\n",
      "Epoch 181/500 - Train Loss: 35.2054689240 | Train Acc: 41.1549410329% | Time: 14.92s\n",
      "Epoch 182/500 - Train Loss: 34.6467790681 | Train Acc: 44.8962993087% | Time: 14.90s\n",
      "Epoch 183/500 - Train Loss: 35.1169008079 | Train Acc: 44.1642944286% | Time: 14.93s\n",
      "Epoch 184/500 - Train Loss: 35.1137803638 | Train Acc: 41.2362749085% | Time: 14.90s\n",
      "Epoch 185/500 - Train Loss: 34.6955436158 | Train Acc: 42.9036193575% | Time: 14.89s\n",
      "Epoch 186/500 - Train Loss: 35.4779602274 | Train Acc: 39.8535990240% | Time: 14.92s\n",
      "Epoch 187/500 - Train Loss: 35.1580912045 | Train Acc: 42.9036193575% | Time: 14.88s\n",
      "Epoch 188/500 - Train Loss: 35.2398607328 | Train Acc: 42.5782838552% | Time: 14.89s\n",
      "Epoch 189/500 - Train Loss: 36.6041731912 | Train Acc: 39.4875965840% | Time: 14.89s\n",
      "Epoch 190/500 - Train Loss: 35.5160698086 | Train Acc: 39.9755998373% | Time: 14.89s\n",
      "Epoch 191/500 - Train Loss: 35.3590474268 | Train Acc: 40.0162667751% | Time: 14.94s\n",
      "Epoch 192/500 - Train Loss: 34.6672426648 | Train Acc: 43.8796258642% | Time: 14.91s\n",
      "Epoch 193/500 - Train Loss: 34.8841394434 | Train Acc: 42.0496136641% | Time: 14.91s\n",
      "Epoch 194/500 - Train Loss: 34.8105171005 | Train Acc: 43.1069540464% | Time: 14.91s\n",
      "Epoch 195/500 - Train Loss: 35.2759136705 | Train Acc: 42.4156161041% | Time: 14.90s\n",
      "Epoch 196/500 - Train Loss: 34.7957014263 | Train Acc: 41.4802765352% | Time: 14.89s\n",
      "Epoch 197/500 - Train Loss: 34.9159425420 | Train Acc: 42.3342822285% | Time: 14.91s\n",
      "Epoch 198/500 - Train Loss: 34.6125959932 | Train Acc: 44.0422936153% | Time: 14.90s\n",
      "Epoch 199/500 - Train Loss: 35.3312911043 | Train Acc: 40.8702724685% | Time: 14.94s\n",
      "Epoch 200/500 - Train Loss: 35.3407766045 | Train Acc: 42.2936152908% | Time: 14.90s\n",
      "Epoch 201/500 - Train Loss: 35.1719475969 | Train Acc: 42.4969499797% | Time: 14.92s\n",
      "Epoch 202/500 - Train Loss: 34.9037038243 | Train Acc: 43.5949572997% | Time: 14.89s\n",
      "Epoch 203/500 - Train Loss: 35.6993524455 | Train Acc: 41.5209434730% | Time: 14.95s\n",
      "Epoch 204/500 - Train Loss: 35.7189868627 | Train Acc: 38.9995933306% | Time: 14.92s\n",
      "Epoch 205/500 - Train Loss: 36.4525356169 | Train Acc: 39.4875965840% | Time: 14.95s\n",
      "Epoch 206/500 - Train Loss: 34.9889700320 | Train Acc: 43.3102887353% | Time: 14.92s\n",
      "Epoch 207/500 - Train Loss: 35.3097840826 | Train Acc: 40.4229361529% | Time: 14.93s\n",
      "Epoch 208/500 - Train Loss: 34.9613561444 | Train Acc: 42.0089467263% | Time: 14.93s\n",
      "Epoch 209/500 - Train Loss: 35.5441540294 | Train Acc: 41.1549410329% | Time: 14.91s\n",
      "Epoch 210/500 - Train Loss: 34.7980801734 | Train Acc: 44.0016266775% | Time: 14.94s\n",
      "Epoch 211/500 - Train Loss: 35.2012824579 | Train Acc: 41.0329402196% | Time: 14.90s\n",
      "Epoch 212/500 - Train Loss: 35.4705214516 | Train Acc: 41.1142740952% | Time: 14.90s\n",
      "Epoch 213/500 - Train Loss: 34.7488217741 | Train Acc: 43.2289548597% | Time: 14.90s\n",
      "Epoch 214/500 - Train Loss: 35.0171334983 | Train Acc: 43.0662871086% | Time: 14.90s\n",
      "Epoch 215/500 - Train Loss: 35.6850583847 | Train Acc: 39.9755998373% | Time: 14.89s\n",
      "Epoch 216/500 - Train Loss: 35.2247653905 | Train Acc: 40.9922732818% | Time: 14.93s\n",
      "Epoch 217/500 - Train Loss: 34.6570685916 | Train Acc: 42.6596177308% | Time: 14.92s\n",
      "Epoch 218/500 - Train Loss: 34.8320562360 | Train Acc: 42.9849532330% | Time: 14.93s\n",
      "Epoch 219/500 - Train Loss: 36.0153841709 | Train Acc: 38.7149247662% | Time: 14.89s\n",
      "Epoch 220/500 - Train Loss: 35.2823797728 | Train Acc: 41.1142740952% | Time: 14.93s\n",
      "Epoch 221/500 - Train Loss: 35.0789304662 | Train Acc: 43.5949572997% | Time: 14.90s\n",
      "Epoch 222/500 - Train Loss: 34.8936637346 | Train Acc: 41.8056120374% | Time: 14.89s\n",
      "Epoch 223/500 - Train Loss: 35.2202822264 | Train Acc: 40.5042700285% | Time: 14.92s\n",
      "Epoch 224/500 - Train Loss: 35.2507445859 | Train Acc: 42.0496136641% | Time: 14.91s\n",
      "Epoch 225/500 - Train Loss: 34.9715707287 | Train Acc: 40.9109394063% | Time: 14.93s\n",
      "Epoch 226/500 - Train Loss: 35.4631143390 | Train Acc: 40.6262708418% | Time: 14.97s\n",
      "Epoch 227/500 - Train Loss: 35.0003642951 | Train Acc: 41.6022773485% | Time: 14.92s\n",
      "Epoch 228/500 - Train Loss: 35.5044248305 | Train Acc: 41.6429442863% | Time: 14.91s\n",
      "Epoch 229/500 - Train Loss: 35.3725510681 | Train Acc: 39.8942659618% | Time: 14.89s\n",
      "Epoch 230/500 - Train Loss: 35.0412132554 | Train Acc: 43.0256201708% | Time: 14.89s\n",
      "Epoch 231/500 - Train Loss: 34.9983161703 | Train Acc: 42.1309475397% | Time: 14.91s\n",
      "Epoch 232/500 - Train Loss: 35.1329717621 | Train Acc: 41.3176087841% | Time: 14.92s\n",
      "Epoch 233/500 - Train Loss: 35.8600434715 | Train Acc: 40.7482716551% | Time: 14.92s\n",
      "Epoch 234/500 - Train Loss: 34.7652270206 | Train Acc: 44.1642944286% | Time: 14.91s\n",
      "Epoch 235/500 - Train Loss: 34.8563981552 | Train Acc: 42.7002846686% | Time: 14.97s\n",
      "Epoch 236/500 - Train Loss: 35.0700166442 | Train Acc: 40.9109394063% | Time: 14.89s\n",
      "Epoch 237/500 - Train Loss: 34.7999292039 | Train Acc: 43.0256201708% | Time: 14.90s\n",
      "Epoch 238/500 - Train Loss: 35.0010591606 | Train Acc: 44.0422936153% | Time: 14.90s\n",
      "Epoch 239/500 - Train Loss: 35.7717109330 | Train Acc: 38.7555917039% | Time: 14.91s\n",
      "Epoch 240/500 - Train Loss: 35.2501486602 | Train Acc: 41.6429442863% | Time: 14.98s\n",
      "Epoch 241/500 - Train Loss: 34.7771554272 | Train Acc: 43.4322895486% | Time: 14.90s\n",
      "Epoch 242/500 - Train Loss: 35.0163464074 | Train Acc: 42.7816185441% | Time: 14.95s\n",
      "Epoch 243/500 - Train Loss: 35.2162888104 | Train Acc: 42.5376169174% | Time: 14.88s\n",
      "Epoch 244/500 - Train Loss: 34.6962784807 | Train Acc: 43.3102887353% | Time: 14.91s\n",
      "Epoch 245/500 - Train Loss: 35.2621518730 | Train Acc: 42.6189507930% | Time: 14.88s\n",
      "Epoch 246/500 - Train Loss: 35.0188984112 | Train Acc: 42.7816185441% | Time: 14.91s\n",
      "Epoch 247/500 - Train Loss: 35.0024057580 | Train Acc: 41.8869459130% | Time: 14.88s\n",
      "Epoch 248/500 - Train Loss: 35.3560339816 | Train Acc: 41.1142740952% | Time: 14.94s\n",
      "Epoch 249/500 - Train Loss: 35.3431474094 | Train Acc: 41.8462789752% | Time: 14.87s\n",
      "Epoch 250/500 - Train Loss: 34.9248652737 | Train Acc: 41.2362749085% | Time: 14.93s\n",
      "Epoch 251/500 - Train Loss: 34.6581926826 | Train Acc: 43.9202928020% | Time: 14.91s\n",
      "Epoch 252/500 - Train Loss: 34.8071671384 | Train Acc: 42.6189507930% | Time: 14.91s\n",
      "Epoch 253/500 - Train Loss: 35.4803670289 | Train Acc: 41.1549410329% | Time: 14.90s\n",
      "Epoch 254/500 - Train Loss: 34.7518197267 | Train Acc: 43.3509556730% | Time: 14.88s\n",
      "Epoch 255/500 - Train Loss: 34.8434954293 | Train Acc: 42.3342822285% | Time: 14.92s\n",
      "Epoch 256/500 - Train Loss: 34.5618841338 | Train Acc: 43.0256201708% | Time: 14.96s\n",
      "Epoch 257/500 - Train Loss: 34.9769219129 | Train Acc: 42.7002846686% | Time: 14.94s\n",
      "Epoch 258/500 - Train Loss: 34.6089454580 | Train Acc: 43.7169581131% | Time: 14.88s\n",
      "Epoch 259/500 - Train Loss: 34.8617639278 | Train Acc: 43.8389589264% | Time: 14.97s\n",
      "Epoch 260/500 - Train Loss: 34.7460800905 | Train Acc: 43.1069540464% | Time: 14.89s\n",
      "Epoch 261/500 - Train Loss: 35.5811850251 | Train Acc: 41.8056120374% | Time: 14.90s\n",
      "Epoch 262/500 - Train Loss: 35.4848300281 | Train Acc: 41.3582757218% | Time: 14.91s\n",
      "Epoch 263/500 - Train Loss: 34.5722516713 | Train Acc: 43.5542903619% | Time: 14.94s\n",
      "Epoch 264/500 - Train Loss: 35.6000477091 | Train Acc: 39.0402602684% | Time: 14.90s\n",
      "Epoch 265/500 - Train Loss: 35.0559702214 | Train Acc: 41.6022773485% | Time: 14.95s\n",
      "Epoch 266/500 - Train Loss: 34.6426842584 | Train Acc: 42.5376169174% | Time: 14.87s\n",
      "Epoch 267/500 - Train Loss: 35.3989086430 | Train Acc: 40.9516063440% | Time: 14.89s\n",
      "Epoch 268/500 - Train Loss: 35.8534367503 | Train Acc: 38.3895892639% | Time: 14.88s\n",
      "Epoch 269/500 - Train Loss: 35.6576170906 | Train Acc: 39.8535990240% | Time: 14.88s\n",
      "Epoch 270/500 - Train Loss: 34.9435086266 | Train Acc: 44.0016266775% | Time: 14.94s\n",
      "Epoch 271/500 - Train Loss: 34.6043594967 | Train Acc: 44.5302968686% | Time: 14.89s\n",
      "Epoch 272/500 - Train Loss: 35.1030053148 | Train Acc: 41.3989426596% | Time: 14.88s\n",
      "Epoch 273/500 - Train Loss: 35.2038211033 | Train Acc: 41.7649450996% | Time: 14.89s\n",
      "Epoch 274/500 - Train Loss: 35.5309270760 | Train Acc: 41.4396095974% | Time: 14.91s\n",
      "Epoch 275/500 - Train Loss: 34.8298050413 | Train Acc: 42.5376169174% | Time: 14.89s\n",
      "Epoch 276/500 - Train Loss: 34.8631112343 | Train Acc: 42.3342822285% | Time: 14.88s\n",
      "Epoch 277/500 - Train Loss: 35.2741464694 | Train Acc: 40.8296055307% | Time: 14.88s\n",
      "Epoch 278/500 - Train Loss: 34.6272866478 | Train Acc: 44.4896299309% | Time: 14.91s\n",
      "Epoch 279/500 - Train Loss: 34.5926383378 | Train Acc: 43.4322895486% | Time: 14.89s\n",
      "Epoch 280/500 - Train Loss: 34.5778154584 | Train Acc: 42.8629524197% | Time: 14.88s\n",
      "Epoch 281/500 - Train Loss: 35.1338797792 | Train Acc: 42.8629524197% | Time: 14.88s\n",
      "Epoch 282/500 - Train Loss: 34.7475323104 | Train Acc: 43.8796258642% | Time: 14.92s\n",
      "Epoch 283/500 - Train Loss: 35.5422428366 | Train Acc: 39.6502643351% | Time: 14.89s\n",
      "Epoch 284/500 - Train Loss: 36.3783822834 | Train Acc: 39.4062627084% | Time: 14.88s\n",
      "Epoch 285/500 - Train Loss: 35.0116870527 | Train Acc: 43.4322895486% | Time: 14.89s\n",
      "Epoch 286/500 - Train Loss: 35.2784491576 | Train Acc: 41.3989426596% | Time: 14.89s\n",
      "Epoch 287/500 - Train Loss: 35.2276611700 | Train Acc: 39.4875965840% | Time: 14.88s\n",
      "Epoch 288/500 - Train Loss: 35.4952084383 | Train Acc: 39.7315982107% | Time: 14.88s\n",
      "Epoch 289/500 - Train Loss: 34.8152465325 | Train Acc: 42.9849532330% | Time: 14.93s\n",
      "Epoch 290/500 - Train Loss: 35.0223511736 | Train Acc: 40.9109394063% | Time: 14.87s\n",
      "Epoch 291/500 - Train Loss: 35.1518089756 | Train Acc: 41.9682797885% | Time: 14.93s\n",
      "Epoch 292/500 - Train Loss: 34.7638422808 | Train Acc: 42.7409516063% | Time: 14.87s\n",
      "Epoch 293/500 - Train Loss: 35.4198181056 | Train Acc: 41.4396095974% | Time: 14.88s\n",
      "Epoch 294/500 - Train Loss: 34.9640405519 | Train Acc: 41.8869459130% | Time: 14.89s\n",
      "Epoch 295/500 - Train Loss: 35.4351120552 | Train Acc: 41.6022773485% | Time: 14.93s\n",
      "Epoch 296/500 - Train Loss: 35.3205055293 | Train Acc: 41.9276128508% | Time: 14.89s\n",
      "Epoch 297/500 - Train Loss: 34.9185692769 | Train Acc: 40.9922732818% | Time: 14.94s\n",
      "Epoch 298/500 - Train Loss: 35.4950057036 | Train Acc: 42.4969499797% | Time: 14.89s\n",
      "Epoch 299/500 - Train Loss: 35.4824507701 | Train Acc: 41.4396095974% | Time: 14.87s\n",
      "Epoch 300/500 - Train Loss: 35.9035076491 | Train Acc: 38.6742578284% | Time: 14.91s\n",
      "Epoch 301/500 - Train Loss: 35.2299567399 | Train Acc: 40.5042700285% | Time: 14.88s\n",
      "Epoch 302/500 - Train Loss: 35.5321556485 | Train Acc: 38.5115900773% | Time: 14.95s\n",
      "Epoch 303/500 - Train Loss: 35.7472127165 | Train Acc: 39.5689304595% | Time: 14.92s\n",
      "Epoch 304/500 - Train Loss: 36.0994095431 | Train Acc: 39.1215941440% | Time: 14.89s\n",
      "Epoch 305/500 - Train Loss: 35.3395880306 | Train Acc: 42.4156161041% | Time: 14.87s\n",
      "Epoch 306/500 - Train Loss: 35.5233765531 | Train Acc: 39.8129320862% | Time: 14.94s\n",
      "Epoch 307/500 - Train Loss: 34.9191423809 | Train Acc: 41.8056120374% | Time: 14.88s\n",
      "Epoch 308/500 - Train Loss: 36.1484004337 | Train Acc: 40.7076047174% | Time: 14.94s\n",
      "Epoch 309/500 - Train Loss: 35.1775792667 | Train Acc: 42.0089467263% | Time: 14.90s\n",
      "Epoch 310/500 - Train Loss: 34.9730470397 | Train Acc: 43.1882879219% | Time: 14.92s\n",
      "Epoch 311/500 - Train Loss: 35.0380049139 | Train Acc: 41.7649450996% | Time: 14.90s\n",
      "Epoch 312/500 - Train Loss: 35.2857904961 | Train Acc: 40.9922732818% | Time: 14.90s\n",
      "Epoch 313/500 - Train Loss: 35.2385539699 | Train Acc: 40.4229361529% | Time: 14.88s\n",
      "Epoch 314/500 - Train Loss: 35.1158825422 | Train Acc: 42.2122814152% | Time: 14.92s\n",
      "Epoch 315/500 - Train Loss: 35.6122169193 | Train Acc: 38.5929239528% | Time: 14.90s\n",
      "Epoch 316/500 - Train Loss: 34.7889535505 | Train Acc: 43.5136234242% | Time: 14.88s\n",
      "Epoch 317/500 - Train Loss: 34.5755411758 | Train Acc: 43.6762911753% | Time: 14.90s\n",
      "Epoch 318/500 - Train Loss: 34.6699521727 | Train Acc: 42.9849532330% | Time: 14.91s\n",
      "Epoch 319/500 - Train Loss: 35.3186857840 | Train Acc: 42.2936152908% | Time: 14.89s\n",
      "Epoch 320/500 - Train Loss: 36.0614557467 | Train Acc: 39.7315982107% | Time: 14.89s\n",
      "Epoch 321/500 - Train Loss: 34.7263584671 | Train Acc: 44.0016266775% | Time: 14.90s\n",
      "Epoch 322/500 - Train Loss: 35.5734218916 | Train Acc: 41.4802765352% | Time: 14.88s\n",
      "Epoch 323/500 - Train Loss: 34.7792830684 | Train Acc: 43.3916226108% | Time: 14.92s\n",
      "Epoch 324/500 - Train Loss: 35.2638080244 | Train Acc: 40.6262708418% | Time: 14.90s\n",
      "Epoch 325/500 - Train Loss: 35.8743193792 | Train Acc: 41.6022773485% | Time: 14.96s\n",
      "Epoch 326/500 - Train Loss: 35.8216706917 | Train Acc: 40.3822692151% | Time: 14.93s\n",
      "Epoch 327/500 - Train Loss: 35.2434774606 | Train Acc: 43.4729564864% | Time: 14.90s\n",
      "Epoch 328/500 - Train Loss: 34.7344537401 | Train Acc: 42.1716144774% | Time: 14.89s\n",
      "Epoch 329/500 - Train Loss: 35.2045091081 | Train Acc: 40.8296055307% | Time: 14.89s\n",
      "Epoch 330/500 - Train Loss: 35.9133548071 | Train Acc: 41.8056120374% | Time: 14.90s\n",
      "Epoch 331/500 - Train Loss: 35.5787511483 | Train Acc: 40.5042700285% | Time: 14.90s\n",
      "Epoch 332/500 - Train Loss: 35.3498681025 | Train Acc: 40.7076047174% | Time: 14.94s\n",
      "Epoch 333/500 - Train Loss: 35.1780409271 | Train Acc: 40.0162667751% | Time: 14.92s\n",
      "Epoch 334/500 - Train Loss: 34.7109103373 | Train Acc: 42.9442862952% | Time: 14.93s\n",
      "Epoch 335/500 - Train Loss: 35.0530196630 | Train Acc: 40.3009353396% | Time: 14.90s\n",
      "Epoch 336/500 - Train Loss: 34.7638359627 | Train Acc: 43.9202928020% | Time: 14.89s\n",
      "Epoch 337/500 - Train Loss: 34.6439480921 | Train Acc: 43.6762911753% | Time: 14.89s\n",
      "Epoch 338/500 - Train Loss: 35.2717665635 | Train Acc: 40.5449369662% | Time: 14.88s\n",
      "Epoch 339/500 - Train Loss: 34.7293255407 | Train Acc: 44.2456283042% | Time: 14.87s\n",
      "Epoch 340/500 - Train Loss: 36.0767962035 | Train Acc: 38.9589263928% | Time: 14.92s\n",
      "Epoch 341/500 - Train Loss: 35.3695130565 | Train Acc: 40.9516063440% | Time: 14.88s\n",
      "Epoch 342/500 - Train Loss: 35.5114412463 | Train Acc: 40.3416022773% | Time: 14.93s\n",
      "Epoch 343/500 - Train Loss: 34.9504089263 | Train Acc: 43.1069540464% | Time: 14.88s\n",
      "Epoch 344/500 - Train Loss: 35.7864792982 | Train Acc: 41.3176087841% | Time: 14.91s\n",
      "Epoch 345/500 - Train Loss: 35.8533963956 | Train Acc: 39.4875965840% | Time: 14.89s\n",
      "Epoch 346/500 - Train Loss: 35.8812821670 | Train Acc: 39.5282635218% | Time: 14.88s\n",
      "Epoch 347/500 - Train Loss: 35.4363544281 | Train Acc: 39.9349328996% | Time: 14.87s\n",
      "Epoch 348/500 - Train Loss: 35.4308002367 | Train Acc: 40.8702724685% | Time: 14.88s\n",
      "Epoch 349/500 - Train Loss: 35.6192214412 | Train Acc: 42.7816185441% | Time: 14.93s\n",
      "Epoch 350/500 - Train Loss: 34.8689230588 | Train Acc: 43.9609597397% | Time: 14.89s\n",
      "Epoch 351/500 - Train Loss: 35.0226750792 | Train Acc: 42.7002846686% | Time: 14.90s\n",
      "Epoch 352/500 - Train Loss: 34.7641734489 | Train Acc: 43.4729564864% | Time: 14.88s\n",
      "Epoch 353/500 - Train Loss: 34.8058169724 | Train Acc: 43.9202928020% | Time: 14.90s\n",
      "Epoch 354/500 - Train Loss: 34.8431563192 | Train Acc: 42.6189507930% | Time: 14.88s\n",
      "Epoch 355/500 - Train Loss: 35.2895850361 | Train Acc: 41.7242781619% | Time: 14.93s\n",
      "Epoch 356/500 - Train Loss: 35.1366941898 | Train Acc: 42.6596177308% | Time: 14.88s\n",
      "Epoch 357/500 - Train Loss: 35.2687516197 | Train Acc: 40.5042700285% | Time: 14.92s\n",
      "Epoch 358/500 - Train Loss: 35.4275079130 | Train Acc: 39.0809272062% | Time: 14.87s\n",
      "Epoch 359/500 - Train Loss: 35.6156286373 | Train Acc: 39.6095973973% | Time: 14.89s\n",
      "Epoch 360/500 - Train Loss: 35.3281402147 | Train Acc: 41.8869459130% | Time: 14.88s\n",
      "Epoch 361/500 - Train Loss: 35.4768286076 | Train Acc: 41.4396095974% | Time: 14.90s\n",
      "Epoch 362/500 - Train Loss: 34.9590932069 | Train Acc: 45.0589670598% | Time: 14.89s\n",
      "Epoch 363/500 - Train Loss: 35.0855040566 | Train Acc: 41.7649450996% | Time: 14.88s\n",
      "Epoch 364/500 - Train Loss: 35.1341492356 | Train Acc: 42.2936152908% | Time: 14.89s\n",
      "Epoch 365/500 - Train Loss: 36.0526198783 | Train Acc: 40.5856039040% | Time: 14.88s\n",
      "Epoch 366/500 - Train Loss: 34.9624976229 | Train Acc: 42.1716144774% | Time: 14.89s\n",
      "Epoch 367/500 - Train Loss: 35.5483304541 | Train Acc: 41.1549410329% | Time: 14.88s\n",
      "Epoch 368/500 - Train Loss: 35.4888740917 | Train Acc: 40.0569337129% | Time: 14.88s\n",
      "Epoch 369/500 - Train Loss: 35.0298725351 | Train Acc: 41.1956079707% | Time: 14.91s\n",
      "Epoch 370/500 - Train Loss: 34.5859804153 | Train Acc: 43.8796258642% | Time: 14.88s\n",
      "Epoch 371/500 - Train Loss: 35.4856008322 | Train Acc: 42.2936152908% | Time: 14.87s\n",
      "Epoch 372/500 - Train Loss: 35.0923657448 | Train Acc: 41.8462789752% | Time: 14.94s\n",
      "Epoch 373/500 - Train Loss: 34.9788651389 | Train Acc: 44.4896299309% | Time: 14.88s\n",
      "Epoch 374/500 - Train Loss: 35.4392086446 | Train Acc: 40.9516063440% | Time: 14.91s\n",
      "Epoch 375/500 - Train Loss: 34.9742925709 | Train Acc: 42.3749491663% | Time: 14.89s\n",
      "Epoch 376/500 - Train Loss: 35.0079703749 | Train Acc: 43.3102887353% | Time: 14.94s\n",
      "Epoch 377/500 - Train Loss: 35.0352033299 | Train Acc: 42.4156161041% | Time: 14.87s\n",
      "Epoch 378/500 - Train Loss: 35.7510581125 | Train Acc: 40.5449369662% | Time: 14.91s\n",
      "Epoch 379/500 - Train Loss: 35.8206613931 | Train Acc: 39.4062627084% | Time: 14.95s\n",
      "Epoch 380/500 - Train Loss: 35.2514138113 | Train Acc: 42.7002846686% | Time: 14.88s\n",
      "Epoch 381/500 - Train Loss: 35.3555028036 | Train Acc: 40.9516063440% | Time: 14.89s\n",
      "Epoch 382/500 - Train Loss: 36.1707417284 | Train Acc: 40.3822692151% | Time: 14.88s\n",
      "Epoch 383/500 - Train Loss: 34.8648390507 | Train Acc: 43.7982919886% | Time: 14.88s\n",
      "Epoch 384/500 - Train Loss: 34.9850323928 | Train Acc: 41.3989426596% | Time: 14.88s\n",
      "Epoch 385/500 - Train Loss: 35.1397624891 | Train Acc: 40.7889385929% | Time: 14.88s\n",
      "Epoch 386/500 - Train Loss: 35.7556561170 | Train Acc: 40.5856039040% | Time: 14.88s\n",
      "Epoch 387/500 - Train Loss: 35.9821076811 | Train Acc: 39.4875965840% | Time: 14.93s\n",
      "Epoch 388/500 - Train Loss: 35.0870331650 | Train Acc: 42.1716144774% | Time: 14.89s\n",
      "Epoch 389/500 - Train Loss: 35.0383287204 | Train Acc: 42.6596177308% | Time: 14.90s\n",
      "Epoch 390/500 - Train Loss: 35.7709079129 | Train Acc: 39.8942659618% | Time: 14.88s\n",
      "Epoch 391/500 - Train Loss: 34.9345156063 | Train Acc: 41.5209434730% | Time: 14.89s\n",
      "Epoch 392/500 - Train Loss: 34.9307859780 | Train Acc: 42.2529483530% | Time: 14.91s\n",
      "Epoch 393/500 - Train Loss: 35.2966522009 | Train Acc: 39.7315982107% | Time: 14.88s\n",
      "Epoch 394/500 - Train Loss: 35.0497131502 | Train Acc: 42.2936152908% | Time: 14.89s\n",
      "Epoch 395/500 - Train Loss: 35.0632130867 | Train Acc: 41.5616104107% | Time: 14.88s\n",
      "Epoch 396/500 - Train Loss: 34.8499391048 | Train Acc: 42.3342822285% | Time: 14.91s\n",
      "Epoch 397/500 - Train Loss: 34.9681610179 | Train Acc: 41.7242781619% | Time: 14.90s\n",
      "Epoch 398/500 - Train Loss: 35.5528076516 | Train Acc: 39.4062627084% | Time: 14.90s\n",
      "Epoch 399/500 - Train Loss: 34.7491826129 | Train Acc: 42.9849532330% | Time: 14.90s\n",
      "Epoch 400/500 - Train Loss: 35.0465094192 | Train Acc: 41.0736071574% | Time: 14.89s\n",
      "Epoch 401/500 - Train Loss: 35.0245692653 | Train Acc: 42.6596177308% | Time: 14.88s\n",
      "Epoch 402/500 - Train Loss: 35.0790308559 | Train Acc: 42.5376169174% | Time: 14.89s\n",
      "Epoch 403/500 - Train Loss: 34.8771665917 | Train Acc: 43.2696217975% | Time: 14.91s\n",
      "Epoch 404/500 - Train Loss: 34.9341195992 | Train Acc: 43.5949572997% | Time: 14.88s\n",
      "Epoch 405/500 - Train Loss: 34.9491509060 | Train Acc: 43.0662871086% | Time: 14.93s\n",
      "Epoch 406/500 - Train Loss: 35.0508534181 | Train Acc: 40.2602684018% | Time: 14.89s\n",
      "Epoch 407/500 - Train Loss: 35.1023450641 | Train Acc: 42.9036193575% | Time: 14.88s\n",
      "Epoch 408/500 - Train Loss: 35.2473895828 | Train Acc: 41.2769418463% | Time: 14.92s\n",
      "Epoch 409/500 - Train Loss: 35.1549048192 | Train Acc: 42.5782838552% | Time: 14.88s\n",
      "Epoch 410/500 - Train Loss: 35.0474762684 | Train Acc: 43.0256201708% | Time: 14.89s\n",
      "Epoch 411/500 - Train Loss: 34.6342009461 | Train Acc: 44.0422936153% | Time: 14.89s\n",
      "Epoch 412/500 - Train Loss: 35.1838821250 | Train Acc: 42.1716144774% | Time: 14.88s\n",
      "Epoch 413/500 - Train Loss: 35.4304159059 | Train Acc: 41.2769418463% | Time: 14.88s\n",
      "Epoch 414/500 - Train Loss: 34.9952435106 | Train Acc: 41.9276128508% | Time: 14.90s\n",
      "Epoch 415/500 - Train Loss: 35.3471258414 | Train Acc: 39.8535990240% | Time: 14.92s\n",
      "Epoch 416/500 - Train Loss: 34.9905519842 | Train Acc: 41.8056120374% | Time: 14.90s\n",
      "Epoch 417/500 - Train Loss: 35.9420302611 | Train Acc: 41.0736071574% | Time: 14.90s\n",
      "Epoch 418/500 - Train Loss: 34.8839498108 | Train Acc: 41.9682797885% | Time: 14.88s\n",
      "Epoch 419/500 - Train Loss: 34.5812866115 | Train Acc: 43.3509556730% | Time: 14.89s\n",
      "Epoch 420/500 - Train Loss: 35.3314305730 | Train Acc: 39.2842618951% | Time: 14.90s\n",
      "Epoch 421/500 - Train Loss: 34.9906194411 | Train Acc: 43.7576250508% | Time: 14.89s\n",
      "Epoch 422/500 - Train Loss: 35.0228497301 | Train Acc: 42.1309475397% | Time: 14.90s\n",
      "Epoch 423/500 - Train Loss: 35.6123534023 | Train Acc: 41.4802765352% | Time: 14.92s\n",
      "Epoch 424/500 - Train Loss: 34.6515123844 | Train Acc: 42.6596177308% | Time: 14.90s\n",
      "Epoch 425/500 - Train Loss: 35.0841687267 | Train Acc: 41.8056120374% | Time: 14.88s\n",
      "Epoch 426/500 - Train Loss: 35.4071624620 | Train Acc: 40.6262708418% | Time: 14.91s\n",
      "Epoch 427/500 - Train Loss: 35.0034152889 | Train Acc: 42.4969499797% | Time: 14.88s\n",
      "Epoch 428/500 - Train Loss: 34.9410139601 | Train Acc: 44.1236274908% | Time: 14.88s\n",
      "Epoch 429/500 - Train Loss: 34.9749044954 | Train Acc: 42.3749491663% | Time: 14.90s\n",
      "Epoch 430/500 - Train Loss: 35.3151628491 | Train Acc: 41.4396095974% | Time: 14.92s\n",
      "Epoch 431/500 - Train Loss: 35.2441100269 | Train Acc: 40.4229361529% | Time: 14.88s\n",
      "Epoch 432/500 - Train Loss: 35.2039858459 | Train Acc: 41.6022773485% | Time: 14.88s\n",
      "Epoch 433/500 - Train Loss: 34.9721704133 | Train Acc: 42.4969499797% | Time: 14.89s\n",
      "Epoch 434/500 - Train Loss: 35.1105001577 | Train Acc: 41.1956079707% | Time: 14.92s\n",
      "Epoch 435/500 - Train Loss: 34.7906430418 | Train Acc: 43.4322895486% | Time: 14.90s\n",
      "Epoch 436/500 - Train Loss: 35.8674322343 | Train Acc: 41.8056120374% | Time: 14.89s\n",
      "Epoch 437/500 - Train Loss: 34.9075900084 | Train Acc: 42.2529483530% | Time: 14.88s\n",
      "Epoch 438/500 - Train Loss: 34.9570168984 | Train Acc: 43.5136234242% | Time: 14.91s\n",
      "Epoch 439/500 - Train Loss: 35.0982741806 | Train Acc: 42.5376169174% | Time: 14.88s\n",
      "Epoch 440/500 - Train Loss: 35.2608457045 | Train Acc: 42.6596177308% | Time: 14.89s\n",
      "Epoch 441/500 - Train Loss: 35.0843743248 | Train Acc: 42.4156161041% | Time: 14.93s\n",
      "Epoch 442/500 - Train Loss: 34.9800034777 | Train Acc: 42.0089467263% | Time: 14.91s\n",
      "Epoch 443/500 - Train Loss: 34.9794993106 | Train Acc: 42.9442862952% | Time: 14.91s\n",
      "Epoch 444/500 - Train Loss: 34.7157715048 | Train Acc: 41.7649450996% | Time: 14.89s\n",
      "Epoch 445/500 - Train Loss: 35.0558460022 | Train Acc: 41.7649450996% | Time: 14.88s\n",
      "Epoch 446/500 - Train Loss: 34.8117245428 | Train Acc: 41.9276128508% | Time: 14.87s\n",
      "Epoch 447/500 - Train Loss: 35.1665737211 | Train Acc: 41.6836112241% | Time: 14.93s\n",
      "Epoch 448/500 - Train Loss: 34.6400844447 | Train Acc: 44.1642944286% | Time: 14.88s\n",
      "Epoch 449/500 - Train Loss: 35.6496538884 | Train Acc: 41.5209434730% | Time: 14.88s\n",
      "Epoch 450/500 - Train Loss: 35.4863192323 | Train Acc: 41.1142740952% | Time: 14.89s\n",
      "Epoch 451/500 - Train Loss: 35.7948843767 | Train Acc: 39.6502643351% | Time: 14.90s\n",
      "Epoch 452/500 - Train Loss: 35.2864660706 | Train Acc: 40.0162667751% | Time: 14.87s\n",
      "Epoch 453/500 - Train Loss: 35.0681903331 | Train Acc: 41.4802765352% | Time: 14.89s\n",
      "Epoch 454/500 - Train Loss: 35.0127443292 | Train Acc: 43.7576250508% | Time: 14.88s\n",
      "Epoch 455/500 - Train Loss: 35.1269609866 | Train Acc: 41.1549410329% | Time: 14.91s\n",
      "Epoch 456/500 - Train Loss: 34.9173094623 | Train Acc: 42.4156161041% | Time: 14.88s\n",
      "Epoch 457/500 - Train Loss: 35.6282468090 | Train Acc: 40.0976006507% | Time: 14.90s\n",
      "Epoch 458/500 - Train Loss: 34.7892606800 | Train Acc: 41.7649450996% | Time: 14.93s\n",
      "Epoch 459/500 - Train Loss: 34.9953129632 | Train Acc: 41.8869459130% | Time: 14.92s\n",
      "Epoch 460/500 - Train Loss: 35.7456212601 | Train Acc: 39.1215941440% | Time: 14.90s\n",
      "Epoch 461/500 - Train Loss: 35.3750788082 | Train Acc: 40.0162667751% | Time: 14.88s\n",
      "Epoch 462/500 - Train Loss: 34.9929797371 | Train Acc: 43.1476209841% | Time: 14.92s\n",
      "Epoch 463/500 - Train Loss: 35.8362206453 | Train Acc: 39.2029280195% | Time: 14.89s\n",
      "Epoch 464/500 - Train Loss: 34.6220938540 | Train Acc: 44.5709638064% | Time: 14.92s\n",
      "Epoch 465/500 - Train Loss: 35.1800562205 | Train Acc: 42.2529483530% | Time: 14.89s\n",
      "Epoch 466/500 - Train Loss: 34.9079562039 | Train Acc: 41.6429442863% | Time: 14.91s\n",
      "Epoch 467/500 - Train Loss: 34.8398855584 | Train Acc: 42.1309475397% | Time: 14.90s\n",
      "Epoch 468/500 - Train Loss: 35.2568295203 | Train Acc: 42.0902806019% | Time: 14.90s\n",
      "Epoch 469/500 - Train Loss: 34.8845671555 | Train Acc: 42.1309475397% | Time: 14.94s\n",
      "Epoch 470/500 - Train Loss: 35.6222501312 | Train Acc: 39.4062627084% | Time: 14.91s\n",
      "Epoch 471/500 - Train Loss: 34.9888689719 | Train Acc: 43.4729564864% | Time: 14.90s\n",
      "Epoch 472/500 - Train Loss: 35.1735845464 | Train Acc: 42.3749491663% | Time: 14.90s\n",
      "Epoch 473/500 - Train Loss: 34.6412973388 | Train Acc: 44.7336315575% | Time: 14.90s\n",
      "Epoch 474/500 - Train Loss: 35.1788717446 | Train Acc: 40.2196014640% | Time: 14.93s\n",
      "Epoch 475/500 - Train Loss: 35.1408358549 | Train Acc: 42.7816185441% | Time: 14.92s\n",
      "Epoch 476/500 - Train Loss: 35.1006909284 | Train Acc: 42.2529483530% | Time: 14.90s\n",
      "Epoch 477/500 - Train Loss: 34.6458602586 | Train Acc: 43.6356242375% | Time: 14.91s\n",
      "Epoch 478/500 - Train Loss: 36.1608561409 | Train Acc: 40.3416022773% | Time: 14.90s\n",
      "Epoch 479/500 - Train Loss: 35.1857856094 | Train Acc: 43.0256201708% | Time: 14.91s\n",
      "Epoch 480/500 - Train Loss: 34.9309622823 | Train Acc: 42.3749491663% | Time: 14.92s\n",
      "Epoch 481/500 - Train Loss: 34.8897367081 | Train Acc: 41.4396095974% | Time: 14.92s\n",
      "Epoch 482/500 - Train Loss: 35.1847987639 | Train Acc: 41.1956079707% | Time: 14.89s\n",
      "Epoch 483/500 - Train Loss: 34.5361844781 | Train Acc: 44.4082960553% | Time: 14.93s\n",
      "Epoch 484/500 - Train Loss: 34.7315177592 | Train Acc: 43.6356242375% | Time: 14.90s\n",
      "Epoch 485/500 - Train Loss: 35.0047504569 | Train Acc: 42.5376169174% | Time: 14.93s\n",
      "Epoch 486/500 - Train Loss: 35.3235888698 | Train Acc: 42.1309475397% | Time: 14.89s\n",
      "Epoch 487/500 - Train Loss: 35.0313664102 | Train Acc: 43.3916226108% | Time: 14.91s\n",
      "Epoch 488/500 - Train Loss: 34.9052018407 | Train Acc: 42.9849532330% | Time: 14.91s\n",
      "Epoch 489/500 - Train Loss: 34.7276220136 | Train Acc: 44.0016266775% | Time: 14.91s\n",
      "Epoch 490/500 - Train Loss: 34.9039846070 | Train Acc: 43.9609597397% | Time: 14.94s\n",
      "Epoch 491/500 - Train Loss: 35.0032745337 | Train Acc: 43.8796258642% | Time: 15.06s\n",
      "Epoch 492/500 - Train Loss: 35.5145885588 | Train Acc: 41.9276128508% | Time: 14.91s\n",
      "Epoch 493/500 - Train Loss: 34.8994937655 | Train Acc: 41.4396095974% | Time: 14.89s\n",
      "Epoch 494/500 - Train Loss: 34.7835229341 | Train Acc: 42.7409516063% | Time: 14.92s\n",
      "Epoch 495/500 - Train Loss: 35.5308083280 | Train Acc: 41.6429442863% | Time: 14.94s\n",
      "Epoch 496/500 - Train Loss: 35.3679741838 | Train Acc: 40.3822692151% | Time: 14.94s\n",
      "Epoch 497/500 - Train Loss: 34.7999333143 | Train Acc: 42.2529483530% | Time: 14.90s\n",
      "Epoch 498/500 - Train Loss: 35.9712586387 | Train Acc: 40.3822692151% | Time: 14.95s\n",
      "Epoch 499/500 - Train Loss: 35.2855340986 | Train Acc: 42.4969499797% | Time: 14.90s\n",
      "Epoch 500/500 - Train Loss: 35.3237953743 | Train Acc: 40.7889385929% | Time: 14.92s\n",
      "Classifier training complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs_clf = 500\n",
    "best_train_acc = 0.0  # Best training accuracy so far.\n",
    "\n",
    "for epoch in range(num_epochs_clf):\n",
    "    epoch_start_time = time.time()\n",
    "    classifier.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for context_block, _, label, _  in train_loader_aav_ijepa:\n",
    "        context_block = context_block.cuda()  # [B, C, 224, 224]\n",
    "        label = label.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = context_encoder(context_block)  # [B, 768]\n",
    "\n",
    "        logits = classifier(features)  # [B, num_classes]\n",
    "        loss = criterion_cls(logits, label)\n",
    "\n",
    "        clf_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clf_optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * context_block.size(0)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct_train += (preds == label).sum().item()\n",
    "        total_train += label.size(0)\n",
    "\n",
    "    epoch_train_loss = running_loss / len(train_loader_aav_ijepa)\n",
    "    epoch_train_acc = correct_train / total_train\n",
    "    epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs_clf} - Train Loss: {epoch_train_loss:.10f} | Train Acc: {epoch_train_acc*100:.10f}% | Time: {epoch_time:.2f}s\")\n",
    "\n",
    "    # Save checkpoint if training accuracy improves.\n",
    "    if epoch_train_acc > best_train_acc:\n",
    "        best_train_acc = epoch_train_acc\n",
    "        checkpoint = {\n",
    "            'epoch': epoch+1,\n",
    "            'classifier_state_dict': classifier.state_dict(),\n",
    "            'optimizer_state_dict': clf_optimizer.state_dict(),\n",
    "            'train_loss': epoch_train_loss,\n",
    "            'train_acc': epoch_train_acc\n",
    "        }\n",
    "        torch.save(checkpoint, os.path.join(base_dir,\"ijepa_classifier_best.pth\"))\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1} with Train Acc: {epoch_train_acc*100:.10f}%\")\n",
    "\n",
    "print(\"Classifier training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f0c2446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T14:19:27.361246Z",
     "iopub.status.busy": "2025-04-03T14:19:27.360919Z",
     "iopub.status.idle": "2025-04-03T14:19:27.364318Z",
     "shell.execute_reply": "2025-04-03T14:19:27.363618Z"
    },
    "id": "OfvaWDggmMKX",
    "papermill": {
     "duration": 0.590842,
     "end_time": "2025-04-03T14:19:27.365517",
     "exception": false,
     "start_time": "2025-04-03T14:19:26.774675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from google.colab import output\n",
    "#output.eval_js('google.colab.kernel.disconnect()')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7010008,
     "sourceId": 11224133,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23710.934348,
   "end_time": "2025-04-03T14:19:31.900553",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-03T07:44:20.966205",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
