{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 11262517,
          "sourceType": "datasetVersion",
          "datasetId": 7039367
        },
        {
          "sourceId": 11270413,
          "sourceType": "datasetVersion",
          "datasetId": 7044877
        }
      ],
      "dockerImageVersionId": 30919,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "collapsed_sections": [
        "Km6L8fvfyblv",
        "YhA8NzTLygaj"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raihanewubd/selfSupervised/blob/main/i_jepa_aav_v4_raw_EfficientNetB2_classifer_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "from torchvision.models import vit_b_16\n",
        "\n",
        "\n",
        "\n",
        "import timm\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import pickle\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:27:48.840145Z",
          "iopub.execute_input": "2025-04-04T05:27:48.840581Z",
          "iopub.status.idle": "2025-04-04T05:28:13.816982Z",
          "shell.execute_reply.started": "2025-04-04T05:27:48.840549Z",
          "shell.execute_reply": "2025-04-04T05:28:13.816229Z"
        },
        "id": "InkoMtgxDxFO"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "def get_environment():\n",
        "    if 'google.colab' in sys.modules:\n",
        "        return \"Google Colab\"\n",
        "    elif 'KAGGLE_URL_BASE' in os.environ:\n",
        "        return \"Kaggle\"\n",
        "    else:\n",
        "        return \"Local or Other Environment\"\n",
        "\n",
        "print(get_environment())\n"
      ],
      "metadata": {
        "id": "nzewh7sJZQk3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804ac0ed-42c0-42c8-d485-d0fa323dd701"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set device for GPU acceleration if available.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:28:13.818062Z",
          "iopub.execute_input": "2025-04-04T05:28:13.818292Z",
          "iopub.status.idle": "2025-04-04T05:28:13.883898Z",
          "shell.execute_reply.started": "2025-04-04T05:28:13.818272Z",
          "shell.execute_reply": "2025-04-04T05:28:13.882743Z"
        },
        "id": "fycYWBafDxFR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68806902-b83f-479b-85c6-2e88278b827a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNHtl33RD9A-",
        "outputId": "dffe2066-9f67-4d99-ebf6-b29301591e56"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base directory and file name for saving the classifier checkpoint.\n",
        "base_dir = \"/kaggle/working/\"\n",
        "base_dir = \"/content/drive/MyDrive/AAVDATASET/1s_segment_raw/\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:28:13.885857Z",
          "iopub.execute_input": "2025-04-04T05:28:13.886133Z",
          "iopub.status.idle": "2025-04-04T05:28:13.941852Z",
          "shell.execute_reply.started": "2025-04-04T05:28:13.886109Z",
          "shell.execute_reply": "2025-04-04T05:28:13.940855Z"
        },
        "id": "NYkjhF9kDxFS"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "#ijepa_trained_model = \"/kaggle/input/aav-raw-checkpoints/ijepa_aav_raw_checkpoint_best.pth\"\n",
        "#ijepa_raw_precumpted_full_dataset = \"/kaggle/input/aav-raw-checkpoints/precomputed_fulldataset_aav_raw.pkl\"\n",
        "#ijepa_trained_model = \"/content/drive/MyDrive/AAVDATASET/spectrogram/ijepa_checkpoint_best.pth\"\n",
        "#ijepa_trained_classifier_model = \"/content/drive/MyDrive/AAVDATASET/spectrogram/ijepa_classifier_best.pth\"\n",
        "ijepa_raw_precumpted_full_dataset = os.path.join(base_dir,\"precomputed_fulldataset_aav_raw_colab_after_new_context_target.pkl\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "MuEsrJFEDxFS"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/kaggle/input/aav-raw/train_val_photos\"\n",
        "data_dir = os.path.join(base_dir,'train_val_photos')\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:28:13.957021Z",
          "iopub.execute_input": "2025-04-04T05:28:13.957314Z",
          "iopub.status.idle": "2025-04-04T05:28:20.495725Z",
          "shell.execute_reply.started": "2025-04-04T05:28:13.957291Z",
          "shell.execute_reply": "2025-04-04T05:28:20.494600Z"
        },
        "id": "h5d4GL9TDxFT"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to find the first ROI based on grayscale intensity range (10-50)\n",
        "def find_first_roi(img_np):\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "    img_height, img_width = gray.shape\n",
        "\n",
        "    mask = (gray >= 10) & (gray <= 50)\n",
        "    coords = np.column_stack(np.where(mask))\n",
        "\n",
        "    if coords.size == 0:\n",
        "        return None\n",
        "\n",
        "    y_coords, x_coords = coords[:, 0], coords[:, 1]\n",
        "    left = max(0, int(np.min(x_coords)))\n",
        "    top = max(0, int(np.min(y_coords)))\n",
        "    right = min(img_width, int(np.max(x_coords)))\n",
        "    bottom = min(img_height, int(np.max(y_coords)))\n",
        "    width = right - left\n",
        "    height = bottom - top\n",
        "\n",
        "    width = max(1, width)\n",
        "    height = max(1, height)\n",
        "\n",
        "    return (left, top, width, height)\n",
        "\n",
        "# Function to find the second ROI within the first ROI targeting the dense spike cluster\n",
        "def find_second_roi(img_np, first_roi):\n",
        "    if first_roi is None:\n",
        "        return None\n",
        "\n",
        "    roi1_left, roi1_top, roi1_width, roi1_height = first_roi\n",
        "\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "    roi_gray = gray[roi1_top:roi1_top + roi1_height, roi1_left:roi1_left + roi1_width]\n",
        "\n",
        "    mask_spikes = (roi_gray >= 70) & (roi_gray <= 80)\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    mask_spikes = cv2.dilate(mask_spikes.astype(np.uint8) * 255, kernel, iterations=1)\n",
        "\n",
        "    contours, _ = cv2.findContours(mask_spikes, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return (roi1_left, roi1_top, roi1_width, roi1_height)\n",
        "\n",
        "    max_density_contour = max(contours, key=lambda c: len(c))\n",
        "    x, y, w, h = cv2.boundingRect(max_density_contour)\n",
        "\n",
        "    contour_points = max_density_contour.reshape(-1, 2)\n",
        "    y_coords = contour_points[:, 1]\n",
        "\n",
        "    if len(y_coords) > 0:\n",
        "        y_upper = int(np.percentile(y_coords, 75))\n",
        "    else:\n",
        "        y_upper = y + h\n",
        "\n",
        "    roi2_left = roi1_left + x\n",
        "    roi2_top = roi1_top + y\n",
        "    roi2_width = max(1, w)\n",
        "    roi2_height = max(1, y_upper - y)\n",
        "\n",
        "    return (roi2_left, roi2_top, roi2_width, roi2_height)\n",
        "\n",
        "# Function to sample a context block within the second ROI, ensuring it is fully clipped\n",
        "def sample_context_block(second_roi, context_scale=0.5, height_to_width_ratio=0.5):\n",
        "    if second_roi is None:\n",
        "        return None\n",
        "\n",
        "    roi2_left, roi2_top, roi2_width, roi2_height = second_roi\n",
        "    roi2_right = roi2_left + roi2_width\n",
        "    roi2_bottom = roi2_top + roi2_height\n",
        "\n",
        "    context_w = int(roi2_width * context_scale)\n",
        "    context_h = int(context_w * height_to_width_ratio)\n",
        "\n",
        "    context_w = min(context_w, roi2_width)\n",
        "    context_h = min(context_h, roi2_height)\n",
        "\n",
        "    cx_center = roi2_left + roi2_width / 2\n",
        "    cy_center = roi2_top + 0.75 * roi2_height\n",
        "\n",
        "    context_x = int(max(roi2_left, min(cx_center - context_w / 2, roi2_right - context_w)))\n",
        "    context_y = int(max(roi2_top, min(cy_center - context_h / 2, roi2_bottom - context_h)))\n",
        "\n",
        "    if context_x + context_w > roi2_right:\n",
        "        context_w = roi2_right - context_x\n",
        "    if context_y + context_h > roi2_bottom:\n",
        "        context_h = roi2_bottom - context_y\n",
        "\n",
        "    context_w = max(1, context_w)\n",
        "    context_h = max(1, context_h)\n",
        "\n",
        "    return (context_x, context_y, context_w, context_h)\n",
        "\n",
        "# Function to sample exactly num_targets target blocks within the first ROI\n",
        "'''def sample_target_blocks(img_np, first_roi, second_roi, context_block, target_scale=0.20, num_targets=7):\n",
        "    if first_roi is None or context_block is None:\n",
        "        return []\n",
        "\n",
        "    roi1_left, roi1_top, roi1_width, roi1_height = first_roi\n",
        "    roi1_right = roi1_left + roi1_width\n",
        "    roi1_bottom = roi1_top + roi1_height\n",
        "\n",
        "    context_left, context_top, context_width, context_height = context_block\n",
        "    context_right = context_left + context_width\n",
        "    context_bottom = context_top + context_height\n",
        "\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "    roi1_gray = gray[roi1_top:roi1_top + roi1_height, roi1_left:roi1_left + roi1_width]\n",
        "\n",
        "    mask_spikes = (roi1_gray >= 70) & (roi1_gray <= 80)\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    mask_spikes = cv2.dilate(mask_spikes.astype(np.uint8) * 255, kernel, iterations=1)\n",
        "\n",
        "    peak_coords = np.column_stack(np.where(mask_spikes > 0))\n",
        "\n",
        "    current_target_scale = target_scale\n",
        "    target_coords = []\n",
        "\n",
        "    def does_overlap(box1, box2):\n",
        "        if box1 is None or box2 is None:\n",
        "            return False\n",
        "        x1, y1, w1, h1 = box1\n",
        "        x2, y2, w2, h2 = box2\n",
        "        return not (x1 + w1 <= x2 or x2 + w2 <= x1 or y1 + h1 <= y2 or y2 + h2 <= y1)\n",
        "\n",
        "    def is_inside(box, roi):\n",
        "        x, y, w, h = box\n",
        "        rx, ry, rw, rh = roi\n",
        "        return x >= rx and (x + w) <= (rx + rw) and y >= ry and (y + h) <= (ry + rh)\n",
        "\n",
        "    while len(target_coords) < num_targets:\n",
        "        target_w = int(roi1_width * current_target_scale)\n",
        "        target_h = int(roi1_height * current_target_scale)\n",
        "        target_w = max(1, target_w)\n",
        "        target_h = max(1, target_h)\n",
        "\n",
        "        attempts = 0\n",
        "        max_attempts = 200\n",
        "\n",
        "        while attempts < max_attempts and len(target_coords) < num_targets:\n",
        "            if len(peak_coords) > 0:\n",
        "                idx = np.random.randint(0, len(peak_coords))\n",
        "                peak_y, peak_x = peak_coords[idx]\n",
        "                tx = int(peak_x - target_w / 2) + roi1_left\n",
        "                ty = int(peak_y - target_h / 2) + roi1_top\n",
        "            else:\n",
        "                tx = np.random.randint(roi1_left, roi1_right - target_w)\n",
        "                ty = np.random.randint(roi1_top, roi1_bottom - target_h)\n",
        "\n",
        "            tx = max(roi1_left, min(tx, roi1_right - target_w))\n",
        "            ty = max(roi1_top, min(ty, roi1_bottom - target_h))\n",
        "            new_block = (tx, ty, target_w, target_h)\n",
        "\n",
        "            if not is_inside(new_block, first_roi):\n",
        "                attempts += 1\n",
        "                continue\n",
        "\n",
        "            if does_overlap(new_block, context_block):\n",
        "                attempts += 1\n",
        "                continue\n",
        "\n",
        "            if any(does_overlap(new_block, tc) for tc in target_coords):\n",
        "                attempts += 1\n",
        "                continue\n",
        "\n",
        "            target_coords.append(new_block)\n",
        "            attempts = 0\n",
        "\n",
        "        if len(target_coords) < num_targets:\n",
        "            current_target_scale *= 0.8\n",
        "            target_coords = []\n",
        "            #print(f\"Reducing target block size to scale {current_target_scale:.3f} to fit {num_targets} blocks\")\n",
        "\n",
        "    return target_coords'''"
      ],
      "metadata": {
        "id": "WzyoEtlmGX9Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "f322cc44-ba65-44fa-cd1f-29e5bde1d201"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def sample_target_blocks(img_np, first_roi, second_roi, context_block, target_scale=0.20, num_targets=7):\\n    if first_roi is None or context_block is None:\\n        return []\\n\\n    roi1_left, roi1_top, roi1_width, roi1_height = first_roi\\n    roi1_right = roi1_left + roi1_width\\n    roi1_bottom = roi1_top + roi1_height\\n\\n    context_left, context_top, context_width, context_height = context_block\\n    context_right = context_left + context_width\\n    context_bottom = context_top + context_height\\n\\n    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\\n    roi1_gray = gray[roi1_top:roi1_top + roi1_height, roi1_left:roi1_left + roi1_width]\\n\\n    mask_spikes = (roi1_gray >= 70) & (roi1_gray <= 80)\\n    kernel = np.ones((5, 5), np.uint8)\\n    mask_spikes = cv2.dilate(mask_spikes.astype(np.uint8) * 255, kernel, iterations=1)\\n\\n    peak_coords = np.column_stack(np.where(mask_spikes > 0))\\n\\n    current_target_scale = target_scale\\n    target_coords = []\\n\\n    def does_overlap(box1, box2):\\n        if box1 is None or box2 is None:\\n            return False\\n        x1, y1, w1, h1 = box1\\n        x2, y2, w2, h2 = box2\\n        return not (x1 + w1 <= x2 or x2 + w2 <= x1 or y1 + h1 <= y2 or y2 + h2 <= y1)\\n\\n    def is_inside(box, roi):\\n        x, y, w, h = box\\n        rx, ry, rw, rh = roi\\n        return x >= rx and (x + w) <= (rx + rw) and y >= ry and (y + h) <= (ry + rh)\\n\\n    while len(target_coords) < num_targets:\\n        target_w = int(roi1_width * current_target_scale)\\n        target_h = int(roi1_height * current_target_scale)\\n        target_w = max(1, target_w)\\n        target_h = max(1, target_h)\\n\\n        attempts = 0\\n        max_attempts = 200\\n\\n        while attempts < max_attempts and len(target_coords) < num_targets:\\n            if len(peak_coords) > 0:\\n                idx = np.random.randint(0, len(peak_coords))\\n                peak_y, peak_x = peak_coords[idx]\\n                tx = int(peak_x - target_w / 2) + roi1_left\\n                ty = int(peak_y - target_h / 2) + roi1_top\\n            else:\\n                tx = np.random.randint(roi1_left, roi1_right - target_w)\\n                ty = np.random.randint(roi1_top, roi1_bottom - target_h)\\n\\n            tx = max(roi1_left, min(tx, roi1_right - target_w))\\n            ty = max(roi1_top, min(ty, roi1_bottom - target_h))\\n            new_block = (tx, ty, target_w, target_h)\\n\\n            if not is_inside(new_block, first_roi):\\n                attempts += 1\\n                continue\\n\\n            if does_overlap(new_block, context_block):\\n                attempts += 1\\n                continue\\n\\n            if any(does_overlap(new_block, tc) for tc in target_coords):\\n                attempts += 1\\n                continue\\n\\n            target_coords.append(new_block)\\n            attempts = 0\\n\\n        if len(target_coords) < num_targets:\\n            current_target_scale *= 0.8\\n            target_coords = []\\n            #print(f\"Reducing target block size to scale {current_target_scale:.3f} to fit {num_targets} blocks\")\\n\\n    return target_coords'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_target_blocks(img_np, first_roi, second_roi, context_block, target_scale=0.20, num_targets=7, max_overlap_percentage=0.3):\n",
        "    \"\"\"\n",
        "    Sample exactly num_targets target blocks within the first ROI with a fixed size, avoiding overlap with the context block.\n",
        "    Allow a specified percentage of target blocks to overlap with each other.\n",
        "\n",
        "    Args:\n",
        "        img_np: NumPy array of the image (RGB format, shape: (H, W, 3))\n",
        "        first_roi: (left, top, width, height) of the first ROI, or None\n",
        "        second_roi: (left, top, width, height) of the second ROI, or None (not used in overlap check)\n",
        "        context_block: (cx, cy, cw, ch) of the context block, or None\n",
        "        target_scale: Scaling factor for the target blocks relative to first ROI (fixed)\n",
        "        num_targets: Number of target blocks to sample\n",
        "        max_overlap_percentage: Maximum percentage of target blocks allowed to overlap (e.g., 0.3 for 30%)\n",
        "\n",
        "    Returns:\n",
        "        target_coords: List of (tx, ty, tw, th) for each target block\n",
        "    \"\"\"\n",
        "    if first_roi is None or context_block is None:\n",
        "        return []\n",
        "\n",
        "    # Extract coordinates of the first ROI and context block\n",
        "    roi1_left, roi1_top, roi1_width, roi1_height = first_roi\n",
        "    roi1_right = roi1_left + roi1_width\n",
        "    roi1_bottom = roi1_top + roi1_height\n",
        "\n",
        "    context_left, context_top, context_width, context_height = context_block\n",
        "    context_right = context_left + context_width\n",
        "    context_bottom = context_top + context_height\n",
        "\n",
        "    # Convert image to grayscale and crop to the first ROI\n",
        "    gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "    roi1_gray = gray[roi1_top:roi1_top + roi1_height, roi1_left:roi1_left + roi1_width]\n",
        "\n",
        "    # Create a mask for red spikes (grayscale 70-80) to identify high peak regions\n",
        "    mask_spikes = (roi1_gray >= 70) & (roi1_gray <= 80)\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    mask_spikes = cv2.dilate(mask_spikes.astype(np.uint8) * 255, kernel, iterations=1)\n",
        "\n",
        "    # Find coordinates of high peak regions (spikes)\n",
        "    peak_coords = np.column_stack(np.where(mask_spikes > 0))\n",
        "\n",
        "    # Compute fixed target block size based on the initial target_scale\n",
        "    target_w = int(roi1_width * target_scale)\n",
        "    target_h = int(roi1_height * target_scale)\n",
        "    target_w = max(1, target_w)\n",
        "    target_h = max(1, target_h)\n",
        "\n",
        "    target_coords = []\n",
        "    overlap_count = 0  # Track the number of blocks that overlap with others\n",
        "    max_overlaps_allowed = int(num_targets * max_overlap_percentage)  # Maximum number of blocks allowed to overlap\n",
        "\n",
        "    def does_overlap(box1, box2):\n",
        "        \"\"\"\n",
        "        Check if two boxes overlap.\n",
        "\n",
        "        Args:\n",
        "            box1: (x, y, w, h) of the first box\n",
        "            box2: (x, y, w, h) of the second box\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the boxes overlap, False otherwise\n",
        "        \"\"\"\n",
        "        if box1 is None or box2 is None:\n",
        "            return False\n",
        "        x1, y1, w1, h1 = box1\n",
        "        x2, y2, w2, h2 = box2\n",
        "        return not (x1 + w1 <= x2 or x2 + w2 <= x1 or y1 + h1 <= y2 or y2 + h2 <= y1)\n",
        "\n",
        "    def is_inside(box, roi):\n",
        "        \"\"\"\n",
        "        Check if a box is fully inside a region.\n",
        "\n",
        "        Args:\n",
        "            box: (x, y, w, h) of the box\n",
        "            roi: (left, top, width, height) of the region\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the box is inside the region, False otherwise\n",
        "        \"\"\"\n",
        "        x, y, w, h = box\n",
        "        rx, ry, rw, rh = roi\n",
        "        return x >= rx and (x + w) <= (rx + rw) and y >= ry and (y + h) <= (ry + rh)\n",
        "\n",
        "    attempts = 0\n",
        "    max_attempts = 200 * num_targets  # Increase attempts to give more chances to place blocks\n",
        "\n",
        "    while len(target_coords) < num_targets and attempts < max_attempts:\n",
        "        # Sample a position for the new target block\n",
        "        if len(peak_coords) > 0:\n",
        "            idx = np.random.randint(0, len(peak_coords))\n",
        "            peak_y, peak_x = peak_coords[idx]\n",
        "            tx = int(peak_x - target_w / 2) + roi1_left\n",
        "            ty = int(peak_y - target_h / 2) + roi1_top\n",
        "        else:\n",
        "            tx = np.random.randint(roi1_left, roi1_right - target_w)\n",
        "            ty = np.random.randint(roi1_top, roi1_bottom - target_h)\n",
        "\n",
        "        # Ensure the block stays within the first ROI\n",
        "        tx = max(roi1_left, min(tx, roi1_right - target_w))\n",
        "        ty = max(roi1_top, min(ty, roi1_bottom - target_h))\n",
        "        new_block = (tx, ty, target_w, target_h)\n",
        "\n",
        "        # Check if the block is inside the first ROI (should be true due to clamping)\n",
        "        if not is_inside(new_block, first_roi):\n",
        "            attempts += 1\n",
        "            continue\n",
        "\n",
        "        # Check if the block overlaps with the context block\n",
        "        if does_overlap(new_block, context_block):\n",
        "            attempts += 1\n",
        "            continue\n",
        "\n",
        "        # Check for overlap with existing target blocks\n",
        "        overlaps_with_existing = any(does_overlap(new_block, tc) for tc in target_coords)\n",
        "\n",
        "        # Allow overlap only if we haven't exceeded the max_overlap_percentage\n",
        "        if overlaps_with_existing:\n",
        "            if overlap_count >= max_overlaps_allowed:\n",
        "                attempts += 1\n",
        "                continue\n",
        "            overlap_count += 1  # Increment the overlap counter\n",
        "\n",
        "        target_coords.append(new_block)\n",
        "        attempts = 0  # Reset attempts after a successful placement\n",
        "\n",
        "    if len(target_coords) < num_targets:\n",
        "        print(f\"Warning: Could only place {len(target_coords)} out of {num_targets} target blocks without exceeding overlap limit.\")\n",
        "\n",
        "    return target_coords"
      ],
      "metadata": {
        "id": "RNcZGR1qtOdC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_blocks(image_path, context_scale=0.85, target_scale=0.2, num_targets=4, max_overlap=0.5):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "\n",
        "    # Load the original image\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    image_np = np.array(img)\n",
        "\n",
        "    first_roi = find_first_roi(image_np)\n",
        "    second_roi = find_second_roi(image_np, first_roi)\n",
        "    context_coords = sample_context_block(second_roi, context_scale=context_scale)\n",
        "    target_coords = sample_target_blocks(image_np, first_roi, second_roi, context_coords, target_scale=target_scale, num_targets=num_targets)\n",
        "\n",
        "    if context_coords:\n",
        "        cx, cy, cw, ch = context_coords\n",
        "        context_patch = image_np[cy:cy + ch, cx:cx + cw, :]\n",
        "        context_patch = Image.fromarray(context_patch)\n",
        "        context_block = transform(context_patch)\n",
        "        context_block = context_block.to(device)\n",
        "    else:\n",
        "        context_block = torch.zeros(3, 224, 224, device=device)\n",
        "        context_coords = (0, 0, 0, 0)\n",
        "\n",
        "    target_blocks = []\n",
        "    if target_coords:\n",
        "        for tx, ty, tw, th in target_coords:\n",
        "            target_patch = image_np[ty:ty + th, tx:tx + tw, :]\n",
        "            target_patch = Image.fromarray(target_patch)\n",
        "            target_block = transform(target_patch)\n",
        "            target_block = target_block.to(device)\n",
        "            target_blocks.append(target_block)\n",
        "    else:\n",
        "        target_blocks = [torch.zeros(3, 224, 224, device=device) for _ in range(num_targets)]\n",
        "        target_coords = [(0, 0, 0, 0) for _ in range(num_targets)]\n",
        "\n",
        "    return context_block, target_blocks, context_coords, target_coords\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:28:20.496558Z",
          "iopub.execute_input": "2025-04-04T05:28:20.496852Z",
          "iopub.status.idle": "2025-04-04T05:28:20.504415Z",
          "shell.execute_reply.started": "2025-04-04T05:28:20.496829Z",
          "shell.execute_reply": "2025-04-04T05:28:20.503126Z"
        },
        "id": "rG21_6tyDxFT"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "def process_sample(sample, context_scale, target_scale, num_targets):\n",
        "    (img, label), image_path = sample\n",
        "    context_block, target_blocks, context_coords, target_coords = extract_blocks(image_path, context_scale, target_scale, num_targets)\n",
        "    return (context_block.cpu(), [tb.cpu() for tb in target_blocks], label, image_path, context_coords, target_coords)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:28:20.505340Z",
          "iopub.execute_input": "2025-04-04T05:28:20.505612Z",
          "iopub.status.idle": "2025-04-04T05:28:20.543126Z",
          "shell.execute_reply.started": "2025-04-04T05:28:20.505590Z",
          "shell.execute_reply": "2025-04-04T05:28:20.542006Z"
        },
        "id": "OpDhrH3pDxFU"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "class PrecomputedIJEPADataset(Dataset):\n",
        "    def __init__(self, base_dataset, context_scale=0.75, target_scale=0.2, num_targets=10, cache_file=None):\n",
        "        self.num_targets = num_targets  # Store num_targets for later use\n",
        "        self.cache_file = cache_file\n",
        "        if cache_file and os.path.exists(cache_file):\n",
        "            with open(cache_file, 'rb') as f:\n",
        "                self.data = pickle.load(f)\n",
        "        else:\n",
        "            if hasattr(base_dataset, 'samples'):\n",
        "                base_samples = [\n",
        "                    (base_dataset[i], base_dataset.samples[i][0])\n",
        "                    for i in tqdm(range(len(base_dataset)), desc=\"Loading samples\")\n",
        "                ]\n",
        "            else:\n",
        "                base_samples = [\n",
        "                    (sample, None) for sample in tqdm(base_dataset, desc=\"Loading samples\")\n",
        "                ]\n",
        "\n",
        "            self.data = []\n",
        "            for sample in tqdm(base_samples, desc=\"Processing samples\"):\n",
        "                result = process_sample(sample, context_scale, target_scale, num_targets)\n",
        "                self.data.append(result)\n",
        "\n",
        "            if cache_file:\n",
        "                with open(cache_file, 'wb') as f:\n",
        "                    pickle.dump(self.data, f)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:28:20.545426Z",
          "iopub.execute_input": "2025-04-04T05:28:20.545741Z",
          "iopub.status.idle": "2025-04-04T05:28:20.553810Z",
          "shell.execute_reply.started": "2025-04-04T05:28:20.545715Z",
          "shell.execute_reply": "2025-04-04T05:28:20.552811Z"
        },
        "id": "v6NvLO5NDxFU"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "cache_path = ijepa_raw_precumpted_full_dataset\n",
        "print(ijepa_raw_precumpted_full_dataset)\n",
        "print(cache_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:32:33.811719Z",
          "iopub.execute_input": "2025-04-04T05:32:33.812098Z",
          "iopub.status.idle": "2025-04-04T05:32:33.817562Z",
          "shell.execute_reply.started": "2025-04-04T05:32:33.812065Z",
          "shell.execute_reply": "2025-04-04T05:32:33.816602Z"
        },
        "id": "bLFk09WtDxFU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026a6acd-5840-4d3d-b7b4-0e8f522af77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AAVDATASET/1s_segment_raw/precomputed_fulldataset_aav_raw_colab_after_new_context_target.pkl\n",
            "/content/drive/MyDrive/AAVDATASET/1s_segment_raw/precomputed_fulldataset_aav_raw_colab_after_new_context_target.pkl\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# Timing the loading of the dataset and DataLoader\n",
        "#cache_path = os.path.join(base_dir,\"precomputed_fulldataset_aav_raw.pkl\")\n",
        "dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "start_time = time.time()\n",
        "# Create the precomputed dataset\n",
        "precomputed_dataset = PrecomputedIJEPADataset(dataset, context_scale=0.75, target_scale=0.2, num_targets=7, cache_file=cache_path)\n",
        "\n",
        "#dataset_aav_ijepa = PrecomputedIJEPADataset(dataset, cache_file=cache_path)\n",
        "end_time_train_ijepa_dataset = time.time()\n",
        "#dataloader_aav_ijepa = DataLoader(dataset_aav_ijepa, batch_size=32, shuffle=True)\n",
        "precomputed_dataloader = DataLoader(precomputed_dataset, batch_size=16, shuffle=True)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken to load dataset: {end_time_train_ijepa_dataset - start_time:.4f} seconds and DataLoader: {end_time - end_time_train_ijepa_dataset:.4f} seconds\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:32:36.922524Z",
          "iopub.execute_input": "2025-04-04T05:32:36.922898Z",
          "iopub.status.idle": "2025-04-04T05:33:20.418450Z",
          "shell.execute_reply.started": "2025-04-04T05:32:36.922868Z",
          "shell.execute_reply": "2025-04-04T05:33:20.417418Z"
        },
        "id": "76mLUmdPDxFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e804b6d4-5230-4aa4-875e-6a3446f95048"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading samples:  49%|████▉     | 1352/2732 [01:47<06:09,  3.74it/s]"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization: Sample n images from each class and display in a grid\n",
        "n_samples_per_class = 10  # Number of images to sample per class\n",
        "num_targets = 10  # Must match the value used in PrecomputedIJEPADataset\n",
        "class_names = ['Empty', 'Single', 'Double']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Group samples by class\n",
        "samples_by_class = {class_name: [] for class_name in class_names}\n",
        "for idx in range(len(precomputed_dataset)):\n",
        "    _, _, label, image_path, context_coords, target_coords = precomputed_dataset[idx]\n",
        "    class_name = class_names[label]\n",
        "    samples_by_class[class_name].append((image_path, context_coords, target_coords))\n",
        "\n",
        "# Sample n images from each class\n",
        "selected_samples = {}\n",
        "for class_name in class_names:\n",
        "    class_samples = samples_by_class[class_name]\n",
        "    if len(class_samples) >= n_samples_per_class:\n",
        "        selected_samples[class_name] = random.sample(class_samples, n_samples_per_class)\n",
        "    else:\n",
        "        print(f\"Warning: Not enough samples for class {class_name}. Found {len(class_samples)}, needed {n_samples_per_class}.\")\n",
        "        selected_samples[class_name] = class_samples\n",
        "\n",
        "# Create the visualization grid\n",
        "fig, axes = plt.subplots(num_classes, n_samples_per_class, figsize=(5 * n_samples_per_class, 5 * num_classes))\n",
        "\n",
        "# Ensure axes is 2D even if n_samples_per_class == 1\n",
        "if n_samples_per_class == 1:\n",
        "    axes = np.array([axes]).reshape(num_classes, 1)\n",
        "\n",
        "# Plot the images\n",
        "for row_idx, class_name in enumerate(class_names):\n",
        "    class_samples = selected_samples[class_name]\n",
        "\n",
        "    # If no samples for this class, display a placeholder\n",
        "    if not class_samples:\n",
        "        for col_idx in range(n_samples_per_class):\n",
        "            axes[row_idx, col_idx].text(0.5, 0.5, f\"No samples for {class_name}\",\n",
        "                                        ha='center', va='center', fontsize=12)\n",
        "            axes[row_idx, col_idx].axis(\"off\")\n",
        "        continue\n",
        "\n",
        "    # Pad with placeholders if fewer samples than n_samples_per_class\n",
        "    while len(class_samples) < n_samples_per_class:\n",
        "        class_samples.append((None, None, None))\n",
        "\n",
        "    for col_idx, (image_path, context_coords, target_coords) in enumerate(class_samples):\n",
        "        # Handle placeholder for missing samples\n",
        "        if image_path is None:\n",
        "            axes[row_idx, col_idx].text(0.5, 0.5, \"No sample\",\n",
        "                                        ha='center', va='center', fontsize=12)\n",
        "            axes[row_idx, col_idx].axis(\"off\")\n",
        "            continue\n",
        "\n",
        "        # Load the original image\n",
        "        img = Image.open(image_path).convert(\"RGB\")\n",
        "        img_np = np.array(img)\n",
        "\n",
        "        # Display the image\n",
        "        axes[row_idx, col_idx].imshow(img_np)\n",
        "\n",
        "        # Draw context block\n",
        "        if context_coords and context_coords != (0, 0, 0, 0):\n",
        "            cx, cy, cw, ch = context_coords\n",
        "            print(f\"context_records: {context_coords}\")\n",
        "            rect_context = patches.Rectangle((cx, cy), cw, ch, linewidth=2, edgecolor='blue', facecolor='none')\n",
        "            axes[row_idx, col_idx].add_patch(rect_context)\n",
        "        else:\n",
        "            print(f\"no context_records\")\n",
        "\n",
        "        # Draw target blocks\n",
        "        if target_coords and target_coords != [(0, 0, 0, 0)] * num_targets:\n",
        "            for idx, (tx, ty, tw, th) in enumerate(target_coords):\n",
        "                print(f\"target: {target_coords}\")\n",
        "                if (tx, ty, tw, th) == (0, 0, 0, 0):\n",
        "                    continue\n",
        "                rect_target = patches.Rectangle((tx, ty), tw, th, linewidth=2, edgecolor='black', facecolor='none')\n",
        "                axes[row_idx, col_idx].add_patch(rect_target)\n",
        "                axes[row_idx, col_idx].text(tx, ty, f\"{idx+1}\", color='black',\n",
        "                                            fontsize=12, fontweight='bold',\n",
        "                                            verticalalignment='top', horizontalalignment='left')\n",
        "        else:\n",
        "            print(f\"no target_records\")\n",
        "\n",
        "        # Set title\n",
        "        axes[row_idx, col_idx].set_title(f\"{class_name} #{col_idx+1}\")\n",
        "        axes[row_idx, col_idx].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Peemg-91Kyj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#precomputed_dataloader\n",
        "dataset_aav_ijepa = precomputed_dataset\n",
        "dataloader_aav_ijepa = precomputed_dataloader"
      ],
      "metadata": {
        "id": "XCE2KxUUu_z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_images = len(dataset_aav_ijepa)\n",
        "print(f\"Number of images in the dataset: {num_images}\")\n",
        "total_batches = len(dataloader_aav_ijepa)\n",
        "print(\"Total number of batches:\", total_batches)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:33:20.427471Z",
          "iopub.execute_input": "2025-04-04T05:33:20.427795Z",
          "iopub.status.idle": "2025-04-04T05:33:20.442212Z",
          "shell.execute_reply.started": "2025-04-04T05:33:20.427771Z",
          "shell.execute_reply": "2025-04-04T05:33:20.441162Z"
        },
        "id": "_Vd4NGVFDxFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542bf1d4-a22c-4db6-9ed2-103561584b57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the dataset: 2732\n",
            "Total number of batches: 171\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the labels from the dataset:\n",
        "labels = [sample[2] for sample in dataset_aav_ijepa.data]\n",
        "\n",
        "# Count the occurrences of each label using Counter:\n",
        "class_counts = Counter(labels)\n",
        "\n",
        "# Get the class labels and their corresponding counts:\n",
        "class_labels, counts = zip(*class_counts.items())\n",
        "\n",
        "# Create the bar graph:\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(class_labels, counts)\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.title(\"Number of Images per Class\")\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Add text labels above the bars:\n",
        "for i, count in enumerate(counts):\n",
        "    plt.text(class_labels[i], count + 5,  # Adjust vertical position as needed\n",
        "             str(count), ha='center', va='bottom')\n",
        "\n",
        "# Add text labels for class names below the x-axis:\n",
        "for i, label in enumerate(class_labels):\n",
        "    plt.text(label, -10,  # Adjust vertical position as needed\n",
        "             dataset.classes[label], ha='center', va='top', rotation=45)  # Assuming dataset has 'classes' attribute\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:33:20.443418Z",
          "iopub.execute_input": "2025-04-04T05:33:20.443830Z",
          "iopub.status.idle": "2025-04-04T05:33:20.780300Z",
          "shell.execute_reply.started": "2025-04-04T05:33:20.443797Z",
          "shell.execute_reply": "2025-04-04T05:33:20.779274Z"
        },
        "id": "j4ky6oiNDxFW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "outputId": "18846d90-e75a-40c3-c1d0-2b9d10b5b48b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Subset, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the split ratios (e.g., 70% train, 15% validation, 15% test)\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Get the total number of samples in the dataset.\n",
        "num_samples = len(dataset_aav_ijepa)\n",
        "\n",
        "# 1. Split into train and (validation + test)\n",
        "train_indices, val_test_indices = train_test_split(\n",
        "    list(range(num_samples)),\n",
        "    test_size=val_ratio + test_ratio,\n",
        "    random_state=42  # Set random_state for reproducibility\n",
        ")\n",
        "\n",
        "# 2. Split (validation + test) into validation and test\n",
        "val_indices, test_indices = train_test_split(\n",
        "    val_test_indices,\n",
        "    test_size=test_ratio / (val_ratio + test_ratio),\n",
        "    random_state=42  # Set random_state for reproducibility\n",
        ")\n",
        "\n",
        "# Create Subset datasets for train, validation, and test\n",
        "train_dataset_aav_ijepa = Subset(dataset_aav_ijepa, train_indices)\n",
        "val_dataset_aav_ijepa = Subset(dataset_aav_ijepa, val_indices)\n",
        "test_dataset_aav_ijepa = Subset(dataset_aav_ijepa, test_indices)\n",
        "\n",
        "# Create DataLoaders for train, validation, and test\n",
        "train_loader_aav_ijepa = torch.utils.data.DataLoader(train_dataset_aav_ijepa, batch_size=32, shuffle=True)\n",
        "val_loader_aav_ijepa = torch.utils.data.DataLoader(val_dataset_aav_ijepa, batch_size=32, shuffle=False)\n",
        "test_loader_aav_ijepa = torch.utils.data.DataLoader(test_dataset_aav_ijepa, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Training set size: {len(train_dataset_aav_ijepa)}\")\n",
        "print(f\"Validation set size: {len(val_dataset_aav_ijepa)}\")\n",
        "print(f\"Testing set size: {len(test_dataset_aav_ijepa)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:33:20.781426Z",
          "iopub.execute_input": "2025-04-04T05:33:20.781810Z",
          "iopub.status.idle": "2025-04-04T05:33:20.808153Z",
          "shell.execute_reply.started": "2025-04-04T05:33:20.781775Z",
          "shell.execute_reply": "2025-04-04T05:33:20.807131Z"
        },
        "id": "ELwkN5YhDxFW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e895f636-5ef5-405c-b22e-6fa89f15c3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 1912\n",
            "Validation set size: 410\n",
            "Testing set size: 410\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VIT based i-jpea"
      ],
      "metadata": {
        "id": "Km6L8fvfyblv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def get_vit_encoder():\n",
        "#    model = vit_b_16(pretrained=False)\n",
        "#    model.heads = nn.Identity()  # remove classification head\n",
        "#    return model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:36:10.149971Z",
          "iopub.execute_input": "2025-04-04T05:36:10.150327Z",
          "iopub.status.idle": "2025-04-04T05:36:10.154875Z",
          "shell.execute_reply.started": "2025-04-04T05:36:10.150299Z",
          "shell.execute_reply": "2025-04-04T05:36:10.153920Z"
        },
        "id": "BpKuWrxPDxFX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#context_encoder = get_vit_encoder().cuda()\n",
        "#target_encoder  = get_vit_encoder().cuda()\n",
        "#target_encoder.load_state_dict(context_encoder.state_dict())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:36:12.587240Z",
          "iopub.execute_input": "2025-04-04T05:36:12.587568Z",
          "iopub.status.idle": "2025-04-04T05:36:15.551009Z",
          "shell.execute_reply.started": "2025-04-04T05:36:12.587544Z",
          "shell.execute_reply": "2025-04-04T05:36:15.550154Z"
        },
        "id": "_wAphvj1DxFX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "'''class Predictor(nn.Module):\n",
        "    def __init__(self, input_dim=768, hidden_dim=768, output_dim=768, num_targets=4):\n",
        "        super().__init__()\n",
        "        self.num_targets = num_targets\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim * num_targets)\n",
        "        )\n",
        "    def forward(self, context_repr):\n",
        "        pred = self.mlp(context_repr)\n",
        "        # Reshape to [B, num_targets, output_dim]\n",
        "        return pred.view(-1, self.num_targets, pred.size(-1) // self.num_targets)'''"
      ],
      "metadata": {
        "id": "wX3BWeORGpvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet50"
      ],
      "metadata": {
        "id": "YhA8NzTLygaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import models\n",
        "\n",
        "'''def get_resnet_encoder():\n",
        "    # Instantiate a ResNet50 and remove its classification head.\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    model.fc = nn.Identity()  # Remove the fully-connected layer.\n",
        "    return model'''"
      ],
      "metadata": {
        "id": "YKIayXbjyDa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Predictor to use the new feature dimension (2048 for ResNet50)\n",
        "'''class Predictor(nn.Module):\n",
        "    def __init__(self, input_dim=2048, hidden_dim=2048, output_dim=2048, num_targets=4):\n",
        "        super().__init__()\n",
        "        self.num_targets = num_targets\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim * num_targets)\n",
        "        )\n",
        "    def forward(self, context_repr):\n",
        "        pred = self.mlp(context_repr)\n",
        "        # Reshape output to [B, num_targets, output_dim]\n",
        "        return pred.view(-1, self.num_targets, pred.size(-1) // self.num_targets)'''\n"
      ],
      "metadata": {
        "id": "UFc9lSJ0yZ5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace the previous get_vit_encoder() calls with get_resnet_encoder()\n",
        "'''context_encoder = get_resnet_encoder().cuda()\n",
        "target_encoder  = get_resnet_encoder().cuda()\n",
        "# Initialize the target encoder with the context encoder's weights.\n",
        "target_encoder.load_state_dict(context_encoder.state_dict())'''"
      ],
      "metadata": {
        "id": "Z-PGr2OoyXV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''predictor = Predictor().cuda()\n",
        "optimizer = optim.Adam(list(context_encoder.parameters()) + list(predictor.parameters()), lr=1e-1)\n",
        "criterion = nn.MSELoss()'''"
      ],
      "metadata": {
        "id": "D8fvUG6zGujO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''@torch.no_grad()\n",
        "def update_ema(model, model_ema, beta):\n",
        "    for param, param_ema in zip(model.parameters(), model_ema.parameters()):\n",
        "        param_ema.data.mul_(beta).add_(param.data, alpha=1 - beta)'''"
      ],
      "metadata": {
        "id": "OG9fcIgR0lOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EfficientNet B2"
      ],
      "metadata": {
        "id": "vaoz8ojiKvAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import efficientnet_b2\n",
        "def get_efficientnet_encoder():\n",
        "    # Load EfficientNet B2 pretrained model and remove its classifier.\n",
        "    model = efficientnet_b2(pretrained=True)\n",
        "    model.classifier = nn.Identity()\n",
        "    return model"
      ],
      "metadata": {
        "id": "nHVTPWtaKwx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_encoder = get_efficientnet_encoder().cuda()\n",
        "target_encoder  = get_efficientnet_encoder().cuda()\n",
        "target_encoder.load_state_dict(context_encoder.state_dict())"
      ],
      "metadata": {
        "id": "_jJ0TTZeKybh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40690317-81cc-4c06-9e8e-353bedbc5dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 138MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Predictor to use input_dim=1408 (EfficientNet B2's feature dimension)\n",
        "class Predictor(nn.Module):\n",
        "    def __init__(self, input_dim=1408, hidden_dim=1408, output_dim=1408, num_targets=4):\n",
        "        super().__init__()\n",
        "        self.num_targets = num_targets\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, output_dim * num_targets)\n",
        "        )\n",
        "    def forward(self, context_repr):\n",
        "        pred = self.mlp(context_repr)\n",
        "        return pred.view(-1, self.num_targets, pred.size(-1) // self.num_targets)\n",
        "\n",
        "predictor = Predictor(num_targets=7).cuda()\n",
        "\n",
        "# Set up optimizer, criterion, and EMA update.\n",
        "optimizer = optim.Adam(list(context_encoder.parameters()) + list(predictor.parameters()), lr=0.01)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "DfoZh2KaK19g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def update_ema(model, model_ema, beta):\n",
        "    for param, param_ema in zip(model.parameters(), model_ema.parameters()):\n",
        "        param_ema.data.mul_(beta).add_(param.data, alpha=1-beta)"
      ],
      "metadata": {
        "id": "hRZG0IUGK4P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Supervised i-JEPA Training with Validation Evaluation"
      ],
      "metadata": {
        "id": "mKdmXQ2LzOpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 500\n",
        "ema_decay = 0.9\n",
        "best_loss = float('inf')\n",
        "total_start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    context_encoder.train()\n",
        "    predictor.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Enumerate over batches with a progress bar.\n",
        "    for batch_idx, (context_block, target_blocks, _, _, _, _) in enumerate(tqdm(train_loader_aav_ijepa, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)):\n",
        "        context_block = context_block.cuda()            # [B, C, 224, 224]\n",
        "        target_blocks = torch.stack(target_blocks, dim=1).cuda()\n",
        "        #target_blocks = [tb.cuda() for tb in target_blocks]\n",
        "        #target_blocks = target_blocks.cuda()              # [B, num_targets, C, 224, 224]\n",
        "\n",
        "        # Forward pass through context encoder and predictor.\n",
        "        context_repr = context_encoder(context_block)     # [B, 768]\n",
        "        preds = predictor(context_repr)                   # [B, num_targets, 768]\n",
        "\n",
        "        B, num_targets, C, Ht, Wt = target_blocks.shape\n",
        "        target_blocks_flat = target_blocks.view(B * num_targets, C, Ht, Wt)\n",
        "        with torch.no_grad():\n",
        "            target_repr_flat = target_encoder(target_blocks_flat)\n",
        "        target_repr = target_repr_flat.view(B, num_targets, -1)\n",
        "\n",
        "        loss = criterion(preds, target_repr)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        update_ema(context_encoder, target_encoder, ema_decay)\n",
        "        running_loss += loss.item() * context_block.size(0)\n",
        "\n",
        "        # --- Visualization for first image of the current batch ---\n",
        "        '''with torch.no_grad():\n",
        "            # Get the first sample's context block and compute its feature vector.\n",
        "            context_img = context_block[0].cpu()  # shape: [C, 224, 224]\n",
        "            context_feat = context_encoder(context_block[0].unsqueeze(0)).cpu().squeeze(0)  # shape: [768]\n",
        "            # Reshape feature vector to a 2D heatmap (24x32).\n",
        "            context_heat = context_feat.view(24, 32).numpy()\n",
        "\n",
        "            # For target, choose the first target block of the first sample.\n",
        "            target_img = target_blocks[0][0].cpu()  # shape: [C, 224, 224]\n",
        "            target_feat = target_encoder(target_blocks[0][0].unsqueeze(0).to(context_block.device)).cpu().squeeze(0)\n",
        "            target_heat = target_feat.view(24, 32).numpy()\n",
        "\n",
        "            # Plot the images and corresponding heatmaps.\n",
        "            fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "            # Display context block image.\n",
        "            if context_img.shape[0] == 1:\n",
        "                axs[0, 0].imshow(context_img.squeeze(), cmap='gray')\n",
        "            else:\n",
        "                axs[0, 0].imshow(context_img.permute(1, 2, 0))\n",
        "            axs[0, 0].set_title(\"Context Block\")\n",
        "            axs[0, 0].axis(\"off\")\n",
        "\n",
        "            # Display context feature heatmap.\n",
        "            im0 = axs[0, 1].imshow(context_heat, cmap=\"viridis\")\n",
        "            axs[0, 1].set_title(\"Context Feature Heatmap\")\n",
        "            axs[0, 1].axis(\"off\")\n",
        "            fig.colorbar(im0, ax=axs[0, 1])\n",
        "\n",
        "            # Display target block image.\n",
        "            if target_img.shape[0] == 1:\n",
        "                axs[1, 0].imshow(target_img.squeeze(), cmap='gray')\n",
        "            else:\n",
        "                axs[1, 0].imshow(target_img.permute(1, 2, 0))\n",
        "            axs[1, 0].set_title(\"Target Block\")\n",
        "            axs[1, 0].axis(\"off\")\n",
        "\n",
        "            # Display target feature heatmap.\n",
        "            im1 = axs[1, 1].imshow(target_heat, cmap=\"viridis\")\n",
        "            axs[1, 1].set_title(\"Target Feature Heatmap\")\n",
        "            axs[1, 1].axis(\"off\")\n",
        "            fig.colorbar(im1, ax=axs[1, 1])\n",
        "\n",
        "            # Save the visualization figure with epoch and batch number.\n",
        "            viz_path = os.path.join(viz_dir, f\"epoch{epoch+1}_batch{batch_idx+1}.png\")\n",
        "            plt.savefig(viz_path)\n",
        "            plt.close(fig)'''\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset_aav_ijepa)\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.10f} - Epoch Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # Save checkpoint if current epoch loss is lower than previous best.\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        checkpoint = {\n",
        "            'epoch': epoch+1,\n",
        "            'context_encoder_state_dict': context_encoder.state_dict(),\n",
        "            'target_encoder_state_dict': target_encoder.state_dict(),\n",
        "            'predictor_state_dict': predictor.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': epoch_loss\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join(base_dir,f\"best_efficientnet_b2_model_raw_ema_{ema_decay}_lr_0.001_new_context_target.pth\"))\n",
        "        print(f\"Checkpoint saved at epoch {epoch+1} with loss {epoch_loss:.4f}\")\n",
        "\n",
        "\n",
        "total_train_time = time.time() - total_start_time\n",
        "print(f\"Total Training Time: {total_train_time:.2f}s\")"
      ],
      "metadata": {
        "id": "kpwrFmpPgJSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef0074d-e34b-4a71-f53b-999b0f507e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500 - Train Loss: 0.5883350119 - Epoch Time: 13.27s\n",
            "Checkpoint saved at epoch 1 with loss 0.5883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/500 - Train Loss: 0.0120822732 - Epoch Time: 13.34s\n",
            "Checkpoint saved at epoch 2 with loss 0.0121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/500 - Train Loss: 0.0118398149 - Epoch Time: 13.36s\n",
            "Checkpoint saved at epoch 3 with loss 0.0118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/500 - Train Loss: 0.0121287198 - Epoch Time: 13.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/500 - Train Loss: 0.0104142404 - Epoch Time: 13.41s\n",
            "Checkpoint saved at epoch 5 with loss 0.0104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/500 - Train Loss: 0.0100255906 - Epoch Time: 13.39s\n",
            "Checkpoint saved at epoch 6 with loss 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/500 - Train Loss: 0.0099769099 - Epoch Time: 13.29s\n",
            "Checkpoint saved at epoch 7 with loss 0.0100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/500 - Train Loss: 0.0096138557 - Epoch Time: 13.28s\n",
            "Checkpoint saved at epoch 8 with loss 0.0096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/500 - Train Loss: 0.0094756970 - Epoch Time: 13.34s\n",
            "Checkpoint saved at epoch 9 with loss 0.0095\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/500 - Train Loss: 0.0091686370 - Epoch Time: 13.16s\n",
            "Checkpoint saved at epoch 10 with loss 0.0092\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/500 - Train Loss: 0.0098000998 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/500 - Train Loss: 0.0102206073 - Epoch Time: 13.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/500 - Train Loss: 0.0102747185 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/500 - Train Loss: 0.0103961411 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/500 - Train Loss: 0.0097002739 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/500 - Train Loss: 0.0095543653 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/500 - Train Loss: 0.0086957539 - Epoch Time: 13.39s\n",
            "Checkpoint saved at epoch 17 with loss 0.0087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/500 - Train Loss: 0.0084089273 - Epoch Time: 13.20s\n",
            "Checkpoint saved at epoch 18 with loss 0.0084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/500 - Train Loss: 0.0083205908 - Epoch Time: 13.17s\n",
            "Checkpoint saved at epoch 19 with loss 0.0083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/500 - Train Loss: 0.0083324698 - Epoch Time: 13.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/500 - Train Loss: 0.0082594364 - Epoch Time: 13.20s\n",
            "Checkpoint saved at epoch 21 with loss 0.0083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/500 - Train Loss: 0.0081954301 - Epoch Time: 13.16s\n",
            "Checkpoint saved at epoch 22 with loss 0.0082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/500 - Train Loss: 0.0084016891 - Epoch Time: 13.13s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/500 - Train Loss: 0.0087156304 - Epoch Time: 13.48s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/500 - Train Loss: 0.0101292436 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/500 - Train Loss: 0.0100825932 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/500 - Train Loss: 0.0096233834 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/500 - Train Loss: 0.0091337639 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/500 - Train Loss: 0.0085395646 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/500 - Train Loss: 0.0081153851 - Epoch Time: 13.36s\n",
            "Checkpoint saved at epoch 30 with loss 0.0081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/500 - Train Loss: 0.0077953014 - Epoch Time: 13.25s\n",
            "Checkpoint saved at epoch 31 with loss 0.0078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/500 - Train Loss: 0.0077973973 - Epoch Time: 13.19s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/500 - Train Loss: 0.0074306525 - Epoch Time: 13.44s\n",
            "Checkpoint saved at epoch 33 with loss 0.0074\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/500 - Train Loss: 0.0070386807 - Epoch Time: 13.40s\n",
            "Checkpoint saved at epoch 34 with loss 0.0070\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/500 - Train Loss: 0.0072801000 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/500 - Train Loss: 0.0069402171 - Epoch Time: 13.25s\n",
            "Checkpoint saved at epoch 36 with loss 0.0069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/500 - Train Loss: 0.0064433469 - Epoch Time: 13.24s\n",
            "Checkpoint saved at epoch 37 with loss 0.0064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38/500 - Train Loss: 0.0066020447 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39/500 - Train Loss: 0.0066187741 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40/500 - Train Loss: 0.0063497680 - Epoch Time: 13.26s\n",
            "Checkpoint saved at epoch 40 with loss 0.0063\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41/500 - Train Loss: 0.0065667619 - Epoch Time: 13.18s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42/500 - Train Loss: 0.0061755639 - Epoch Time: 13.47s\n",
            "Checkpoint saved at epoch 42 with loss 0.0062\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43/500 - Train Loss: 0.0062447122 - Epoch Time: 13.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44/500 - Train Loss: 0.0061180417 - Epoch Time: 13.23s\n",
            "Checkpoint saved at epoch 44 with loss 0.0061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45/500 - Train Loss: 0.0063462524 - Epoch Time: 13.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46/500 - Train Loss: 0.0062480553 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47/500 - Train Loss: 0.0061358181 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48/500 - Train Loss: 0.0060865648 - Epoch Time: 13.23s\n",
            "Checkpoint saved at epoch 48 with loss 0.0061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49/500 - Train Loss: 0.0061430426 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50/500 - Train Loss: 0.0067676492 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51/500 - Train Loss: 0.0057253642 - Epoch Time: 13.48s\n",
            "Checkpoint saved at epoch 51 with loss 0.0057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52/500 - Train Loss: 0.0060467827 - Epoch Time: 13.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53/500 - Train Loss: 0.0061666932 - Epoch Time: 13.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54/500 - Train Loss: 0.0057904902 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55/500 - Train Loss: 0.0062359423 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56/500 - Train Loss: 0.0059942340 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57/500 - Train Loss: 0.0056748947 - Epoch Time: 13.33s\n",
            "Checkpoint saved at epoch 57 with loss 0.0057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58/500 - Train Loss: 0.0058224258 - Epoch Time: 13.20s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/500 - Train Loss: 0.0054445809 - Epoch Time: 13.23s\n",
            "Checkpoint saved at epoch 59 with loss 0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60/500 - Train Loss: 0.0054399357 - Epoch Time: 13.20s\n",
            "Checkpoint saved at epoch 60 with loss 0.0054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61/500 - Train Loss: 0.0052653468 - Epoch Time: 13.27s\n",
            "Checkpoint saved at epoch 61 with loss 0.0053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62/500 - Train Loss: 0.0055184504 - Epoch Time: 13.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63/500 - Train Loss: 0.0053636322 - Epoch Time: 13.16s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64/500 - Train Loss: 0.0055265239 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65/500 - Train Loss: 0.0054063652 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66/500 - Train Loss: 0.0052204321 - Epoch Time: 13.34s\n",
            "Checkpoint saved at epoch 66 with loss 0.0052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67/500 - Train Loss: 0.0049866535 - Epoch Time: 13.24s\n",
            "Checkpoint saved at epoch 67 with loss 0.0050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68/500 - Train Loss: 0.0051704243 - Epoch Time: 13.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69/500 - Train Loss: 0.0049774087 - Epoch Time: 13.29s\n",
            "Checkpoint saved at epoch 69 with loss 0.0050\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70/500 - Train Loss: 0.0050595061 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71/500 - Train Loss: 0.0050952420 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72/500 - Train Loss: 0.0050438017 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73/500 - Train Loss: 0.0051020596 - Epoch Time: 13.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74/500 - Train Loss: 0.0050018960 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75/500 - Train Loss: 0.0050723684 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76/500 - Train Loss: 0.0050491323 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77/500 - Train Loss: 0.0051628844 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78/500 - Train Loss: 0.0051582877 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79/500 - Train Loss: 0.0051894681 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80/500 - Train Loss: 0.0051671991 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81/500 - Train Loss: 0.0051935790 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82/500 - Train Loss: 0.0051254715 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83/500 - Train Loss: 0.0053299685 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84/500 - Train Loss: 0.0053032014 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85/500 - Train Loss: 0.0053191044 - Epoch Time: 13.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86/500 - Train Loss: 0.0053245256 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87/500 - Train Loss: 0.0052738477 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88/500 - Train Loss: 0.0052599204 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89/500 - Train Loss: 0.0053493474 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90/500 - Train Loss: 0.0051348908 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91/500 - Train Loss: 0.0051606634 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92/500 - Train Loss: 0.0052434870 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93/500 - Train Loss: 0.0052776221 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94/500 - Train Loss: 0.0053885587 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95/500 - Train Loss: 0.0052745360 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96/500 - Train Loss: 0.0053567170 - Epoch Time: 13.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97/500 - Train Loss: 0.0051364985 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98/500 - Train Loss: 0.0051887694 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99/500 - Train Loss: 0.0051362513 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100/500 - Train Loss: 0.0053633031 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101/500 - Train Loss: 0.0053029047 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 102/500 - Train Loss: 0.0050599665 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 103/500 - Train Loss: 0.0051390212 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 104/500 - Train Loss: 0.0051534445 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 105/500 - Train Loss: 0.0054251520 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 106/500 - Train Loss: 0.0051673067 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 107/500 - Train Loss: 0.0053524025 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 108/500 - Train Loss: 0.0052837264 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 109/500 - Train Loss: 0.0052446040 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 110/500 - Train Loss: 0.0053824367 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 111/500 - Train Loss: 0.0051483315 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 112/500 - Train Loss: 0.0055245364 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 113/500 - Train Loss: 0.0052319423 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 114/500 - Train Loss: 0.0051334339 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 115/500 - Train Loss: 0.0052796735 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 116/500 - Train Loss: 0.0051606404 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 117/500 - Train Loss: 0.0051983552 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 118/500 - Train Loss: 0.0051747747 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 119/500 - Train Loss: 0.0051427608 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 120/500 - Train Loss: 0.0052942000 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 121/500 - Train Loss: 0.0050983806 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 122/500 - Train Loss: 0.0051082147 - Epoch Time: 13.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 123/500 - Train Loss: 0.0053895129 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 124/500 - Train Loss: 0.0054607007 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 125/500 - Train Loss: 0.0052645028 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 126/500 - Train Loss: 0.0053445883 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 127/500 - Train Loss: 0.0053450667 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 128/500 - Train Loss: 0.0052019276 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 129/500 - Train Loss: 0.0055664345 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 130/500 - Train Loss: 0.0052077219 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 131/500 - Train Loss: 0.0052287474 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 132/500 - Train Loss: 0.0055367866 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 133/500 - Train Loss: 0.0053092344 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 134/500 - Train Loss: 0.0052467807 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 135/500 - Train Loss: 0.0053881727 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 136/500 - Train Loss: 0.0051994586 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 137/500 - Train Loss: 0.0052954947 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 138/500 - Train Loss: 0.0052189098 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 139/500 - Train Loss: 0.0052442995 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 140/500 - Train Loss: 0.0053347028 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 141/500 - Train Loss: 0.0053935985 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 142/500 - Train Loss: 0.0051521808 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 143/500 - Train Loss: 0.0052503175 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 144/500 - Train Loss: 0.0050247682 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 145/500 - Train Loss: 0.0053164982 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 146/500 - Train Loss: 0.0052189172 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 147/500 - Train Loss: 0.0053792000 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 148/500 - Train Loss: 0.0052586407 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 149/500 - Train Loss: 0.0051626441 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 150/500 - Train Loss: 0.0051318904 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 151/500 - Train Loss: 0.0053400970 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 152/500 - Train Loss: 0.0054640372 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 153/500 - Train Loss: 0.0053932626 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 154/500 - Train Loss: 0.0051745888 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 155/500 - Train Loss: 0.0051516990 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 156/500 - Train Loss: 0.0053218494 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 157/500 - Train Loss: 0.0051731860 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 158/500 - Train Loss: 0.0052365372 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 159/500 - Train Loss: 0.0052516825 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 160/500 - Train Loss: 0.0052536582 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 161/500 - Train Loss: 0.0053421708 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 162/500 - Train Loss: 0.0052252318 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 163/500 - Train Loss: 0.0052650378 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 164/500 - Train Loss: 0.0052954926 - Epoch Time: 13.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 165/500 - Train Loss: 0.0052022070 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 166/500 - Train Loss: 0.0052027642 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 167/500 - Train Loss: 0.0051712583 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 168/500 - Train Loss: 0.0052818718 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 169/500 - Train Loss: 0.0051892827 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 170/500 - Train Loss: 0.0052996852 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 171/500 - Train Loss: 0.0051433083 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 172/500 - Train Loss: 0.0051979259 - Epoch Time: 13.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 173/500 - Train Loss: 0.0052818476 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 174/500 - Train Loss: 0.0052541047 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 175/500 - Train Loss: 0.0053237715 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 176/500 - Train Loss: 0.0053344785 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 177/500 - Train Loss: 0.0052882583 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 178/500 - Train Loss: 0.0053260850 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 179/500 - Train Loss: 0.0052736476 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 180/500 - Train Loss: 0.0053384853 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 181/500 - Train Loss: 0.0052388208 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 182/500 - Train Loss: 0.0053449851 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 183/500 - Train Loss: 0.0051743759 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 184/500 - Train Loss: 0.0053589445 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 185/500 - Train Loss: 0.0051934196 - Epoch Time: 13.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 186/500 - Train Loss: 0.0051781723 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 187/500 - Train Loss: 0.0052298483 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 188/500 - Train Loss: 0.0053906234 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 189/500 - Train Loss: 0.0052906585 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 190/500 - Train Loss: 0.0052658065 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 191/500 - Train Loss: 0.0053191592 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 192/500 - Train Loss: 0.0052041926 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 193/500 - Train Loss: 0.0050913296 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 194/500 - Train Loss: 0.0053391399 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 195/500 - Train Loss: 0.0052725948 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 196/500 - Train Loss: 0.0053567437 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 197/500 - Train Loss: 0.0053371834 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 198/500 - Train Loss: 0.0052244454 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 199/500 - Train Loss: 0.0053316237 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 200/500 - Train Loss: 0.0052381814 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 201/500 - Train Loss: 0.0052316834 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 202/500 - Train Loss: 0.0055381022 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 203/500 - Train Loss: 0.0052012808 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 204/500 - Train Loss: 0.0052599785 - Epoch Time: 13.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 205/500 - Train Loss: 0.0052543742 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 206/500 - Train Loss: 0.0051517230 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 207/500 - Train Loss: 0.0051955978 - Epoch Time: 13.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 208/500 - Train Loss: 0.0054975378 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 209/500 - Train Loss: 0.0053600581 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 210/500 - Train Loss: 0.0053750389 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 211/500 - Train Loss: 0.0050997371 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 212/500 - Train Loss: 0.0052606630 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 213/500 - Train Loss: 0.0053608590 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 214/500 - Train Loss: 0.0051655359 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 215/500 - Train Loss: 0.0052704781 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 216/500 - Train Loss: 0.0052906067 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 217/500 - Train Loss: 0.0054404641 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 218/500 - Train Loss: 0.0050404921 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 219/500 - Train Loss: 0.0052365096 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 220/500 - Train Loss: 0.0052188560 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 221/500 - Train Loss: 0.0053191153 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 222/500 - Train Loss: 0.0052738589 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 223/500 - Train Loss: 0.0051196226 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 224/500 - Train Loss: 0.0053138492 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 225/500 - Train Loss: 0.0051918148 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 226/500 - Train Loss: 0.0053491128 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 227/500 - Train Loss: 0.0051617547 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 228/500 - Train Loss: 0.0052401929 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 229/500 - Train Loss: 0.0052322817 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 230/500 - Train Loss: 0.0052734958 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 231/500 - Train Loss: 0.0052720801 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 232/500 - Train Loss: 0.0052845447 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 233/500 - Train Loss: 0.0050990256 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 234/500 - Train Loss: 0.0051861517 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 235/500 - Train Loss: 0.0052137785 - Epoch Time: 13.50s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 236/500 - Train Loss: 0.0051800851 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 237/500 - Train Loss: 0.0052464321 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 238/500 - Train Loss: 0.0052932379 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 239/500 - Train Loss: 0.0052968805 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 240/500 - Train Loss: 0.0052501254 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 241/500 - Train Loss: 0.0052225467 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 242/500 - Train Loss: 0.0050991051 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 243/500 - Train Loss: 0.0053897723 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 244/500 - Train Loss: 0.0053392471 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 245/500 - Train Loss: 0.0053384335 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 246/500 - Train Loss: 0.0052585737 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 247/500 - Train Loss: 0.0053543266 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 248/500 - Train Loss: 0.0053930575 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 249/500 - Train Loss: 0.0051503980 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 250/500 - Train Loss: 0.0053074226 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 251/500 - Train Loss: 0.0053892837 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 252/500 - Train Loss: 0.0054447409 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 253/500 - Train Loss: 0.0052389303 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 254/500 - Train Loss: 0.0051327521 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 255/500 - Train Loss: 0.0052476289 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 256/500 - Train Loss: 0.0053131256 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 257/500 - Train Loss: 0.0053977176 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 258/500 - Train Loss: 0.0052392081 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 259/500 - Train Loss: 0.0051996416 - Epoch Time: 13.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 260/500 - Train Loss: 0.0052307226 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 261/500 - Train Loss: 0.0052130604 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 262/500 - Train Loss: 0.0053121448 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 263/500 - Train Loss: 0.0052748106 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 264/500 - Train Loss: 0.0050827672 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 265/500 - Train Loss: 0.0053432030 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 266/500 - Train Loss: 0.0052531243 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 267/500 - Train Loss: 0.0052211114 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 268/500 - Train Loss: 0.0051467851 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 269/500 - Train Loss: 0.0053510107 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 270/500 - Train Loss: 0.0053069214 - Epoch Time: 13.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 271/500 - Train Loss: 0.0051532610 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 272/500 - Train Loss: 0.0053709921 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 273/500 - Train Loss: 0.0053442969 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 274/500 - Train Loss: 0.0052849882 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 275/500 - Train Loss: 0.0052244206 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 276/500 - Train Loss: 0.0052374617 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 277/500 - Train Loss: 0.0053724775 - Epoch Time: 13.49s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 278/500 - Train Loss: 0.0053021875 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 279/500 - Train Loss: 0.0052154588 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 280/500 - Train Loss: 0.0051962519 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 281/500 - Train Loss: 0.0053000945 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 282/500 - Train Loss: 0.0051164548 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 283/500 - Train Loss: 0.0051601018 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 284/500 - Train Loss: 0.0052858350 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 285/500 - Train Loss: 0.0050919290 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 286/500 - Train Loss: 0.0051165832 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 287/500 - Train Loss: 0.0053704786 - Epoch Time: 13.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 288/500 - Train Loss: 0.0052848561 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 289/500 - Train Loss: 0.0053756527 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 290/500 - Train Loss: 0.0052215112 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 291/500 - Train Loss: 0.0052040475 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 292/500 - Train Loss: 0.0051512347 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 293/500 - Train Loss: 0.0053180135 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 294/500 - Train Loss: 0.0051914046 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 295/500 - Train Loss: 0.0052455674 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 296/500 - Train Loss: 0.0053324472 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 297/500 - Train Loss: 0.0051163553 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 298/500 - Train Loss: 0.0051831728 - Epoch Time: 13.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 299/500 - Train Loss: 0.0053745700 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 300/500 - Train Loss: 0.0053029258 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 301/500 - Train Loss: 0.0053687327 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 302/500 - Train Loss: 0.0052752501 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 303/500 - Train Loss: 0.0050833169 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 304/500 - Train Loss: 0.0053398782 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 305/500 - Train Loss: 0.0052964331 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 306/500 - Train Loss: 0.0052751150 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 307/500 - Train Loss: 0.0051448909 - Epoch Time: 13.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 308/500 - Train Loss: 0.0052295232 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 309/500 - Train Loss: 0.0052506276 - Epoch Time: 13.66s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 310/500 - Train Loss: 0.0051877179 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 311/500 - Train Loss: 0.0051207334 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 312/500 - Train Loss: 0.0051684824 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 313/500 - Train Loss: 0.0053798542 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 314/500 - Train Loss: 0.0052265594 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 315/500 - Train Loss: 0.0052668317 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 316/500 - Train Loss: 0.0053468764 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 317/500 - Train Loss: 0.0053619750 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 318/500 - Train Loss: 0.0053359144 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 319/500 - Train Loss: 0.0053226852 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 320/500 - Train Loss: 0.0052102655 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 321/500 - Train Loss: 0.0051701408 - Epoch Time: 13.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 322/500 - Train Loss: 0.0051791054 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 323/500 - Train Loss: 0.0053245019 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 324/500 - Train Loss: 0.0051395795 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 325/500 - Train Loss: 0.0052355156 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 326/500 - Train Loss: 0.0053182224 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 327/500 - Train Loss: 0.0053143033 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 328/500 - Train Loss: 0.0054786754 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 329/500 - Train Loss: 0.0053418440 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 330/500 - Train Loss: 0.0051557585 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 331/500 - Train Loss: 0.0053555093 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 332/500 - Train Loss: 0.0054017228 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 333/500 - Train Loss: 0.0053969933 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 334/500 - Train Loss: 0.0052493038 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 335/500 - Train Loss: 0.0053325499 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 336/500 - Train Loss: 0.0054894839 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 337/500 - Train Loss: 0.0052819068 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 338/500 - Train Loss: 0.0051562070 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 339/500 - Train Loss: 0.0053006910 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 340/500 - Train Loss: 0.0053150930 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 341/500 - Train Loss: 0.0052263324 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 342/500 - Train Loss: 0.0052777508 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 343/500 - Train Loss: 0.0052759800 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 344/500 - Train Loss: 0.0053024248 - Epoch Time: 13.47s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 345/500 - Train Loss: 0.0052932685 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 346/500 - Train Loss: 0.0055200245 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 347/500 - Train Loss: 0.0052767637 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 348/500 - Train Loss: 0.0051525383 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 349/500 - Train Loss: 0.0051900439 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 350/500 - Train Loss: 0.0053363221 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 351/500 - Train Loss: 0.0052978892 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 352/500 - Train Loss: 0.0053315145 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 353/500 - Train Loss: 0.0054483363 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 354/500 - Train Loss: 0.0051875663 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 355/500 - Train Loss: 0.0052663220 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 356/500 - Train Loss: 0.0052653959 - Epoch Time: 13.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 357/500 - Train Loss: 0.0052277383 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 358/500 - Train Loss: 0.0054723789 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 359/500 - Train Loss: 0.0052633517 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 360/500 - Train Loss: 0.0052852547 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 361/500 - Train Loss: 0.0052402146 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 362/500 - Train Loss: 0.0051192742 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 363/500 - Train Loss: 0.0816942046 - Epoch Time: 13.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 364/500 - Train Loss: 2.3803866060 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 365/500 - Train Loss: 0.0334754868 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 366/500 - Train Loss: 0.0333682370 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 367/500 - Train Loss: 0.0327517441 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 368/500 - Train Loss: 0.0336318142 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 369/500 - Train Loss: 0.0334622955 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 370/500 - Train Loss: 0.0342832995 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 371/500 - Train Loss: 0.0359339173 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 372/500 - Train Loss: 0.0331100808 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 373/500 - Train Loss: 0.0347315343 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 374/500 - Train Loss: 0.0349562980 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 375/500 - Train Loss: 0.0352146332 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 376/500 - Train Loss: 0.0349095171 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 377/500 - Train Loss: 0.0327742623 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 378/500 - Train Loss: 0.0349021869 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 379/500 - Train Loss: 0.0324530813 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 380/500 - Train Loss: 0.0344368919 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 381/500 - Train Loss: 19.7915809715 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 382/500 - Train Loss: 0.1667141987 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 383/500 - Train Loss: 0.0343502484 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 384/500 - Train Loss: 0.0333611871 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 385/500 - Train Loss: 0.0327874522 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 386/500 - Train Loss: 0.0352739674 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 387/500 - Train Loss: 0.0325687455 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 388/500 - Train Loss: 0.0310398566 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 389/500 - Train Loss: 0.0328514404 - Epoch Time: 13.50s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 390/500 - Train Loss: 0.0327066690 - Epoch Time: 13.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 391/500 - Train Loss: 0.0362843760 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 392/500 - Train Loss: 0.0317186687 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 393/500 - Train Loss: 0.0325405323 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 394/500 - Train Loss: 0.0322965763 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 395/500 - Train Loss: 0.0334409756 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 396/500 - Train Loss: 0.0328971215 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 397/500 - Train Loss: 0.0341267456 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 398/500 - Train Loss: 0.0320834862 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 399/500 - Train Loss: 0.0337249462 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 400/500 - Train Loss: 0.0335587254 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 401/500 - Train Loss: 0.0330257293 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 402/500 - Train Loss: 0.0334267788 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 403/500 - Train Loss: 0.0342032736 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 404/500 - Train Loss: 0.0347259436 - Epoch Time: 13.46s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 405/500 - Train Loss: 0.0337881820 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 406/500 - Train Loss: 0.0321762856 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 407/500 - Train Loss: 0.0332950788 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 408/500 - Train Loss: 0.0333592448 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 409/500 - Train Loss: 0.0314240660 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 410/500 - Train Loss: 0.0329050128 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 411/500 - Train Loss: 0.0324802073 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 412/500 - Train Loss: 0.0332798733 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 413/500 - Train Loss: 0.0311212073 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 414/500 - Train Loss: 0.0343331769 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 415/500 - Train Loss: 0.0344176207 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 416/500 - Train Loss: 0.0327768972 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 417/500 - Train Loss: 0.0341584855 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 418/500 - Train Loss: 0.0335598502 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 419/500 - Train Loss: 0.0311173022 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 420/500 - Train Loss: 0.0334521175 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 421/500 - Train Loss: 0.0329351192 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 422/500 - Train Loss: 0.0325578629 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 423/500 - Train Loss: 0.0334695358 - Epoch Time: 13.22s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 424/500 - Train Loss: 0.0323676334 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 425/500 - Train Loss: 0.0338140099 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 426/500 - Train Loss: 0.0343866601 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 427/500 - Train Loss: 0.0320810715 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 428/500 - Train Loss: 0.0320935020 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 429/500 - Train Loss: 0.0361180936 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 430/500 - Train Loss: 0.0343821135 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 431/500 - Train Loss: 0.0337863010 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 432/500 - Train Loss: 0.0343857314 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 433/500 - Train Loss: 0.0304819642 - Epoch Time: 13.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 434/500 - Train Loss: 0.0338768308 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 435/500 - Train Loss: 0.0319901756 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 436/500 - Train Loss: 0.0340926628 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 437/500 - Train Loss: 0.0317381821 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 438/500 - Train Loss: 0.0316072164 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 439/500 - Train Loss: 0.0332972726 - Epoch Time: 13.24s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 440/500 - Train Loss: 0.0334090557 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 441/500 - Train Loss: 0.0339827357 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 442/500 - Train Loss: 0.0337519933 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 443/500 - Train Loss: 0.0328087488 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 444/500 - Train Loss: 0.0345224474 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 445/500 - Train Loss: 0.0342335309 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 446/500 - Train Loss: 0.0323223442 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 447/500 - Train Loss: 0.0321786012 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 448/500 - Train Loss: 0.0334642386 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 449/500 - Train Loss: 0.0319508382 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 450/500 - Train Loss: 0.0324431563 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 451/500 - Train Loss: 0.0323156423 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 452/500 - Train Loss: 0.0327455015 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 453/500 - Train Loss: 0.0331385392 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 454/500 - Train Loss: 0.0350742388 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 455/500 - Train Loss: 0.0321458090 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 456/500 - Train Loss: 0.0331163572 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 457/500 - Train Loss: 0.0332732337 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 458/500 - Train Loss: 0.0341927073 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 459/500 - Train Loss: 0.0334159206 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 460/500 - Train Loss: 0.0321419000 - Epoch Time: 13.21s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 461/500 - Train Loss: 0.0326115803 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 462/500 - Train Loss: 0.0342700980 - Epoch Time: 13.25s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 463/500 - Train Loss: 0.0330904486 - Epoch Time: 13.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 464/500 - Train Loss: 0.0304378213 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 465/500 - Train Loss: 0.0314923396 - Epoch Time: 13.36s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 466/500 - Train Loss: 0.0338853823 - Epoch Time: 13.38s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 467/500 - Train Loss: 0.0364507623 - Epoch Time: 13.23s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 468/500 - Train Loss: 0.0322149914 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 469/500 - Train Loss: 0.0331810458 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 470/500 - Train Loss: 0.0319264789 - Epoch Time: 13.43s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 471/500 - Train Loss: 0.0320781753 - Epoch Time: 13.37s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 472/500 - Train Loss: 0.0331775786 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 473/500 - Train Loss: 0.0345649064 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 474/500 - Train Loss: 0.0338300211 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 475/500 - Train Loss: 0.0346008156 - Epoch Time: 13.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 476/500 - Train Loss: 0.0331853824 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 477/500 - Train Loss: 0.0332888306 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 478/500 - Train Loss: 0.0349484532 - Epoch Time: 13.45s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 479/500 - Train Loss: 0.0354645944 - Epoch Time: 13.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 480/500 - Train Loss: 0.0321501783 - Epoch Time: 13.42s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 481/500 - Train Loss: 0.0309913347 - Epoch Time: 13.32s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 482/500 - Train Loss: 0.0334760457 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 483/500 - Train Loss: 0.0340516268 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 484/500 - Train Loss: 0.0324957563 - Epoch Time: 13.33s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 485/500 - Train Loss: 0.0339885081 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 486/500 - Train Loss: 0.0347778341 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 487/500 - Train Loss: 0.0333263162 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 488/500 - Train Loss: 0.0360619905 - Epoch Time: 13.40s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 489/500 - Train Loss: 0.0314136765 - Epoch Time: 13.35s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 490/500 - Train Loss: 0.0343998793 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 491/500 - Train Loss: 0.0340104303 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 492/500 - Train Loss: 0.0336622075 - Epoch Time: 13.28s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 493/500 - Train Loss: 0.0331780246 - Epoch Time: 13.30s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 494/500 - Train Loss: 0.0330940577 - Epoch Time: 13.39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 495/500 - Train Loss: 0.0353850150 - Epoch Time: 13.41s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 496/500 - Train Loss: 0.0322342644 - Epoch Time: 13.44s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 497/500 - Train Loss: 0.0337055224 - Epoch Time: 13.29s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 498/500 - Train Loss: 0.0323751884 - Epoch Time: 13.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 499/500 - Train Loss: 0.0316148853 - Epoch Time: 13.34s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                              "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 500/500 - Train Loss: 0.0327819666 - Epoch Time: 13.42s\n",
            "Total Training Time: 6713.65s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grid Search ema decay and learning rate"
      ],
      "metadata": {
        "id": "Vj-pF0phgEb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Define candidate values for EMA decay and learning rate.\n",
        "ema_decay_candidates = [0.1, 0.3, 0.5, 0.7, 0.95, 0.99]\n",
        "lr_candidates = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "\n",
        "num_epochs_grid = 5  # Maximum epochs for each grid search candidate.\n",
        "patience = 1         # Early stopping patience.\n",
        "\n",
        "grid_results = {}     # Dictionary to store best validation loss for each candidate.\n",
        "grid_training_curves = {}  # (Optional) store training losses per candidate.\n",
        "grid_validation_curves = {}  # (Optional) store validation losses per candidate.\n",
        "\n",
        "# Dictionary to store the temporary checkpoint filename for each candidate.\n",
        "candidate_ckpt_files = {}\n",
        "best_val_loss_candidate = float('inf')\n",
        "for ema_candidate in ema_decay_candidates:\n",
        "    for lr_candidate in lr_candidates:\n",
        "        print(f\"\\nTraining with ema_decay = {ema_candidate} and learning rate = {lr_candidate}\")\n",
        "        # --- Reinitialize the models for each candidate combination ---\n",
        "        context_encoder = get_efficientnet_encoder().cuda()\n",
        "        target_encoder  = get_efficientnet_encoder().cuda()\n",
        "        target_encoder.load_state_dict(context_encoder.state_dict())\n",
        "        predictor = Predictor(num_targets=7).cuda()  # Predictor expects 2048 features.\n",
        "\n",
        "        optimizer = optim.Adam(list(context_encoder.parameters()) + list(predictor.parameters()), lr=lr_candidate)\n",
        "\n",
        "        # Define temporary checkpoint filename.\n",
        "        tmp_ckpt_filename = os.path.join(base_dir, f\"tmp_efficientnet_b2_model_raw_ema_{ema_candidate}_lr_{lr_candidate}_new_context_target.pth\")\n",
        "\n",
        "        candidate_ckpt_files[(ema_candidate, lr_candidate)] = tmp_ckpt_filename\n",
        "\n",
        "        # Initialize tracking variables.\n",
        "\n",
        "        patience_counter = 0\n",
        "        start_epoch = 0\n",
        "        candidate_train_losses = []\n",
        "        candidate_val_losses = []\n",
        "\n",
        "        # --- Resume training if temporary checkpoint exists ---\n",
        "        if os.path.exists(tmp_ckpt_filename):\n",
        "            checkpoint = torch.load(tmp_ckpt_filename)\n",
        "            start_epoch = checkpoint['epoch']\n",
        "            best_val_loss_candidate = checkpoint['val_loss']\n",
        "            context_encoder.load_state_dict(checkpoint['context_encoder_state_dict'])\n",
        "            target_encoder.load_state_dict(checkpoint['target_encoder_state_dict'])\n",
        "            predictor.load_state_dict(checkpoint['predictor_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            print(f\"Resuming from checkpoint at epoch {start_epoch} for (ema_decay={ema_candidate}, lr={lr_candidate})\")\n",
        "\n",
        "        # Training loop for the current candidate.\n",
        "        for epoch in range(start_epoch, num_epochs_grid):\n",
        "            epoch_start_time = time.time()\n",
        "            context_encoder.train()\n",
        "            predictor.train()\n",
        "            running_loss = 0.0\n",
        "\n",
        "            # --- Training Loop ---\n",
        "            for batch_idx, (context_block, target_blocks, _, _, _, _) in enumerate(\n",
        "                    tqdm(train_loader_aav_ijepa, desc=f\"Candidate Epoch {epoch+1}/{num_epochs_grid}\", leave=False)):\n",
        "                context_block = context_block.cuda()            # [B, C, 224, 224]\n",
        "                target_blocks = torch.stack(target_blocks, dim=1).cuda()            # [B, num_targets, C, 224, 224]\n",
        "\n",
        "                # Forward pass.\n",
        "                context_repr = context_encoder(context_block)     # [B, 2048]\n",
        "                preds = predictor(context_repr)                   # [B, num_targets, 2048]\n",
        "\n",
        "                B, num_targets, C, Ht, Wt = target_blocks.shape\n",
        "                target_blocks_flat = target_blocks.view(B * num_targets, C, Ht, Wt)\n",
        "                with torch.no_grad():\n",
        "                    target_repr_flat = target_encoder(target_blocks_flat)\n",
        "                target_repr = target_repr_flat.view(B, num_targets, -1)  # [B, num_targets, 2048]\n",
        "\n",
        "                loss = criterion(preds, target_repr)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                update_ema(context_encoder, target_encoder, ema_candidate)\n",
        "                running_loss += loss.item() * context_block.size(0)\n",
        "\n",
        "            epoch_loss = running_loss / len(train_dataset_aav_ijepa)\n",
        "            candidate_train_losses.append(epoch_loss)\n",
        "            train_time = time.time() - epoch_start_time\n",
        "\n",
        "            # --- Validation Evaluation ---\n",
        "            context_encoder.eval()\n",
        "            predictor.eval()\n",
        "            running_val_loss = 0.0\n",
        "            with torch.no_grad():\n",
        "                for context_block, target_blocks, _, _, _, _ in val_loader_aav_ijepa:\n",
        "                    context_block = context_block.cuda()\n",
        "                    #target_blocks = target_blocks.cuda()\n",
        "                    target_blocks = torch.stack(target_blocks, dim=1).cuda()\n",
        "                    context_repr = context_encoder(context_block)\n",
        "                    preds = predictor(context_repr)\n",
        "\n",
        "                    B, num_targets, C, Ht, Wt = target_blocks.shape\n",
        "                    target_blocks_flat = target_blocks.view(B * num_targets, C, Ht, Wt)\n",
        "                    target_repr_flat = target_encoder(target_blocks_flat)\n",
        "                    target_repr = target_repr_flat.view(B, num_targets, -1)\n",
        "\n",
        "                    loss_val = criterion(preds, target_repr)\n",
        "                    running_val_loss += loss_val.item() * context_block.size(0)\n",
        "            val_loss = running_val_loss / len(val_dataset_aav_ijepa)\n",
        "            candidate_val_losses.append(val_loss)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs_grid} - Train Loss: {epoch_loss:.6f} - Val Loss: {val_loss:.6f} - Time: {train_time:.2f}s\")\n",
        "\n",
        "            # --- Check for Improvement and Save Temporary Checkpoint ---\n",
        "            if val_loss < best_val_loss_candidate:\n",
        "                best_val_loss_candidate = val_loss\n",
        "                patience_counter = 0\n",
        "                checkpoint = {\n",
        "                    'epoch': epoch+1,\n",
        "                    'context_encoder_state_dict': context_encoder.state_dict(),\n",
        "                    'target_encoder_state_dict': target_encoder.state_dict(),\n",
        "                    'predictor_state_dict': predictor.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'val_loss': val_loss,\n",
        "                    'ema_decay': ema_candidate,\n",
        "                    'lr': lr_candidate\n",
        "                }\n",
        "                torch.save(checkpoint, tmp_ckpt_filename)\n",
        "                print(f\"Temporary checkpoint saved at epoch {epoch+1} with Val Loss: {val_loss:.6f} for (ema_decay={ema_candidate}, lr={lr_candidate})\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping triggered after {epoch+1} epochs for (ema_decay={ema_candidate}, lr={lr_candidate}).\")\n",
        "                    break\n",
        "\n",
        "        grid_results[(ema_candidate, lr_candidate)] = best_val_loss_candidate\n",
        "        grid_training_curves[(ema_candidate, lr_candidate)] = candidate_train_losses\n",
        "        grid_validation_curves[(ema_candidate, lr_candidate)] = candidate_val_losses\n",
        "        print(f\"Combination (ema_decay={ema_candidate}, lr={lr_candidate}) - Best Val Loss: {best_val_loss_candidate:.6f}\")\n",
        "\n",
        "# Display grid search results.\n",
        "print(\"\\nGrid Search Results (EMA Decay, LR) -> Best Val Loss:\")\n",
        "for params, loss_val in grid_results.items():\n",
        "    print(f\"  {params} -> {loss_val:.6f}\")\n",
        "\n",
        "# Find the best hyperparameters based on the validation loss.\n",
        "best_params = min(grid_results, key=grid_results.get)\n",
        "best_loss = grid_results[best_params]\n",
        "print(f\"\\nBest parameters: EMA decay = {best_params[0]}, Learning Rate = {best_params[1]} with Val Loss: {best_loss:.6f}\")\n",
        "\n",
        "# Load the best candidate's checkpoint from its temporary file and save as best checkpoint.\n",
        "best_tmp_ckpt_filename = candidate_ckpt_files[best_params]\n",
        "if os.path.exists(best_tmp_ckpt_filename):\n",
        "    best_checkpoint = torch.load(best_tmp_ckpt_filename)\n",
        "    best_ckpt_filename = os.path.join(base_dir, f\"best_efficientnet_b2_model_raw_ema_{best_params[0]}_lr_{best_params[1]}_new_context_target.pth\")\n",
        "    torch.save(best_checkpoint, best_ckpt_filename)\n",
        "    print(f\"Best checkpoint saved as {best_ckpt_filename}\")\n",
        "else:\n",
        "    print(\"No checkpoint file found for the best candidate.\")\n"
      ],
      "metadata": {
        "id": "39mm4A06XNcA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75301805-6944-4548-dfb3-8677dae3a2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with ema_decay = 0.1 and learning rate = 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 25366.128705 - Val Loss: 0.266372 - Time: 13.15s\n",
            "Temporary checkpoint saved at epoch 1 with Val Loss: 0.266372 for (ema_decay=0.1, lr=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Train Loss: 0.256324 - Val Loss: 0.240690 - Time: 13.22s\n",
            "Temporary checkpoint saved at epoch 2 with Val Loss: 0.240690 for (ema_decay=0.1, lr=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Train Loss: 0.231581 - Val Loss: 0.217244 - Time: 13.21s\n",
            "Temporary checkpoint saved at epoch 3 with Val Loss: 0.217244 for (ema_decay=0.1, lr=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Train Loss: 0.215748 - Val Loss: 0.196693 - Time: 13.26s\n",
            "Temporary checkpoint saved at epoch 4 with Val Loss: 0.196693 for (ema_decay=0.1, lr=0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/5 - Train Loss: 0.189924 - Val Loss: 0.174788 - Time: 13.12s\n",
            "Temporary checkpoint saved at epoch 5 with Val Loss: 0.174788 for (ema_decay=0.1, lr=0.1)\n",
            "Combination (ema_decay=0.1, lr=0.1) - Best Val Loss: 0.174788\n",
            "\n",
            "Training with ema_decay = 0.1 and learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 1.475811 - Val Loss: 0.028385 - Time: 13.29s\n",
            "Temporary checkpoint saved at epoch 1 with Val Loss: 0.028385 for (ema_decay=0.1, lr=0.01)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Train Loss: 0.019293 - Val Loss: 0.019277 - Time: 13.42s\n",
            "Temporary checkpoint saved at epoch 2 with Val Loss: 0.019277 for (ema_decay=0.1, lr=0.01)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Train Loss: 0.020456 - Val Loss: 0.020719 - Time: 13.11s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 3 epochs for (ema_decay=0.1, lr=0.01).\n",
            "Combination (ema_decay=0.1, lr=0.01) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.1 and learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.056363 - Val Loss: 0.038105 - Time: 13.26s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.1, lr=0.001).\n",
            "Combination (ema_decay=0.1, lr=0.001) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.1 and learning rate = 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.075148 - Val Loss: 0.054083 - Time: 13.22s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.1, lr=0.0001).\n",
            "Combination (ema_decay=0.1, lr=0.0001) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.3 and learning rate = 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 73717.619379 - Val Loss: 34954.058422 - Time: 13.15s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.3, lr=0.1).\n",
            "Combination (ema_decay=0.3, lr=0.1) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.3 and learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 1.787204 - Val Loss: 0.025125 - Time: 13.16s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.3, lr=0.01).\n",
            "Combination (ema_decay=0.3, lr=0.01) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.3 and learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.044135 - Val Loss: 0.026763 - Time: 13.16s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.3, lr=0.001).\n",
            "Combination (ema_decay=0.3, lr=0.001) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.3 and learning rate = 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.069552 - Val Loss: 0.044754 - Time: 13.12s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.3, lr=0.0001).\n",
            "Combination (ema_decay=0.3, lr=0.0001) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.5 and learning rate = 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 79098.998593 - Val Loss: 2862.837745 - Time: 13.14s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.5, lr=0.1).\n",
            "Combination (ema_decay=0.5, lr=0.1) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.5 and learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 1.006921 - Val Loss: 0.031463 - Time: 13.13s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.5, lr=0.01).\n",
            "Combination (ema_decay=0.5, lr=0.01) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.5 and learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.054372 - Val Loss: 0.033727 - Time: 13.09s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.5, lr=0.001).\n",
            "Combination (ema_decay=0.5, lr=0.001) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.5 and learning rate = 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.071673 - Val Loss: 0.050007 - Time: 13.08s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.5, lr=0.0001).\n",
            "Combination (ema_decay=0.5, lr=0.0001) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.7 and learning rate = 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 44030.183231 - Val Loss: 163.642457 - Time: 13.17s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.7, lr=0.1).\n",
            "Combination (ema_decay=0.7, lr=0.1) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.7 and learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 1.994799 - Val Loss: 0.038682 - Time: 13.20s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.7, lr=0.01).\n",
            "Combination (ema_decay=0.7, lr=0.01) - Best Val Loss: 0.019277\n",
            "\n",
            "Training with ema_decay = 0.7 and learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.029049 - Val Loss: 0.012521 - Time: 13.31s\n",
            "Temporary checkpoint saved at epoch 1 with Val Loss: 0.012521 for (ema_decay=0.7, lr=0.001)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/5 - Train Loss: 0.010857 - Val Loss: 0.009783 - Time: 13.33s\n",
            "Temporary checkpoint saved at epoch 2 with Val Loss: 0.009783 for (ema_decay=0.7, lr=0.001)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/5 - Train Loss: 0.008719 - Val Loss: 0.007921 - Time: 13.27s\n",
            "Temporary checkpoint saved at epoch 3 with Val Loss: 0.007921 for (ema_decay=0.7, lr=0.001)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/5 - Train Loss: 0.007906 - Val Loss: 0.007980 - Time: 13.33s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 4 epochs for (ema_decay=0.7, lr=0.001).\n",
            "Combination (ema_decay=0.7, lr=0.001) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.7 and learning rate = 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.078592 - Val Loss: 0.056181 - Time: 13.29s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.7, lr=0.0001).\n",
            "Combination (ema_decay=0.7, lr=0.0001) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.95 and learning rate = 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 39462.238062 - Val Loss: 19.575971 - Time: 13.15s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.95, lr=0.1).\n",
            "Combination (ema_decay=0.95, lr=0.1) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.95 and learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 1.013126 - Val Loss: 0.023054 - Time: 13.14s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.95, lr=0.01).\n",
            "Combination (ema_decay=0.95, lr=0.01) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.95 and learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.055278 - Val Loss: 0.031146 - Time: 13.28s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.95, lr=0.001).\n",
            "Combination (ema_decay=0.95, lr=0.001) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.95 and learning rate = 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.089358 - Val Loss: 0.070078 - Time: 13.32s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.95, lr=0.0001).\n",
            "Combination (ema_decay=0.95, lr=0.0001) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.99 and learning rate = 0.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 120650.080158 - Val Loss: 1831053915.629268 - Time: 13.28s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.99, lr=0.1).\n",
            "Combination (ema_decay=0.99, lr=0.1) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.99 and learning rate = 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.847916 - Val Loss: 0.044644 - Time: 13.32s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.99, lr=0.01).\n",
            "Combination (ema_decay=0.99, lr=0.01) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.99 and learning rate = 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.079330 - Val Loss: 0.053435 - Time: 13.25s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.99, lr=0.001).\n",
            "Combination (ema_decay=0.99, lr=0.001) - Best Val Loss: 0.007921\n",
            "\n",
            "Training with ema_decay = 0.99 and learning rate = 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5 - Train Loss: 0.097926 - Val Loss: 0.087981 - Time: 13.26s\n",
            "No improvement in validation loss for 1 epoch(s).\n",
            "Early stopping triggered after 1 epochs for (ema_decay=0.99, lr=0.0001).\n",
            "Combination (ema_decay=0.99, lr=0.0001) - Best Val Loss: 0.007921\n",
            "\n",
            "Grid Search Results (EMA Decay, LR) -> Best Val Loss:\n",
            "  (0.1, 0.1) -> 0.174788\n",
            "  (0.1, 0.01) -> 0.019277\n",
            "  (0.1, 0.001) -> 0.019277\n",
            "  (0.1, 0.0001) -> 0.019277\n",
            "  (0.3, 0.1) -> 0.019277\n",
            "  (0.3, 0.01) -> 0.019277\n",
            "  (0.3, 0.001) -> 0.019277\n",
            "  (0.3, 0.0001) -> 0.019277\n",
            "  (0.5, 0.1) -> 0.019277\n",
            "  (0.5, 0.01) -> 0.019277\n",
            "  (0.5, 0.001) -> 0.019277\n",
            "  (0.5, 0.0001) -> 0.019277\n",
            "  (0.7, 0.1) -> 0.019277\n",
            "  (0.7, 0.01) -> 0.019277\n",
            "  (0.7, 0.001) -> 0.007921\n",
            "  (0.7, 0.0001) -> 0.007921\n",
            "  (0.95, 0.1) -> 0.007921\n",
            "  (0.95, 0.01) -> 0.007921\n",
            "  (0.95, 0.001) -> 0.007921\n",
            "  (0.95, 0.0001) -> 0.007921\n",
            "  (0.99, 0.1) -> 0.007921\n",
            "  (0.99, 0.01) -> 0.007921\n",
            "  (0.99, 0.001) -> 0.007921\n",
            "  (0.99, 0.0001) -> 0.007921\n",
            "\n",
            "Best parameters: EMA decay = 0.7, Learning Rate = 0.001 with Val Loss: 0.007921\n",
            "Best checkpoint saved as /content/drive/MyDrive/AAVDATASET/1s_segment_raw/best_efficientnet_b2_model_raw_ema_0.7_lr_0.001_new_context_target.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "ema_decay = 0.1\n",
        "best_loss = float('inf')\n",
        "total_start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_start_time = time.time()\n",
        "    context_encoder.train()\n",
        "    predictor.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    # Enumerate over batches with a progress bar.\n",
        "    for batch_idx, (context_block, target_blocks, _, _) in enumerate(tqdm(train_loader_aav_ijepa, desc=f\"Epoch {epoch+1}/{num_epochs}\", leave=False)):\n",
        "        context_block = context_block.cuda()            # [B, C, 224, 224]\n",
        "        target_blocks = target_blocks.cuda()              # [B, num_targets, C, 224, 224]\n",
        "\n",
        "        # Forward pass through context encoder and predictor.\n",
        "        context_repr = context_encoder(context_block)     # [B, 768]\n",
        "        preds = predictor(context_repr)                   # [B, num_targets, 768]\n",
        "\n",
        "        B, num_targets, C, Ht, Wt = target_blocks.shape\n",
        "        target_blocks_flat = target_blocks.view(B * num_targets, C, Ht, Wt)\n",
        "        with torch.no_grad():\n",
        "            target_repr_flat = target_encoder(target_blocks_flat)\n",
        "        target_repr = target_repr_flat.view(B, num_targets, -1)\n",
        "\n",
        "        loss = criterion(preds, target_repr)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        update_ema(context_encoder, target_encoder, ema_decay)\n",
        "        running_loss += loss.item() * context_block.size(0)\n",
        "\n",
        "        # --- Visualization for first image of the current batch ---\n",
        "        '''with torch.no_grad():\n",
        "            # Get the first sample's context block and compute its feature vector.\n",
        "            context_img = context_block[0].cpu()  # shape: [C, 224, 224]\n",
        "            context_feat = context_encoder(context_block[0].unsqueeze(0)).cpu().squeeze(0)  # shape: [768]\n",
        "            # Reshape feature vector to a 2D heatmap (24x32).\n",
        "            context_heat = context_feat.view(24, 32).numpy()\n",
        "\n",
        "            # For target, choose the first target block of the first sample.\n",
        "            target_img = target_blocks[0][0].cpu()  # shape: [C, 224, 224]\n",
        "            target_feat = target_encoder(target_blocks[0][0].unsqueeze(0).to(context_block.device)).cpu().squeeze(0)\n",
        "            target_heat = target_feat.view(24, 32).numpy()\n",
        "\n",
        "            # Plot the images and corresponding heatmaps.\n",
        "            fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
        "\n",
        "            # Display context block image.\n",
        "            if context_img.shape[0] == 1:\n",
        "                axs[0, 0].imshow(context_img.squeeze(), cmap='gray')\n",
        "            else:\n",
        "                axs[0, 0].imshow(context_img.permute(1, 2, 0))\n",
        "            axs[0, 0].set_title(\"Context Block\")\n",
        "            axs[0, 0].axis(\"off\")\n",
        "\n",
        "            # Display context feature heatmap.\n",
        "            im0 = axs[0, 1].imshow(context_heat, cmap=\"viridis\")\n",
        "            axs[0, 1].set_title(\"Context Feature Heatmap\")\n",
        "            axs[0, 1].axis(\"off\")\n",
        "            fig.colorbar(im0, ax=axs[0, 1])\n",
        "\n",
        "            # Display target block image.\n",
        "            if target_img.shape[0] == 1:\n",
        "                axs[1, 0].imshow(target_img.squeeze(), cmap='gray')\n",
        "            else:\n",
        "                axs[1, 0].imshow(target_img.permute(1, 2, 0))\n",
        "            axs[1, 0].set_title(\"Target Block\")\n",
        "            axs[1, 0].axis(\"off\")\n",
        "\n",
        "            # Display target feature heatmap.\n",
        "            im1 = axs[1, 1].imshow(target_heat, cmap=\"viridis\")\n",
        "            axs[1, 1].set_title(\"Target Feature Heatmap\")\n",
        "            axs[1, 1].axis(\"off\")\n",
        "            fig.colorbar(im1, ax=axs[1, 1])\n",
        "\n",
        "            # Save the visualization figure with epoch and batch number.\n",
        "            viz_path = os.path.join(viz_dir, f\"epoch{epoch+1}_batch{batch_idx+1}.png\")\n",
        "            plt.savefig(viz_path)\n",
        "            plt.close(fig)'''\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataset_aav_ijepa)\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.10f} - Epoch Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # Save checkpoint if current epoch loss is lower than previous best.\n",
        "    if epoch_loss < best_loss:\n",
        "        best_loss = epoch_loss\n",
        "        checkpoint = {\n",
        "            'epoch': epoch+1,\n",
        "            'context_encoder_state_dict': context_encoder.state_dict(),\n",
        "            'target_encoder_state_dict': target_encoder.state_dict(),\n",
        "            'predictor_state_dict': predictor.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': epoch_loss\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join(base_dir,\"ijepa_checkpoint_best.pth\"))\n",
        "        print(f\"Checkpoint saved at epoch {epoch+1} with loss {epoch_loss:.4f}\")\n",
        "\n",
        "\n",
        "total_train_time = time.time() - total_start_time\n",
        "print(f\"Total Training Time: {total_train_time:.2f}s\")"
      ],
      "metadata": {
        "id": "N0Dp1ndAvSrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading pretrained model"
      ],
      "metadata": {
        "id": "4YFBMqa_yyVl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "# Define the checkpoint filename (adjust parameters as needed).\n",
        "#ckpt_filename = os.path.join(base_dir, \"best_resnet50_model_ema_0.95_lr_0.001.pth\")\n",
        "ckpt_filename = best_ckpt_filename\n",
        "print(f\"Checkpoint loaded for evaluation: {best_tmp_ckpt_filename}\")\n",
        "# Load the checkpoint.\n",
        "checkpoint = torch.load(ckpt_filename, map_location=device)\n",
        "\n",
        "# Load the state dictionaries into your model instances.\n",
        "context_encoder.load_state_dict(checkpoint['context_encoder_state_dict'])\n",
        "target_encoder.load_state_dict(checkpoint['target_encoder_state_dict'])\n",
        "predictor.load_state_dict(checkpoint['predictor_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# Optionally, retrieve other metadata.\n",
        "start_epoch = checkpoint['epoch']\n",
        "val_loss = checkpoint['val_loss']\n",
        "\n",
        "print(f\"Checkpoint loaded from epoch {start_epoch} with validation loss {val_loss:.6f}\")\n"
      ],
      "metadata": {
        "id": "qKCpRDOegODc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization of Output from I-Jepa"
      ],
      "metadata": {
        "id": "XnIF2mdVy3P4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modified extraction function returning coordinates.\n",
        "def extract_blocks_with_coords(image, context_scale=0.85, target_scale=0.2, num_targets=4, max_overlap=0.5):\n",
        "    # image: tensor of shape [C, H, W]\n",
        "    _, H, W = image.shape\n",
        "    context_size = int(context_scale * H)\n",
        "    top = (H - context_size) // 2\n",
        "    left = (W - context_size) // 2\n",
        "    # Extract context block.\n",
        "    context_block = image[:, top:top+context_size, left:left+context_size]\n",
        "    context_block = torch.nn.functional.interpolate(\n",
        "        context_block.unsqueeze(0),\n",
        "        size=(224, 224),\n",
        "        mode='bilinear',\n",
        "        align_corners=False\n",
        "    ).squeeze(0)\n",
        "    # Coordinates for context: (left, top, width, height)\n",
        "    context_coords = (left, top, context_size, context_size)\n",
        "\n",
        "    # Extract target blocks and record their coordinates.\n",
        "    target_blocks = []\n",
        "    target_coords = []\n",
        "    for _ in range(num_targets):\n",
        "        target_size = int(target_scale * H)\n",
        "        top_t = random.randint(0, H - target_size)\n",
        "        left_t = random.randint(0, W - target_size)\n",
        "        target_coords.append((left_t, top_t, target_size, target_size))\n",
        "        target_block = image[:, top_t:top_t+target_size, left_t:left_t+target_size]\n",
        "        target_block = torch.nn.functional.interpolate(\n",
        "            target_block.unsqueeze(0),\n",
        "            size=(224, 224),\n",
        "            mode='bilinear',\n",
        "            align_corners=False\n",
        "        ).squeeze(0)\n",
        "        target_blocks.append(target_block)\n",
        "    target_blocks = torch.stack(target_blocks)\n",
        "    return context_block, target_blocks, context_coords, target_coords\n",
        "\n",
        "# Modified process_sample function.\n",
        "def process_sample_with_coords(sample, context_scale, target_scale, num_targets):\n",
        "    # Unpack sample: sample is ((img, label), image_path)\n",
        "    (img, label), image_path = sample\n",
        "    img = img.to(device)\n",
        "    context_block, target_blocks, context_coords, target_coords = extract_blocks_with_coords(\n",
        "        img, context_scale, target_scale, num_targets\n",
        "    )\n",
        "    # Bring results back to CPU before caching.\n",
        "    return (context_block.cpu(), target_blocks.cpu(), label, image_path, context_coords, target_coords)\n"
      ],
      "metadata": {
        "id": "vh5WrLPhQo9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Number of images per class to display.\n",
        "n_images_per_class = 5\n",
        "\n",
        "# Get the list of class names from the dataset (ImageFolder).\n",
        "class_names = dataset.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Group image paths by class label using dataset.samples.\n",
        "# dataset.samples is a list of (image_path, label) tuples.\n",
        "samples_by_class = {i: [] for i in range(num_classes)}\n",
        "for img_path, label in dataset.samples:\n",
        "    samples_by_class[label].append(img_path)\n",
        "\n",
        "# Prepare a grid: each row is a class and each column is one image.\n",
        "fig, axes = plt.subplots(num_classes, n_images_per_class, figsize=(4 * n_images_per_class, 4 * num_classes))\n",
        "\n",
        "# If only one row or one column, make axes 2D for consistency.\n",
        "if num_classes == 1:\n",
        "    axes = np.expand_dims(axes, axis=0)\n",
        "if n_images_per_class == 1:\n",
        "    axes = np.expand_dims(axes, axis=1)\n",
        "\n",
        "# For each class, randomly sample n images and display.\n",
        "for class_idx in range(num_classes):\n",
        "    # Get all image paths for this class.\n",
        "    paths = samples_by_class[class_idx]\n",
        "    # If there are fewer images than n, sample with replacement.\n",
        "    if len(paths) < n_images_per_class:\n",
        "        selected_paths = random.choices(paths, k=n_images_per_class)\n",
        "    else:\n",
        "        selected_paths = random.sample(paths, n_images_per_class)\n",
        "\n",
        "    for col_idx, image_path in enumerate(selected_paths):\n",
        "        # Load the image using the dataset loader.\n",
        "        pil_img = dataset.loader(image_path)  # Typically PIL.Image.open\n",
        "        # Apply the same transform to get the tensor version.\n",
        "        img_tensor = transform(pil_img)  # Shape: [C, H, W]\n",
        "\n",
        "        # Form the sample tuple as expected by process_sample_with_coords.\n",
        "        # Format: ((img_tensor, label), image_path)\n",
        "        sample_tuple = ((img_tensor, class_idx), image_path)\n",
        "\n",
        "        # Process the sample to extract context and target blocks with coordinates.\n",
        "        # This returns: context_block, target_blocks, label, image_path, context_coords, target_coords\n",
        "        context_block, target_blocks, label, img_path, context_coords, target_coords = process_sample_with_coords(\n",
        "            sample_tuple, context_scale=0.85, target_scale=0.2, num_targets=4\n",
        "        )\n",
        "\n",
        "        # Load the main image from disk and resize it to 224x224.\n",
        "        main_img = Image.open(image_path).convert(\"RGB\")\n",
        "        main_img = main_img.resize((224, 224))\n",
        "        main_img_np = np.array(main_img) / 255.0\n",
        "\n",
        "        # Get the current axis from the grid.\n",
        "        ax = axes[class_idx, col_idx]\n",
        "        ax.imshow(main_img_np)\n",
        "\n",
        "        # Draw the context block in red.\n",
        "        # context_coords: (left, top, width, height)\n",
        "        rect_context = patches.Rectangle((context_coords[0], context_coords[1]),\n",
        "                                         context_coords[2], context_coords[3],\n",
        "                                         linewidth=2, edgecolor='red', facecolor='none')\n",
        "        ax.add_patch(rect_context)\n",
        "\n",
        "        # Draw each target block in blue.\n",
        "        for i, coords in enumerate(target_coords):\n",
        "            rect_target = patches.Rectangle((coords[0], coords[1]),\n",
        "                                            coords[2], coords[3],\n",
        "                                            linewidth=2, edgecolor='blue', facecolor='none')\n",
        "            ax.add_patch(rect_target)\n",
        "\n",
        "        ax.set_title(f\"{class_names[class_idx]}\")\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9jY1NY6lKQIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Number of images per class to display.\n",
        "n_images_per_class = 3\n",
        "\n",
        "# Get class names and number of classes from your ImageFolder dataset.\n",
        "class_names = dataset.classes\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Group image paths by class label using dataset.samples.\n",
        "samples_by_class = {i: [] for i in range(num_classes)}\n",
        "for img_path, label in dataset.samples:\n",
        "    samples_by_class[label].append(img_path)\n",
        "\n",
        "# Prepare a grid.\n",
        "# For each sample, we now show 6 images:\n",
        "# (a) Main image with bounding boxes,\n",
        "# (b) Context vector heatmap,\n",
        "# (c) Four target block heatmaps (one per target block).\n",
        "n_cols = n_images_per_class * 6\n",
        "fig, axes = plt.subplots(num_classes, n_cols, figsize=(2 * n_cols, 2 * num_classes))\n",
        "if num_classes == 1:\n",
        "    axes = np.expand_dims(axes, axis=0)\n",
        "if n_cols == 1:\n",
        "    axes = np.expand_dims(axes, axis=1)\n",
        "\n",
        "# Set models to evaluation mode.\n",
        "context_encoder.eval()\n",
        "target_encoder.eval()\n",
        "\n",
        "for class_idx in range(num_classes):\n",
        "    # Select n random images for this class.\n",
        "    paths = samples_by_class[class_idx]\n",
        "    if len(paths) < n_images_per_class:\n",
        "        selected_paths = random.choices(paths, k=n_images_per_class)\n",
        "    else:\n",
        "        selected_paths = random.sample(paths, n_images_per_class)\n",
        "\n",
        "    for sample_idx, image_path in enumerate(selected_paths):\n",
        "        # Load the image.\n",
        "        pil_img = dataset.loader(image_path)  # Typically PIL.Image.open\n",
        "        img_tensor = transform(pil_img)  # Shape: [C, H, W]\n",
        "\n",
        "        # Create sample tuple as expected by process_sample_with_coords.\n",
        "        sample_tuple = ((img_tensor, class_idx), image_path)\n",
        "\n",
        "        # Process the sample to extract blocks and bounding box coordinates.\n",
        "        context_block, target_blocks, label, img_path, context_coords, target_coords = process_sample_with_coords(\n",
        "            sample_tuple, context_scale=0.85, target_scale=0.2, num_targets=4\n",
        "        )\n",
        "\n",
        "        # Load the main image from disk and resize to 224x224.\n",
        "        main_img = Image.open(image_path).convert(\"RGB\")\n",
        "        main_img = main_img.resize((224,224))\n",
        "        main_img_np = np.array(main_img) / 255.0\n",
        "\n",
        "        # Compute starting column index for this sample in the grid.\n",
        "        col_start = sample_idx * 6\n",
        "\n",
        "        # (a) Display the main image with bounding boxes.\n",
        "        ax_main = axes[class_idx, col_start]\n",
        "        ax_main.imshow(main_img_np)\n",
        "\n",
        "        # Draw context block in red.\n",
        "        rect_context = patches.Rectangle((context_coords[0], context_coords[1]),\n",
        "                                         context_coords[2], context_coords[3],\n",
        "                                         linewidth=2, edgecolor='red', facecolor='none')\n",
        "        ax_main.add_patch(rect_context)\n",
        "\n",
        "        # Draw each target block in blue and add a label (target block number).\n",
        "        for i, coords in enumerate(target_coords):\n",
        "            rect_target = patches.Rectangle((coords[0], coords[1]),\n",
        "                                            coords[2], coords[3],\n",
        "                                            linewidth=2, edgecolor='blue', facecolor='none')\n",
        "            ax_main.add_patch(rect_target)\n",
        "            # Place the target number at the top-left corner of the bounding box.\n",
        "            ax_main.text(coords[0], max(coords[1] - 5, 0), f\"{i+1}\",\n",
        "                         color=\"blue\", fontsize=12, fontweight=\"bold\")\n",
        "\n",
        "        ax_main.set_title(f\"{class_names[class_idx]}\")\n",
        "        ax_main.axis(\"off\")\n",
        "\n",
        "        # (b) Display the context encoder feature heatmap.\n",
        "        with torch.no_grad():\n",
        "            context_feat = context_encoder(context_block.unsqueeze(0).to(device))\n",
        "        context_feat = context_feat.cpu().squeeze(0)\n",
        "        context_heatmap = context_feat.view(32,44).numpy()  # Reshape assuming 768=24*32.\n",
        "        ax_context = axes[class_idx, col_start+1]\n",
        "        im1 = ax_context.imshow(context_heatmap, cmap=\"viridis\")\n",
        "        ax_context.set_title(\"Context\")\n",
        "        ax_context.axis(\"off\")\n",
        "        plt.colorbar(im1, ax=ax_context, fraction=0.046, pad=0.04)\n",
        "\n",
        "        # (c) Display individual target block feature heatmaps.\n",
        "        # For each of the 4 target blocks, compute its encoder feature and display.\n",
        "        for j in range(4):\n",
        "            with torch.no_grad():\n",
        "                target_feat = target_encoder(target_blocks[j].unsqueeze(0).to(device))\n",
        "            target_feat = target_feat.cpu().squeeze(0)\n",
        "            target_heatmap = target_feat.view(32,44).numpy()  # Reshape as heatmap.\n",
        "            ax_target = axes[class_idx, col_start+2+j]\n",
        "            im2 = ax_target.imshow(target_heatmap, cmap=\"viridis\")\n",
        "            ax_target.set_title(f\"Target {j+1}\")\n",
        "            ax_target.axis(\"off\")\n",
        "            plt.colorbar(im2, ax=ax_target, fraction=0.046, pad=0.04)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hZOti31PL435"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Ensure the context encoder is in evaluation mode.\n",
        "context_encoder.eval()\n",
        "\n",
        "# Collect features from a subset of your data (using train_loader_aav_ijepa as an example).\n",
        "all_features = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for context_block, _, label, _ in train_loader_aav_ijepa:\n",
        "        context_block = context_block.to(device)\n",
        "        features = context_encoder(context_block)  # e.g., [B, 768]\n",
        "        all_features.append(features.cpu().numpy())\n",
        "        all_labels.extend(label.cpu().numpy())\n",
        "all_features = np.concatenate(all_features, axis=0)\n",
        "\n",
        "# Dimensionality reduction using t-SNE.\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "features_2d = tsne.fit_transform(all_features)\n",
        "\n",
        "# --------------------- KMeans Clustering ---------------------\n",
        "n_clusters = 3  # Adjust as needed.\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "cluster_labels_kmeans = kmeans.fit_predict(all_features)\n",
        "sil_score_kmeans = silhouette_score(all_features, cluster_labels_kmeans)\n",
        "print(f\"KMeans Silhouette Score: {sil_score_kmeans:.3f}\")\n",
        "\n",
        "# --------------------- DBSCAN Clustering ---------------------\n",
        "# You may need to tune eps and min_samples based on your data.\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "cluster_labels_dbscan = dbscan.fit_predict(all_features)\n",
        "unique_dbscan = np.unique(cluster_labels_dbscan)\n",
        "if len(unique_dbscan) > 1 and -1 not in unique_dbscan:\n",
        "    sil_score_dbscan = silhouette_score(all_features, cluster_labels_dbscan)\n",
        "    print(f\"DBSCAN Silhouette Score: {sil_score_dbscan:.3f}\")\n",
        "else:\n",
        "    print(\"DBSCAN did not form valid clusters for silhouette score computation.\")\n",
        "\n",
        "# --------------------- Agglomerative Clustering ---------------------\n",
        "agglo = AgglomerativeClustering(n_clusters=n_clusters)\n",
        "cluster_labels_agglo = agglo.fit_predict(all_features)\n",
        "sil_score_agglo = silhouette_score(all_features, cluster_labels_agglo)\n",
        "print(f\"Agglomerative Clustering Silhouette Score: {sil_score_agglo:.3f}\")\n",
        "\n",
        "# --------------------- Visualization ---------------------\n",
        "plt.figure(figsize=(20,6))\n",
        "\n",
        "# Plot KMeans clusters.\n",
        "plt.subplot(1,3,1)\n",
        "scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=cluster_labels_kmeans, cmap='viridis', alpha=0.6)\n",
        "plt.title(\"KMeans Clustering\")\n",
        "plt.xlabel(\"t-SNE Dim 1\")\n",
        "plt.ylabel(\"t-SNE Dim 2\")\n",
        "plt.colorbar(scatter, label='Cluster Label')\n",
        "\n",
        "# Plot DBSCAN clusters.\n",
        "plt.subplot(1,3,2)\n",
        "scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=cluster_labels_dbscan, cmap='viridis', alpha=0.6)\n",
        "plt.title(\"DBSCAN Clustering\")\n",
        "plt.xlabel(\"t-SNE Dim 1\")\n",
        "plt.ylabel(\"t-SNE Dim 2\")\n",
        "plt.colorbar(scatter, label='Cluster Label')\n",
        "\n",
        "# Plot Agglomerative clusters.\n",
        "plt.subplot(1,3,3)\n",
        "scatter = plt.scatter(features_2d[:, 0], features_2d[:, 1], c=cluster_labels_agglo, cmap='viridis', alpha=0.6)\n",
        "plt.title(\"Agglomerative Clustering\")\n",
        "plt.xlabel(\"t-SNE Dim 1\")\n",
        "plt.ylabel(\"t-SNE Dim 2\")\n",
        "plt.colorbar(scatter, label='Cluster Label')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "6cP-izZXOhrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "def visualize_predictor_output(file_path, context_scale=0.70, target_scale=0.20, num_targets=4, feature_dim=768):\n",
        "    \"\"\"\n",
        "    Visualizes the predictor output versus the target encoder output for one sample.\n",
        "\n",
        "    Steps:\n",
        "      1. Loads an image and applies the transform.\n",
        "      2. Extracts a context block and target blocks using extract_blocks.\n",
        "      3. Computes the context representation.\n",
        "      4. Uses the predictor to predict target features.\n",
        "      5. Computes the actual target features using the target encoder.\n",
        "      6. Reshapes and displays the predicted and actual target features as heatmaps.\n",
        "      7. Also shows the original target block image.\n",
        "\n",
        "    Args:\n",
        "      file_path (str): Path to the image.\n",
        "      context_scale (float): Fraction of image height used for context block.\n",
        "      target_scale (float): Fraction of image height used for target block.\n",
        "      num_targets (int): Number of target blocks to extract.\n",
        "      feature_dim (int): Dimension of the encoder's feature vector (e.g., 768 for ViT, 1408 for EfficientNet B2).\n",
        "    \"\"\"\n",
        "    # Load image and apply transform.\n",
        "    pil_img = Image.open(file_path).convert(\"RGB\")\n",
        "    # Transform the image (should resize to 224x224).\n",
        "    image_tensor = transform(pil_img)  # shape: [C, H, W]\n",
        "\n",
        "    # Extract blocks using your extract_blocks function.\n",
        "    context_block, target_blocks, _, _ = extract_blocks(image_tensor, context_scale, target_scale, num_targets)\n",
        "\n",
        "    # Compute context representation.\n",
        "    context_block = context_block.to(device)\n",
        "    with torch.no_grad():\n",
        "        context_repr = context_encoder(context_block.unsqueeze(0))  # shape: [1, feature_dim]\n",
        "        # Predictor output for target features.\n",
        "        preds = predictor(context_repr)  # shape: [1, num_targets, feature_dim]\n",
        "\n",
        "    # Compute actual target features.\n",
        "    target_blocks = target_blocks.to(device)\n",
        "    B, num_t, C, Ht, Wt = target_blocks.shape\n",
        "    target_blocks_flat = target_blocks.view(B * num_t, C, Ht, Wt)\n",
        "    with torch.no_grad():\n",
        "        target_repr_flat = target_encoder(target_blocks_flat)  # shape: [B*num_t, feature_dim]\n",
        "    target_repr = target_repr_flat.view(B, num_t, -1)  # shape: [1, num_targets, feature_dim]\n",
        "\n",
        "    # For visualization, let's focus on the first target block.\n",
        "    pred_feat = preds[0, 0].cpu()       # shape: [feature_dim]\n",
        "    actual_feat = target_repr[0, 0].cpu()  # shape: [feature_dim]\n",
        "\n",
        "    # Reshape features to 2D for heatmap visualization.\n",
        "    # Choose shape based on feature_dim.\n",
        "    if feature_dim == 768:\n",
        "        # For ViT: 24x32 = 768\n",
        "        pred_heat = pred_feat.view(24, 32).numpy()\n",
        "        actual_heat = actual_feat.view(24, 32).numpy()\n",
        "    elif feature_dim == 1408:\n",
        "        # For EfficientNet B2: 32x44 = 1408\n",
        "        pred_heat = pred_feat.view(32, 44).numpy()\n",
        "        actual_heat = actual_feat.view(32, 44).numpy()\n",
        "    else:\n",
        "        # Fallback: use a square if possible.\n",
        "        side = int(np.sqrt(feature_dim))\n",
        "        pred_heat = pred_feat[:side*side].view(side, side).numpy()\n",
        "        actual_heat = actual_feat[:side*side].view(side, side).numpy()\n",
        "\n",
        "    # Get the original target block image for reference.\n",
        "    target_img = target_blocks[0, 0].cpu()  # shape: [C, 224, 224]\n",
        "    # If single channel, squeeze; else, permute to HWC.\n",
        "    if target_img.shape[0] == 1:\n",
        "        target_img_vis = target_img.squeeze().numpy()\n",
        "    else:\n",
        "        target_img_vis = target_img.permute(1, 2, 0).numpy()\n",
        "\n",
        "    # Plot the results.\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axs[0].imshow(target_img_vis)\n",
        "    axs[0].set_title(\"Original Target Block\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    im1 = axs[1].imshow(pred_heat, cmap=\"viridis\")\n",
        "    axs[1].set_title(\"Predicted Feature (Heatmap)\")\n",
        "    axs[1].axis(\"off\")\n",
        "    plt.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04)\n",
        "\n",
        "    im2 = axs[2].imshow(actual_heat, cmap=\"viridis\")\n",
        "    axs[2].set_title(\"Actual Target Feature (Heatmap)\")\n",
        "    axs[2].axis(\"off\")\n",
        "    plt.colorbar(im2, ax=axs[2], fraction=0.046, pad=0.04)\n",
        "\n",
        "    plt.suptitle(os.path.basename(file_path))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "# visualize_predictor_output(\"path/to/your/image.jpg\", context_scale=0.70, target_scale=0.20, num_targets=4, feature_dim=768)\n"
      ],
      "metadata": {
        "id": "IixWGx24tCJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "def visualize_predictor_output_sample(sample, feature_dim=768):\n",
        "    \"\"\"\n",
        "    Visualizes the predictor’s output versus the target encoder’s output for one sample.\n",
        "\n",
        "    The sample is assumed to be a tuple:\n",
        "      (context_block, target_blocks, label, image_path)\n",
        "    where context_block is a tensor of shape [C, 224, 224],\n",
        "    target_blocks is a tensor of shape [num_targets, C, 224, 224],\n",
        "    label is the class label, and image_path is the image filename.\n",
        "\n",
        "    The function:\n",
        "      - Computes the context representation using the context_encoder.\n",
        "      - Feeds it through the predictor to obtain predicted features for target blocks.\n",
        "      - Computes the actual target features via the target_encoder.\n",
        "      - Reshapes the feature vector for the first target block into a heatmap.\n",
        "      - Visualizes:\n",
        "          (a) the original target block,\n",
        "          (b) the predicted feature heatmap,\n",
        "          (c) the actual target feature heatmap.\n",
        "    \"\"\"\n",
        "    # Unpack sample.\n",
        "    context_block, target_blocks, label, image_path = sample\n",
        "\n",
        "    # Compute predicted target features.\n",
        "    context_block = context_block.to(device)\n",
        "    with torch.no_grad():\n",
        "        context_repr = context_encoder(context_block.unsqueeze(0))  # shape: [1, feature_dim]\n",
        "        preds = predictor(context_repr)  # shape: [1, num_targets, feature_dim]\n",
        "\n",
        "    # Compute actual target features.\n",
        "    target_blocks = target_blocks.to(device)\n",
        "    if len(target_blocks.shape) == 4:\n",
        "      target_blocks = target_blocks.unsqueeze(0)\n",
        "    B, num_t, C, Ht, Wt = target_blocks.shape  # Note: For a single sample, B==1.\n",
        "    target_blocks_flat = target_blocks.view(B * num_t, C, Ht, Wt)\n",
        "    with torch.no_grad():\n",
        "        target_repr_flat = target_encoder(target_blocks_flat)\n",
        "    target_repr = target_repr_flat.view(B, num_t, -1)  # shape: [1, num_targets, feature_dim]\n",
        "\n",
        "    # Select the first target block for visualization.\n",
        "    pred_feat = preds[0, 0].cpu()       # shape: [feature_dim]\n",
        "    actual_feat = target_repr[0, 0].cpu()  # shape: [feature_dim]\n",
        "\n",
        "    # Reshape features into 2D heatmaps.\n",
        "    if feature_dim == 768:\n",
        "        # For example, 24x32=768\n",
        "        pred_heat = pred_feat.view(24, 32).numpy()\n",
        "        actual_heat = actual_feat.view(24, 32).numpy()\n",
        "    elif feature_dim == 1408:\n",
        "        # For EfficientNet B2, 32x44 = 1408\n",
        "        pred_heat = pred_feat.view(32, 44).numpy()\n",
        "        actual_heat = actual_feat.view(32, 44).numpy()\n",
        "    else:\n",
        "        # Fallback: use square shape if possible.\n",
        "        side = int(np.sqrt(feature_dim))\n",
        "        pred_heat = pred_feat[:side*side].view(side, side).numpy()\n",
        "        actual_heat = actual_feat[:side*side].view(side, side).numpy()\n",
        "\n",
        "    # Convert the original target block to a PIL image for display.\n",
        "    # target_blocks is of shape [num_targets, C, 224, 224]; select first.\n",
        "    target_img_tensor = target_blocks[0,0]  # shape: [C, 224, 224]\n",
        "    to_pil = transforms.ToPILImage()\n",
        "    target_img_pil = to_pil(target_img_tensor.cpu())\n",
        "\n",
        "    # Plot the results: original target block, predicted heatmap, actual heatmap.\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axs[0].imshow(target_img_pil)\n",
        "    axs[0].set_title(\"Original Target Block\")\n",
        "    axs[0].axis(\"off\")\n",
        "\n",
        "    im1 = axs[1].imshow(pred_heat, cmap=\"viridis\")\n",
        "    axs[1].set_title(\"Predicted Feature Heatmap\")\n",
        "    axs[1].axis(\"off\")\n",
        "    plt.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04)\n",
        "\n",
        "    im2 = axs[2].imshow(actual_heat, cmap=\"viridis\")\n",
        "    axs[2].set_title(\"Actual Feature Heatmap\")\n",
        "    axs[2].axis(\"off\")\n",
        "    plt.colorbar(im2, ax=axs[2], fraction=0.046, pad=0.04)\n",
        "\n",
        "    plt.suptitle(os.path.basename(image_path))\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Qy77tSCUvi6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Using a Sample from the DataLoader -----------------\n",
        "\n",
        "# Assume train_loader_aav_ijepa is your DataLoader from the precomputed dataset.\n",
        "# It returns tuples: (context_block, target_blocks, label, image_path)\n",
        "\n",
        "# Get one batch (for example).\n",
        "batch = next(iter(train_loader_aav_ijepa))\n",
        "# batch is a tuple of tensors/lists: (context_blocks, target_blocks, labels, file_paths)\n",
        "context_blocks, target_blocks, labels, file_paths = batch\n",
        "\n",
        "# Select the first sample in the batch.\n",
        "sample = (context_blocks[0], target_blocks[0], labels[0], file_paths[0])\n",
        "\n",
        "# Visualize the predictor output using this sample.\n",
        "visualize_predictor_output_sample(sample, feature_dim=1408)"
      ],
      "metadata": {
        "id": "RkWoLYz6vyk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Classifier"
      ],
      "metadata": {
        "id": "-JP5L9-dDxFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # 1. Load the Saved Checkpoint for the Self-Supervised Model"
      ],
      "metadata": {
        "id": "gGP_-S7CDxFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_tmp_ckpt_filename\n",
        "#checkpoint = torch.load(os.path.join(base_dir, \"ijepa_checkpoint_best.pth\"))\n",
        "#checkpoint = torch.load(ijepa_trained_model)\n",
        "#context_encoder.load_state_dict(checkpoint['context_encoder_state_dict'])"
      ],
      "metadata": {
        "id": "5CtCbMZSMibT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checkpoint = torch.load(os.path.join(base_dir, \"ijepa_checkpoint_best.pth\"))\n",
        "#checkpoint = torch.load(ijepa_trained_model)\n",
        "#context_encoder.load_state_dict(checkpoint['context_encoder_state_dict'])\n",
        "# Freeze the context encoder.\n",
        "context_encoder.eval()\n",
        "for param in context_encoder.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:36:22.244962Z",
          "iopub.execute_input": "2025-04-04T05:36:22.245268Z",
          "iopub.status.idle": "2025-04-04T05:36:23.796067Z",
          "shell.execute_reply.started": "2025-04-04T05:36:22.245245Z",
          "shell.execute_reply": "2025-04-04T05:36:23.795265Z"
        },
        "id": "MoLU-VlbDxFY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # 2. Define the Classifier"
      ],
      "metadata": {
        "id": "CXBxnWQwDxFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 3  # Adjust this number based on your dataset.\n",
        "#classifier = nn.Linear(2048, num_classes).cuda()\n",
        "classifier = nn.Linear(1408, num_classes).cuda()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:37:31.156101Z",
          "iopub.execute_input": "2025-04-04T05:37:31.156416Z",
          "iopub.status.idle": "2025-04-04T05:37:31.161624Z",
          "shell.execute_reply.started": "2025-04-04T05:37:31.156392Z",
          "shell.execute_reply": "2025-04-04T05:37:31.160761Z"
        },
        "id": "1w7zBuVpDxFZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # 3. Set Up Optimizer and Loss Criterion"
      ],
      "metadata": {
        "id": "yjtptDC6DxFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_optimizer = optim.Adam(classifier.parameters(), lr=1e-2)\n",
        "criterion_cls = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:37:47.689510Z",
          "iopub.execute_input": "2025-04-04T05:37:47.690101Z",
          "iopub.status.idle": "2025-04-04T05:37:47.694931Z",
          "shell.execute_reply.started": "2025-04-04T05:37:47.690068Z",
          "shell.execute_reply": "2025-04-04T05:37:47.693556Z"
        },
        "id": "dCYqnIs4DxFZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class MultiLayerClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=1408, hidden_dim=1024, num_classes=3):  # Adjust dimensions as needed\n",
        "        super().__init__()\n",
        "        self.projection_head = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.BatchNorm1d(hidden_dim),  # Optional: Batch Normalization for stability\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),  # Optional: Another hidden layer\n",
        "            nn.BatchNorm1d(hidden_dim // 2),  # Optional: Batch Normalization\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classification_head = nn.Linear(hidden_dim // 2, num_classes)  # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.projection_head(x)\n",
        "        x = self.classification_head(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "TIekWSiXyzrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace your previous classifier definition with this:\n",
        "num_classes = 3  # Adjust this number based on your dataset.\n",
        "classifier = MultiLayerClassifier(input_dim=1408, hidden_dim=1024, num_classes=num_classes).cuda()"
      ],
      "metadata": {
        "id": "dRFym5xry275"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Training Loop for the Classifier (Using Training Data Only)"
      ],
      "metadata": {
        "id": "Q04P5EhNDxFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs_clf = 500\n",
        "best_val_loss = float('inf')\n",
        "patience = 50  # Number of epochs to wait for improvement.\n",
        "patience_counter = 0\n",
        "\n",
        "for epoch in range(num_epochs_clf):\n",
        "    epoch_start_time = time.time()\n",
        "    classifier.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    # Training loop.\n",
        "    for context_block, _, label, _ in train_loader_aav_ijepa:\n",
        "        context_block = context_block.cuda()  # [B, C, 224, 224]\n",
        "        label = label.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            features = context_encoder(context_block)  # [B, 768]\n",
        "\n",
        "        logits = classifier(features)  # [B, num_classes]\n",
        "        loss = criterion_cls(logits, label)\n",
        "\n",
        "        clf_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clf_optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * context_block.size(0)\n",
        "        preds = logits.argmax(dim=1)\n",
        "        correct_train += (preds == label).sum().item()\n",
        "        total_train += label.size(0)\n",
        "\n",
        "    epoch_train_loss = running_loss / len(train_dataset_aav_ijepa)\n",
        "    epoch_train_acc = correct_train / total_train\n",
        "    epoch_time = time.time() - epoch_start_time\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_clf} - Train Loss: {epoch_train_loss:.10f} | Train Acc: {epoch_train_acc*100:.10f}% | Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # ----- Validation Evaluation -----\n",
        "    classifier.eval()\n",
        "    running_val_loss = 0.0\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "    with torch.no_grad():\n",
        "        for context_block, _, label, _ in val_loader_aav_ijepa:\n",
        "            context_block = context_block.cuda()\n",
        "            label = label.cuda()\n",
        "            features = context_encoder(context_block)\n",
        "            logits = classifier(features)\n",
        "            loss_val = criterion_cls(logits, label)\n",
        "            running_val_loss += loss_val.item() * context_block.size(0)\n",
        "            preds = logits.argmax(dim=1)\n",
        "            correct_val += (preds == label).sum().item()\n",
        "            total_val += label.size(0)\n",
        "    epoch_val_loss = running_val_loss / len(val_dataset_aav_ijepa)\n",
        "    epoch_val_acc = correct_val / total_val\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs_clf} - Val Loss: {epoch_val_loss:.10f} | Val Acc: {epoch_val_acc*100:.10f}%\")\n",
        "\n",
        "    # ----- Early Stopping Check -----\n",
        "    if epoch_val_loss < best_val_loss:\n",
        "        best_val_loss = epoch_val_loss\n",
        "        patience_counter = 0\n",
        "        # Save checkpoint if improved.\n",
        "        checkpoint = {\n",
        "            'epoch': epoch+1,\n",
        "            'classifier_state_dict': classifier.state_dict(),\n",
        "            'optimizer_state_dict': clf_optimizer.state_dict(),\n",
        "            'train_loss': epoch_train_loss,\n",
        "            'train_acc': epoch_train_acc,\n",
        "            'val_loss': epoch_val_loss,\n",
        "            'val_acc': epoch_val_acc\n",
        "        }\n",
        "        torch.save(checkpoint, os.path.join(base_dir, \"ijepa_classifier_tbest_resnet50_model_ema_0.95_lr_0.001.pth\"))\n",
        "        print(f\"Checkpoint saved at epoch {epoch+1} with Val Loss: {epoch_val_loss:.10f}\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        print(f\"No improvement in validation loss for {patience_counter} epoch(s).\")\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "print(\"Classifier training complete!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:51:12.610619Z",
          "iopub.execute_input": "2025-04-04T05:51:12.611036Z",
          "iopub.status.idle": "2025-04-04T05:52:37.314905Z",
          "shell.execute_reply.started": "2025-04-04T05:51:12.611005Z",
          "shell.execute_reply": "2025-04-04T05:52:37.313903Z"
        },
        "id": "9JMQARGJDxFZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "3afwA_-HDxFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the checkpoint file.\n",
        "checkpoint_path = os.path.join(base_dir, \"ijepa_classifier_best.pth\")\n",
        "checkpoint_path = ijepa_trained_classifier_model\n",
        "# Load the checkpoint dictionary.\n",
        "checkpoint = torch.load(checkpoint_path)\n",
        "\n",
        "# Load state dictionaries into your classifier and optimizer.\n",
        "classifier.load_state_dict(checkpoint['classifier_state_dict'])\n",
        "clf_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "# Optionally, retrieve metadata.\n",
        "start_epoch = checkpoint['epoch']\n",
        "train_loss = checkpoint['train_loss']\n",
        "train_acc = checkpoint['train_acc']\n",
        "#val_loss = checkpoint['val_loss']\n",
        "#val_acc = checkpoint['val_acc']\n",
        "\n",
        "print(f\"Checkpoint loaded from epoch {start_epoch}\")\n",
        "print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc*100:.2f}%\")\n",
        "#print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc*100:.2f}%\")"
      ],
      "metadata": {
        "id": "ncQ9bP3kHGC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Ensure the classifier and context_encoder are in evaluation mode.\n",
        "classifier.eval()\n",
        "context_encoder.eval()\n",
        "\n",
        "# Containers for test results.\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for context_block, _, label, _ in test_loader_aav_ijepa:\n",
        "        context_block = context_block.cuda()  # [B, C, 224, 224]\n",
        "        label = label.cuda()\n",
        "\n",
        "        # Extract features using the frozen context encoder.\n",
        "        features = context_encoder(context_block)  # [B, 768]\n",
        "        logits = classifier(features)              # [B, num_classes]\n",
        "        probs = torch.softmax(logits, dim=1)\n",
        "        preds = logits.argmax(dim=1)\n",
        "\n",
        "        all_labels.extend(label.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "all_probs = np.array(all_probs)\n",
        "\n",
        "# Calculate overall test accuracy.\n",
        "test_accuracy = np.mean(all_preds == all_labels)\n",
        "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:52:40.081921Z",
          "iopub.execute_input": "2025-04-04T05:52:40.082549Z",
          "iopub.status.idle": "2025-04-04T05:52:42.638118Z",
          "shell.execute_reply.started": "2025-04-04T05:52:40.082522Z",
          "shell.execute_reply": "2025-04-04T05:52:42.637084Z"
        },
        "id": "_elbWbwrDxFa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # ----- Confusion Matrix -----"
      ],
      "metadata": {
        "id": "eByUTHbeDxFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "cm_path = os.path.join(base_dir, \"confusion_matrix.png\")\n",
        "plt.show()\n",
        "plt.savefig(cm_path)\n",
        "plt.close()\n",
        "print(f\"Confusion matrix saved to: {cm_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:52:47.337960Z",
          "iopub.execute_input": "2025-04-04T05:52:47.338272Z",
          "iopub.status.idle": "2025-04-04T05:52:47.552494Z",
          "shell.execute_reply.started": "2025-04-04T05:52:47.338249Z",
          "shell.execute_reply": "2025-04-04T05:52:47.551478Z"
        },
        "id": "i2Kw_Vt-DxFa"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # # Print Classification Report."
      ],
      "metadata": {
        "id": "8d9Z5ivLDxFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Classification Report.\n",
        "report = classification_report(all_labels, all_preds, target_names=[f\"Class {i}\" for i in range(num_classes)])\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:53:40.250850Z",
          "iopub.execute_input": "2025-04-04T05:53:40.251206Z",
          "iopub.status.idle": "2025-04-04T05:53:40.270847Z",
          "shell.execute_reply.started": "2025-04-04T05:53:40.251177Z",
          "shell.execute_reply": "2025-04-04T05:53:40.269852Z"
        },
        "id": "O5OqugiTDxFb"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ----- ROC Curves for Multi-class Classification -----\n",
        "# Binarize the true labels for ROC computation."
      ],
      "metadata": {
        "id": "68RumFWdDxFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_labels_bin = label_binarize(all_labels, classes=list(range(num_classes)))\n",
        "fpr = {}\n",
        "tpr = {}\n",
        "roc_auc = {}\n",
        "for i in range(num_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(all_labels_bin[:, i], all_probs[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "# Compute micro-average ROC curve and AUC.\n",
        "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(all_labels_bin.ravel(), all_probs.ravel())\n",
        "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "         label=f\"micro-average ROC curve (area = {roc_auc['micro']:.2f})\",\n",
        "         color=\"deeppink\", linestyle=\":\", linewidth=4)\n",
        "\n",
        "colors = [\"aqua\", \"darkorange\", \"cornflowerblue\"]\n",
        "for i, color in zip(range(num_classes), colors):\n",
        "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "             label=f\"ROC curve of class {i} (area = {roc_auc[i]:.2f})\")\n",
        "\n",
        "plt.plot([0, 1], [0, 1], \"k--\", lw=2)\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"Receiver Operating Characteristic (ROC) Curves\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "roc_path = os.path.join(base_dir, \"roc_curves.png\")\n",
        "plt.savefig(roc_path)\n",
        "plt.close()\n",
        "print(f\"ROC curves saved to: {roc_path}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-04T05:54:08.602532Z",
          "iopub.execute_input": "2025-04-04T05:54:08.602900Z",
          "iopub.status.idle": "2025-04-04T05:54:08.802246Z",
          "shell.execute_reply.started": "2025-04-04T05:54:08.602873Z",
          "shell.execute_reply": "2025-04-04T05:54:08.801414Z"
        },
        "id": "jwd3blfCDxFb"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}